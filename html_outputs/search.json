[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Epidemiologist R Handbook",
    "section": "",
    "text": "Welcome",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#r-for-applied-epidemiology-and-public-health",
    "href": "index.html#r-for-applied-epidemiology-and-public-health",
    "title": "The Epidemiologist R Handbook",
    "section": "R for applied epidemiology and public health",
    "text": "R for applied epidemiology and public health\nUsage: This handbook has been used over 3 million times by 850,000 people around the world.\nWho is this for? Epidemiologists, public health professionals, and students who want to learn R for data analysis, visualization, and reporting.\nAre you just starting with R? Try our free interactive tutorials or synchronous, virtual intro course used by US CDC, WHO, and 400+ other health agencies and Field Epi Training Programs worldwide.\nLanguages: French (Français), Spanish (Español), Vietnamese (Tiếng Việt), Japanese (日本), Turkish (Türkçe), Portuguese (Português), Russian (Русский)\n\n\n\n\n\n\n\n Written by epidemiologists, for epidemiologists\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\nApplied Epi is a nonprofit organisation and grassroots movement of frontline epis from around the world. We write in our spare time to offer this resource to the community. Your encouragement and feedback is most welcome:\n\nVisit our website and join our contact list\n\ncontact@appliedepi.org, tweet @appliedepi, or LinkedIn\n\nSubmit issues to our Github repository\n\nWe offer live R training from instructors with decades of applied epidemiology experience - www.appliedepi.org/live.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-handbook",
    "href": "index.html#how-to-use-this-handbook",
    "title": "The Epidemiologist R Handbook",
    "section": "How to use this handbook",
    "text": "How to use this handbook\n\nBrowse the pages in the Table of Contents, or use the search box\nClick the “copy” icons to copy code\n\nYou can follow-along with the example data\n\nOffline version\nSee instructions in the Download handbook and data page.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "The Epidemiologist R Handbook",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis handbook is produced by an independent collaboration of epidemiologists from around the world drawing upon experience with organizations including local, state, provincial, and national health agencies, the World Health Organization (WHO), Doctors without Borders (MSF), hospital systems, and academic institutions.\nThis handbook is not an approved product of any specific organization. Although we strive for accuracy, we provide no guarantee of the content in this book.\n\nContributors\nEditor: Neale Batra\nAuthors: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Chris Bailey, Daniel Molling, Isha Berry, Emma Buajitti, Mathilde Mousset, Sara Hollis, Wen Lin\nReviewers and supporters: Pat Keating, Amrish Baidjoe, Annick Lenglet, Margot Charette, Danielly Xavier, Marie-Amélie Degail Chabrat, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Kate Kelsey, Berhe Etsay, John Rossow, Mackenzie Zendt, James Wright, Laura Haskins, Flavio Finger, Tim Taylor, Jae Hyoung Tim Lee, Brianna Bradley, Wayne Enanoria, Manual Albela Miranda, Molly Mantus, Pattama Ulrich, Joseph Timothy, Adam Vaughan, Olivia Varsaneux, Lionel Monteiro, Joao Muianga\nIllustrations: Calder Fong\n\n\n\n\n\n\nFunding and support\nThis book was primarily a volunteer effort that took thousands of hours to create.\nThe handbook received some supportive funding via a COVID-19 emergency capacity-building grant from TEPHINET, the global network of Field Epidemiology Training Programs (FETPs).\nAdministrative support was provided by the EPIET Alumni Network (EAN), with special thanks to Annika Wendland. EPIET is the European Programme for Intervention Epidemiology Training.\nSpecial thanks to Médecins Sans Frontières (MSF) Operational Centre Amsterdam (OCA) for their support during the development of this handbook.\nThis publication was supported by Cooperative Agreement number NU2GGH001873, funded by the Centers for Disease Control and Prevention through TEPHINET, a program of The Task Force for Global Health. Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the Centers for Disease Control and Prevention, the Department of Health and Human Services, The Task Force for Global Health, Inc. or TEPHINET.\n\n\nInspiration\nThe multitude of tutorials and vignettes that provided knowledge for development of handbook content are credited within their respective pages.\nMore generally, the following sources provided inspiration for this handbook:\nThe “R4Epis” project (a collaboration between MSF and RECON)\nR Epidemics Consortium (RECON)\nR for Data Science book (R4DS)\nbookdown: Authoring Books and Technical Documents with R Markdown\nNetlify hosts this website",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#terms-of-use-and-contribution",
    "href": "index.html#terms-of-use-and-contribution",
    "title": "The Epidemiologist R Handbook",
    "section": "Terms of Use and Contribution",
    "text": "Terms of Use and Contribution\n\nLicense\n Applied Epi Incorporated, 2021 This work is licensed by Applied Epi Incorporated under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\nAcademic courses and epidemiologist training programs are welcome to contact us about use or adaptation of this material (email contact@appliedepi.org).\n\n\nCitation\nBatra, Neale, et al. The Epidemiologist R Handbook. 2021. \n\n\nContribution\nIf you would like to make a content contribution, please contact with us first via Github issues or by email. We are implementing a schedule for updates and are creating a contributor guide.\nPlease note that the epiRhandbook project is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.html",
    "href": "new_pages/editorial_style.html",
    "title": "1  Editorial and technical notes",
    "section": "",
    "text": "1.1 Approach and style\nThe potential audience for this book is large. It will surely be used by people very new to R, and also by experienced R users looking for best practices and tips. So it must be both accessible and succinct. Therefore, our approach was to provide just enough text explanation that someone very new to R can apply the code and follow what the code is doing.\nA few other points:",
    "crumbs": [
      "About this book",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Editorial and technical notes</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.html#approach-and-style",
    "href": "new_pages/editorial_style.html#approach-and-style",
    "title": "1  Editorial and technical notes",
    "section": "",
    "text": "This is a code reference book accompanied by relatively brief examples - not a thorough textbook on R or data science\n\nThis is a R handbook for use within applied epidemiology - not a manual on the methods or science of applied epidemiology\n\nThis is intended to be a living document - optimal R packages for a given task change often and we welcome discussion about which to emphasize in this handbook\n\n\nR packages\nSo many choices\nOne of the most challenging aspects of learning R is knowing which R package to use for a given task. It is a common occurrence to struggle through a task only later to realize - hey, there’s an R package that does all that in one command line!\nIn this handbook, we try to offer you at least two ways to complete each task: one tried-and-true method (probably in base R or tidyverse) and one special R package that is custom-built for that purpose. We want you to have a couple options in case you can’t download a given package or it otherwise does not work for you.\nIn choosing which packages to use, we prioritized R packages and approaches that have been tested and vetted by the community, minimize the number of packages used in a typical work session, that are stable (not changing very often), and that accomplish the task simply and cleanly\nThis handbook generally prioritizes R packages and functions from the tidyverse. Tidyverse is a collection of R packages designed for data science that share underlying grammar and data structures. All tidyverse packages can be installed or loaded via the tidyverse package. Read more at the tidyverse website.\nWhen applicable, we also offer code options using base R - the packages and functions that come with R at installation. This is because we recognize that some of this book’s audience may not have reliable internet to download extra packages.\nLinking functions to packages explicitly\nIt is often frustrating in R tutorials when a function is shown in code, but you don’t know which package it is from! We try to avoid this situation.\nIn the narrative text, package names are written in bold (e.g. dplyr) and functions are written like this: mutate(). We strive to be explicit about which package a function comes from, either by referencing the package in nearby text or by specifying the package explicitly in the code like this: dplyr::mutate(). It may look redundant, but we are doing it on purpose.\nSee the page on R basics to learn more about packages and functions.\n\n\nCode style\nIn the handbook, we frequently utilize “new lines”, making our code appear “long”. We do this for a few reasons:\n\nWe can write explanatory comments with # that are adjacent to each little part of the code\n\nGenerally, longer (vertical) code is easier to read\n\nIt is easier to read on a narrow screen (no sideways scrolling needed)\n\nFrom the indentations, it can be easier to know which arguments belong to which function\n\nAs a result, code that could be written like this:\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;%  # group rows by hospital\n  slice_max(date, n = 1, with_ties = F) # if there's a tie (of date), take the first row\n\n…is written like this:\n\nlinelist %&gt;% \n  group_by(hospital) %&gt;% # group rows by hospital\n  slice_max(\n    date,                # keep row per group with maximum date value \n    n = 1,               # keep only the single highest row \n    with_ties = F)       # if there's a tie (of date), take the first row\n\nR code is generally not affected by new lines or indentations. When writing code, if you initiate a new line after a comma it will apply automatic indentation patterns.\nWe also use lots of spaces (e.g. n = 1 instead of n=1) because it is easier to read. Be kind to the people reading your code!\n\n\nNomenclature\nIn this handbook, we generally reference “columns” and “rows” instead of “variables” and “observations”. As explained in this primer on “tidy data”, most epidemiological statistical datasets consist structurally of rows, columns, and values.\nVariables contain the values that measure the same underlying attribute (like age group, outcome, or date of onset). Observations contain all values measured on the same unit (e.g. a person, site, or lab sample). So these aspects can be more difficult to tangibly define.\nIn “tidy” datasets, each column is a variable, each row is an observation, and each cell is a single value. However some datasets you encounter will not fit this mold - a “wide” format dataset may have a variable split across several columns (see an example in the Pivoting data page). Likewise, observations could be split across several rows.\nMost of this handbook is about managing and transforming data, so referring to the concrete data structures of rows and columns is more relevant than the more abstract observations and variables. Exceptions occur primarily in pages on data analysis, where you will see more references to variables and observations.\n\n\nNotes\nHere are the types of notes you may encounter in the handbook:\nNOTE: This is a note\nTIP: This is a tip.\nCAUTION: This is a cautionary note.\nDANGER: This is a warning.",
    "crumbs": [
      "About this book",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Editorial and technical notes</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.html#editorial-decisions",
    "href": "new_pages/editorial_style.html#editorial-decisions",
    "title": "1  Editorial and technical notes",
    "section": "1.2 Editorial decisions",
    "text": "1.2 Editorial decisions\nBelow, we track significant editorial decisions around package and function choice. If you disagree or want to offer a new tool for consideration, please join/start a conversation on our Github page.\nTable of package, function, and other editorial decisions\n\n\n\n\n\n\n\n\n\nSubject\nConsidered\nOutcome\nBrief rationale\n\n\n\n\nGeneral coding approach\ntidyverse, data.table, base\ntidyverse, with a page on data.table, and mentions of base alternatives for readers with no internet\ntidyverse readability, universality, most-taught\n\n\nPackage loading\nlibrary(),install.packages(), require(), pacman\npacman\nShortens and simplifies code for most multi-package install/load use-cases\n\n\nImport and export\nrio, many other packages\nrio\nEase for many file types\n\n\nGrouping for summary statistics\ndplyr group_by(), stats aggregate()\ndplyr group_by()\nConsistent with tidyverse emphasis\n\n\nPivoting\ntidyr (pivot functions), reshape2 (melt/cast), tidyr (spread/gather)\ntidyr (pivot functions)\nreshape2 is retired, tidyr uses pivot functions as of v1.0.0\n\n\nClean column names\nlinelist, janitor\njanitor\nConsolidation of packages emphasized\n\n\nEpiweeks\nlubridate, aweek, tsibble, zoo\nlubridate generally, the others for specific cases\nlubridate’s flexibility, consistency, package maintenance prospects\n\n\nggplot labels\nlabs(), ggtitle()/ylab()/xlab()\nlabs()\nall labels in one place, simplicity\n\n\nConvert to factor\nfactor(), forcats\nforcats\nits various functions also convert to factor in same command\n\n\nEpidemic curves\nincidence, ggplot2, EpiCurve\nincidence2 as quick, ggplot2 as detailed\ndependability\n\n\nConcatenation\npaste(), paste0(), str_glue(), glue()\nstr_glue()\nMore simple syntax than paste functions; within stringr",
    "crumbs": [
      "About this book",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Editorial and technical notes</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.html#major-revisions",
    "href": "new_pages/editorial_style.html#major-revisions",
    "title": "1  Editorial and technical notes",
    "section": "1.3 Major revisions",
    "text": "1.3 Major revisions\n\n\n\nDate\nMajor changes\n\n\n\n\n10 May 2021\nRelease of version 1.0.0\n\n\n20 Nov 2022\nRelease of version 1.0.1\n\n\n\nNEWS With version 1.0.1 the following changes have been implemented:\n\nUpdate to R version 4.2\n\nData cleaning: switched {linelist} to {matchmaker}, removed unnecessary line from case_when() example\n\nDates: switched {linelist} guess_date() to {parsedate} parse_date()\nPivoting: slight update to pivot_wider() id_cols=\n\nSurvey analysis: switched plot_age_pyramid() to age_pyramid(), slight change to alluvial plot code\n\nHeat plots: added ungroup() to agg_weeks chunk\n\nInteractive plots: added ungroup() to chunk that makes agg_weeks so that expand() works as intended\n\nTime series: added data.frame() around objects within all trending::fit() and predict() commands\n\nCombinations analysis: Switch case_when() to ifelse() and added optional across() code for preparing the data\n\nTransmission chains: Update to more recent version of {epicontacts}",
    "crumbs": [
      "About this book",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Editorial and technical notes</span>"
    ]
  },
  {
    "objectID": "new_pages/editorial_style.html#session-info-r-rstudio-packages",
    "href": "new_pages/editorial_style.html#session-info-r-rstudio-packages",
    "title": "1  Editorial and technical notes",
    "section": "1.4 Session info (R, RStudio, packages)",
    "text": "1.4 Session info (R, RStudio, packages)\nBelow is the information on the versions of R, RStudio, and R packages used during this rendering of the Handbook.\n\nsessioninfo::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.2 (2023-10-31)\n os       Ubuntu 22.04.4 LTS\n system   x86_64, linux-gnu\n ui       X11\n language (EN)\n collate  C.UTF-8\n ctype    C.UTF-8\n tz       UTC\n date     2024-06-22\n pandoc   3.1.11 @ /opt/hostedtoolcache/pandoc/3.1.11/x64/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package     * version date (UTC) lib source\n P BiocManager   1.30.22 2023-08-08 [?] CRAN (R 4.3.2)\n P cli           3.6.2   2023-12-11 [?] CRAN (R 4.3.2)\n P digest        0.6.35  2024-03-11 [?] CRAN (R 4.3.2)\n P evaluate      0.23    2023-11-01 [?] CRAN (R 4.3.2)\n P fastmap       1.1.1   2023-02-24 [?] CRAN (R 4.3.2)\n P htmltools     0.5.8   2024-03-25 [?] CRAN (R 4.3.2)\n P htmlwidgets   1.6.4   2023-12-06 [?] CRAN (R 4.3.2)\n P jsonlite      1.8.8   2023-12-04 [?] CRAN (R 4.3.2)\n P knitr         1.45    2023-10-30 [?] CRAN (R 4.3.2)\n   renv          1.0.5   2024-02-29 [1] CRAN (R 4.3.2)\n P rlang         1.1.3   2024-01-10 [?] CRAN (R 4.3.2)\n P rmarkdown     2.26    2024-03-05 [?] CRAN (R 4.3.2)\n P sessioninfo   1.2.2   2021-12-06 [?] CRAN (R 4.3.2)\n P xfun          0.43    2024-03-25 [?] CRAN (R 4.3.2)\n P yaml          2.3.8   2023-12-11 [?] CRAN (R 4.3.2)\n\n [1] /tmp/RtmpKgyyVZ/file26c74995332b/renv/library/R-4.3/x86_64-pc-linux-gnu\n [2] /home/runner/.cache/R/renv/sandbox/R-4.3/x86_64-pc-linux-gnu/95f1b021\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "About this book",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Editorial and technical notes</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.html",
    "href": "new_pages/data_used.html",
    "title": "2  Download handbook and data",
    "section": "",
    "text": "2.1 Download offline handbook\nYou can download the offline version of this handbook as an HTML file so that you can view the file in your web browser even if you no longer have internet access. If you are considering offline use of the Epi R Handbook here are a few things to consider:\nThere are two ways you can download the handbook:",
    "crumbs": [
      "About this book",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Download handbook and data</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.html#download-offline-handbook",
    "href": "new_pages/data_used.html#download-offline-handbook",
    "title": "2  Download handbook and data",
    "section": "",
    "text": "When you open the file it may take a minute or two for the images and the Table of Contents to load\n\nThe offline handbook has a slightly different layout - one very long page with Table of Contents on the left. To search for specific terms use Ctrl+f (Cmd-f)\n\nSee the Suggested packages page to assist you with installing appropriate R packages before you lose internet connectivity\n\nInstall our R package epirhandbook that contains all the example data (install process described below)\n\n\n\nUse download link\nFor quick access, right-click this link and select “Save link as”.\nIf on a Mac, use Cmd+click. If on a mobile, press and hold the link and select “Save link”. The handbook will download to your device. If a screen with raw HTML code appears, ensure you have followed the above instructions or try Option 2.\n\n\nUse our R package\nWe offer an R package called epirhandbook. It includes a function download_book() that downloads the handbook file from our Github repository to your computer.\nThis package also contains a function get_data() that downloads all the example data to your computer.\nRun the following code to install our R package epirhandbook from the Github repository appliedepi. This package is not on CRAN, so use the special function p_install_gh() to install it from Github.\n\n# install the latest version of the Epi R Handbook package\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n\nNow, load the package for use in your current R session:\n\n# load the package for use\npacman::p_load(epirhandbook)\n\nNext, run the package’s function download_book() (with empty parentheses) to download the handbook to your computer. Assuming you are in RStudio, a window will appear allowing you to select a save location.\n\n# download the offline handbook to your computer\ndownload_book()",
    "crumbs": [
      "About this book",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Download handbook and data</span>"
    ]
  },
  {
    "objectID": "new_pages/data_used.html#download-data-to-follow-along",
    "href": "new_pages/data_used.html#download-data-to-follow-along",
    "title": "2  Download handbook and data",
    "section": "2.2 Download data to follow along",
    "text": "2.2 Download data to follow along\nTo “follow along” with the handbook pages, you can download the example data and outputs.\n\nUse our R package\nThe easiest approach to download all the data is to install our R package epirhandbook. It contains a function get_data() that saves all the example data to a folder of your choice on your computer.\nTo install our R package epirhandbook, run the following code. This package is not on CRAN, so use the function p_install_gh() to install it. The input is referencing our Github organisation (“appliedepi”) and the epirhandbook package.\n\n# install the latest version of the Epi R Handbook package\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n\nNow, load the package for use in your current R session:\n\n# load the package for use\npacman::p_load(epirhandbook)\n\nNext, use the package’s function get_data() to download the example data to your computer. Run get_data(\"all\") to get all the example data, or provide a specific file name and extension within the quotes to retrieve only one file.\nThe data have already been downloaded with the package, and simply need to be transferred out to a folder on your computer. A pop-up window will appear, allowing you to select a save folder location. We suggest you create a new “data” folder as there are about 30 files (including example data and example outputs).\n\n# download all the example data into a folder on your computer\nget_data(\"all\")\n\n# download only the linelist example data into a folder on your computer\nget_data(file = \"linelist_cleaned.rds\")\n\n\n# download a specific file into a folder on your computer\nget_data(\"linelist_cleaned.rds\")\n\nOnce you have used get_data() to save a file to your computer, you will still need to import it into R. see the Import and export page for details.\nIf you wish, you can review all the data used in this handbook in the “data” folder of our Github repository.\n\n\nDownload one-by-one\nThis option involves downloading the data file-by-file from our Github repository via either a link or an R command specific to the file. Some file types allow a download button, while others can be downloaded via an R command.\n\nCase linelist\nThis is a fictional Ebola outbreak, expanded by the handbook team from the ebola_sim practice dataset in the outbreaks package.\n\nClick to download the “raw” linelist (.xlsx). The “raw” case linelist is an Excel spreadsheet with messy data. Use this to follow-along with the Cleaning data and core functions page.\nClick to download the “clean” linelist (.rds). Use this file for all other pages of this handbook that use the linelist. A .rds file is an R-specific file type that preserves column classes. This ensures you will have only minimal cleaning to do after importing the data into R.\n\nOther related files:\n\nClick to download the “clean” linelist as an Excel file\nPart of the cleaning page uses a “cleaning dictionary” (.csv file). You can load it directly into R by running the following commands:\n\n\npacman::p_load(rio) # install/load the rio package\n\n# import the file directly from Github\ncleaning_dict &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/cleaning_dict.csv\")\n\n\n\nMalaria count data\nThese data are fictional counts of malaria cases by age group, facility, and day. A .rds file is an R-specific file type that preserves column classes. This ensures you will have only minimal cleaning to do after importing the data into R.\n Click to download the malaria count data (.rds file) \n\n\nLikert-scale data\nThese are fictional data from a Likert-style survey, used in the page on Demographic pyramids and Likert-scales. You can load these data directly into R by running the following commands:\n\npacman::p_load(rio) # install/load the rio package\n\n# import the file directly from Github\nlikert_data &lt;- import(\"https://raw.githubusercontent.com/appliedepi/epirhandbook_eng/master/data/likert_data.csv\")\n\n\n\nFlexdashboard\nBelow are links to the file associated with the page on Dashboards with R Markdown:\n\nTo download the R Markdown for the outbreak dashboard, right-click this link (Cmd+click for Mac) and select “Save link as”.\n\nTo download the HTML dashboard, right-click this link (Cmd+click for Mac) and select “Save link as”.\n\n\n\nContact Tracing\nThe Contact Tracing page demonstrated analysis of contact tracing data, using example data from Go.Data. The data used in the page can be downloaded as .rds files by clicking the following links:\n Click to download the case investigation data (.rds file) \n Click to download the contact registration data (.rds file) \n Click to download the contact follow-up data (.rds file) \nNOTE: Structured contact tracing data from other software (e.g. KoBo, DHIS2 Tracker, CommCare) may look different. If you would like to contribute alternative sample data or content for this page, please contact us.\nTIP: If you are deploying Go.Data and want to connect to your instance’s API, see the Import and export page (API section) and the Go.Data Community of Practice.\n\n\nGIS\nShapefiles have many sub-component files, each with a different file extention. One file will have the “.shp” extension, but others may have “.dbf”, “.prj”, etc.\nThe GIS basics page provides links to the Humanitarian Data Exchange website where you can download the shapefiles directly as zipped files.\nFor example, the health facility points data can be downloaded here. Download “hotosm_sierra_leone_health_facilities_points_shp.zip”. Once saved to your computer, “unzip” the folder. You will see several files with different extensions (e.g. “.shp”, “.prj”, “.shx”) - all these must be saved to the same folder on your computer. Then to import into R, provide the file path and name of the “.shp” file to st_read() from the sf package (as described in the GIS basics page).\nIf you follow Option 1 to download all the example data (via our R package epirhandbook), all the shapefiles are included.\nAlternatively, you can download the shapefiles from the R Handbook Github “data” folder (see the “gis” sub-folder). However, be aware that you will need to download each sub-file individually to your computer. In Github, click on each file individually and download them by clicking on the “Download” button. Below, you can see how the shapefile “sle_adm3” consists of many files - each of which would need to be downloaded from Github.\n\n\n\n\n\n\n\n\n\n\n\nPhylogenetic trees\nSee the page on Phylogenetic trees. Newick file of phylogenetic tree constructed from whole genome sequencing of 299 Shigella sonnei samples and corresponding sample data (converted to a text file). The Belgian samples and resulting data are kindly provided by the Belgian NRC for Salmonella and Shigella in the scope of a project conducted by an ECDC EUPHEM Fellow, and will also be published in a manuscript. The international data are openly available on public databases (ncbi) and have been previously published.\n\nTo download the “Shigella_tree.txt” phylogenetic tree file, right-click this link (Cmd+click for Mac) and select “Save link as”.\n\nTo download the “sample_data_Shigella_tree.csv” with additional information on each sample, right-click this link (Cmd+click for Mac) and select “Save link as”.\n\nTo see the new, created subset-tree, right-click this link (Cmd+click for Mac) and select “Save link as”. The .txt file will download to your computer.\n\nYou can then import the .txt files with read.tree() from the ape package, as explained in the page.\n\nape::read.tree(\"Shigella_tree.txt\")\n\n\n\nStandardization\nSee the page on Standardised rates. You can load the data directly from our Github repository on the internet into your R session with the following commands:\n\n# install/load the rio package\npacman::p_load(rio) \n\n##############\n# Country A\n##############\n# import demographics for country A directly from Github\nA_demo &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics.csv\")\n\n# import deaths for country A directly from Github\nA_deaths &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryA.csv\")\n\n##############\n# Country B\n##############\n# import demographics for country B directly from Github\nB_demo &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics_2.csv\")\n\n# import deaths for country B directly from Github\nB_deaths &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryB.csv\")\n\n\n###############\n# Reference Pop\n###############\n# import demographics for country B directly from Github\nstandard_pop_data &lt;- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/world_standard_population_by_sex.csv\")\n\n\n\nTime series and outbreak detection\nSee the page on Time series and outbreak detection. We use campylobacter cases reported in Germany 2002-2011, as available from the surveillance R package. (nb. this dataset has been adapted from the original, in that 3 months of data have been deleted from the end of 2011 for demonstration purposes)\n Click to download  Campylobacter in Germany (.xlsx) \nWe also use climate data from Germany 2002-2011 (temperature in degrees celsius and rain fail in millimetres) . These were downloaded from the EU Copernicus satellite reanalysis dataset using the ecmwfr package. You will need to download all of these and import them with stars::read_stars() as explained in the time series page.\n Click to download  Germany weather 2002 (.nc file) \n Click to download  Germany weather 2003 (.nc file) \n Click to download  Germany weather 2004 (.nc file) \n Click to download  Germany weather 2005 (.nc file) \n Click to download  Germany weather 2006 (.nc file) \n Click to download  Germany weather 2007 (.nc file) \n Click to download  Germany weather 2008 (.nc file) \n Click to download  Germany weather 2009 (.nc file) \n Click to download  Germany weather 2010 (.nc file) \n Click to download  Germany weather 2011 (.nc file) \n\n\nSurvey analysis\nFor the survey analysis page we use fictional mortality survey data based off MSF OCA survey templates. This fictional data was generated as part of the “R4Epis” project.\n Click to download  Fictional survey data (.xlsx) \n Click to download  Fictional survey data dictionary (.xlsx) \n Click to download  Fictional survey population data (.xlsx) \n\n\nShiny\nThe page on Dashboards with Shiny demonstrates the construction of a simple app to display malaria data.\nTo download the R files that produce the Shiny app:\nYou can  click here to download the app.R file that contains both the UI and Server code for the Shiny app.\nYou can  click here to download the facility_count_data.rds file that contains malaria data for the Shiny app. Note that you may need to store it within a “data” folder for the here() file paths to work correctly.\nYou can  click here to download the global.R file that should run prior to the app opening, as explained in the page.\nYou can  click here to download the plot_epicurve.R file that is sourced by global.R. Note that you may need to store it within a “funcs” folder for the here() file paths to work correctly.",
    "crumbs": [
      "About this book",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Download handbook and data</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.html",
    "href": "new_pages/transition_to_R.html",
    "title": "3  Transition to R",
    "section": "",
    "text": "3.1 From Excel\nTransitioning from Excel directly to R is a very achievable goal. It may seem daunting, but you can do it!\nIt is true that someone with strong Excel skills can do very advanced activities in Excel alone - even using scripting tools like VBA. Excel is used across the world and is an essential tool for an epidemiologist. However, complementing it with R can dramatically improve and expand your work flows.",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Transition to R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.html#from-excel",
    "href": "new_pages/transition_to_R.html#from-excel",
    "title": "3  Transition to R",
    "section": "",
    "text": "Benefits\nYou will find that using R offers immense benefits in time saved, more consistent and accurate analysis, reproducibility, shareability, and faster error-correction. Like any new software there is a learning “curve” of time you must invest to become familiar. The dividends will be significant and immense scope of new possibilities will open to you with R.\nExcel is a well-known software that can be easy for a beginner to use to produce simple analysis and visualizations with “point-and-click”. In comparison, it can take a couple weeks to become comfortable with R functions and interface. However, R has evolved in recent years to become much more friendly to beginners.\nMany Excel workflows rely on memory and on repetition - thus, there is much opportunity for error. Furthermore, generally the data cleaning, analysis methodology, and equations used are hidden from view. It can require substantial time for a new colleague to learn what an Excel workbook is doing and how to troubleshoot it. With R, all the steps are explicitly written in the script and can be easily viewed, edited, corrected, and applied to other datasets.\nTo begin your transition from Excel to R you must adjust your mindset in a few important ways:\n\n\nTidy data\nUse machine-readable “tidy” data instead of messy “human-readable” data. These are the three main requirements for “tidy” data, as explained in this tutorial on “tidy” data in R:\n\nEach variable must have its own column\n\nEach observation must have its own row\n\nEach value must have its own cell\n\nTo Excel users - think of the role that Excel “tables” play in standardizing data and making the format more predictable.\nAn example of “tidy” data would be the case linelist used throughout this handbook - each variable is contained within one column, each observation (one case) has it’s own row, and every value is in just one cell. Below you can view the first 50 rows of the linelist:\n\n\n\n\n\n\nThe main reason one encounters non-tidy data is because many Excel spreadsheets are designed to prioritize easy reading by humans, not easy reading by machines/software.\nTo help you see the difference, below are some fictional examples of non-tidy data that prioritize human-readability over machine-readability:\n\n\n\n\n\n\n\n\n\nProblems: In the spreadsheet above, there are merged cells which are not easily digested by R. Which row should be considered the “header” is not clear. A color-based dictionary is to the right side and cell values are represented by colors - which is also not easily interpreted by R (nor by humans with color-blindness!). Furthermore, different pieces of information are combined into one cell (multiple partner organizations working in one area, or the status “TBC” in the same cell as “Partner D”).\n\n\n\n\n\n\n\n\n\nProblems: In the spreadsheet above, there are numerous extra empty rows and columns within the dataset - this will cause cleaning headaches in R. Furthermore, the GPS coordinates are spread across two rows for a given treatment center. As a side note - the GPS coordinates are in two different formats!\n“Tidy” datasets may not be as readable to a human eye, but they make data cleaning and analysis much easier! Tidy data can be stored in various formats, for example “long” or “wide”“(see page on Pivoting data), but the principles above are still observed.\n\n\nFunctions\nThe R word “function” might be new, but the concept exists in Excel too as formulas. Formulas in Excel also require precise syntax (e.g. placement of semicolons and parentheses). All you need to do is learn a few new functions and how they work together in R.\n\n\nScripts\nInstead of clicking buttons and dragging cells you will be writing every step and procedure into a “script”. Excel users may be familiar with “VBA macros” which also employ a scripting approach.\nThe R script consists of step-by-step instructions. This allows any colleague to read the script and easily see the steps you took. This also helps de-bug errors or inaccurate calculations. See the R basics section on scripts for examples.\nHere is an example of an R script:\n\n\n\n\n\n\n\n\n\n\n\nExcel-to-R resources\nHere are some links to tutorials to help you transition to R from Excel:\n\nR vs. Excel\n\nRStudio course in R for Excel users\n\n\n\nR-Excel interaction\nR has robust ways to import Excel workbooks, work with the data, export/save Excel files, and work with the nuances of Excel sheets.\nIt is true that some of the more aesthetic Excel formatting can get lost in translation (e.g. italics, sideways text, etc.). If your work flow requires passing documents back-and-forth between R and Excel while retaining the original Excel formatting, try packages such as openxlsx.",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Transition to R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.html#from-stata",
    "href": "new_pages/transition_to_R.html#from-stata",
    "title": "3  Transition to R",
    "section": "3.2 From Stata",
    "text": "3.2 From Stata\n\nComing to R from Stata\nMany epidemiologists are first taught how to use Stata, and it can seem daunting to move into R. However, if you are a comfortable Stata user then the jump into R is certainly more manageable than you might think. While there are some key differences between Stata and R in how data can be created and modified, as well as how analysis functions are implemented – after learning these key differences you will be able to translate your skills.\nBelow are some key translations between Stata and R, which may be handy as your review this guide.\nGeneral notes\n\n\n\nSTATA\nR\n\n\n\n\nYou can only view and manipulate one dataset at a time\nYou can view and manipulate multiple datasets at the same time, therefore you will frequently have to specify your dataset within the code\n\n\nOnline community available through https://www.statalist.org/\nOnline community available through RStudio, StackOverFlow, and R-bloggers\n\n\nPoint and click functionality as an option\nMinimal point and click functionality\n\n\nHelp for commands available by help [command]\nHelp available by [function]? or search in the Help pane\n\n\nComment code using * or /// or /* TEXT */\nComment code using #\n\n\nAlmost all commands are built-in to Stata. New/user-written functions can be installed as ado files using ssc install [package]\nR installs with base functions, but typical use involves installing other packages from CRAN (see page on R basics)\n\n\nAnalysis is usually written in a do file\nAnalysis written in an R script in the RStudio source pane. R markdown scripts are an alternative.\n\n\n\nWorking directory\n\n\n\nSTATA\nR\n\n\n\n\nWorking directories involve absolute filepaths (e.g. “C:/usename/documents/projects/data/”)\nWorking directories can be either absolute, or relative to a project root folder by using the here package (see Import and export)\n\n\nSee current working directory with pwd\nUse getwd() or here() (if using the here package), with empty parentheses\n\n\nSet working directory with cd “folder location”\nUse setwd(“folder location”), or set_here(\"folder location) (if using here package)\n\n\n\nImporting and viewing data\n\n\n\nSTATA\nR\n\n\n\n\nSpecific commands per file type\nUse import() from rio package for almost all filetypes. Specific functions exist as alternatives (see Import and export)\n\n\nReading in csv files is done by import delimited “filename.csv”\nUse import(\"filename.csv\")\n\n\nReading in xslx files is done by import excel “filename.xlsx”\nUse import(\"filename.xlsx\")\n\n\nBrowse your data in a new window using the command browse\nView a dataset in the RStudio source pane using View(dataset). You need to specify your dataset name to the function in R because multiple datasets can be held at the same time. Note capital “V” in this function\n\n\nGet a high-level overview of your dataset using summarize, which provides the variable names and basic information\nGet a high-level overview of your dataset using summary(dataset)\n\n\n\nBasic data manipulation\n\n\n\nSTATA\nR\n\n\n\n\nDataset columns are often referred to as “variables”\nMore often referred to as “columns” or sometimes as “vectors” or “variables”\n\n\nNo need to specify the dataset\nIn each of the below commands, you need to specify the dataset - see the page on Cleaning data and core functions for examples\n\n\nNew variables are created using the command generate varname =\nGenerate new variables using the function mutate(varname = ). See page on Cleaning data and core functions for details on all the below dplyr functions.\n\n\nVariables are renamed using rename old_name new_name\nColumns can be renamed using the function rename(new_name = old_name)\n\n\nVariables are dropped using drop varname\nColumns can be removed using the function select() with the column name in the parentheses following a minus sign\n\n\nFactor variables can be labeled using a series of commands such as label define\nLabeling values can done by converting the column to Factor class and specifying levels. See page on Factors. Column names are not typically labeled as they are in Stata.\n\n\n\nDescriptive analysis\n\n\n\nSTATA\nR\n\n\n\n\nTabulate counts of a variable using tab varname\nProvide the dataset and column name to table() such as table(dataset$colname). Alternatively, use count(varname) from the dplyr package, as explained in Grouping data\n\n\nCross-tabulaton of two variables in a 2x2 table is done with tab varname1 varname2\nUse table(dataset$varname1, dataset$varname2 or count(varname1, varname2)\n\n\n\nWhile this list gives an overview of the basics in translating Stata commands into R, it is not exhaustive. There are many other great resources for Stata users transitioning to R that could be of interest:\n\nhttps://dss.princeton.edu/training/RStata.pdf\n\nhttps://clanfear.github.io/Stata_R_Equivalency/docs/r_stata_commands.html\n\nhttp://r4stats.com/books/r4stata/",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Transition to R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.html#from-sas",
    "href": "new_pages/transition_to_R.html#from-sas",
    "title": "3  Transition to R",
    "section": "3.3 From SAS",
    "text": "3.3 From SAS\n\nComing from SAS to R\nSAS is commonly used at public health agencies and academic research fields. Although transitioning to a new language is rarely a simple process, understanding key differences between SAS and R may help you start to navigate the new language using your native language. Below outlines the key translations in data management and descriptive analysis between SAS and R.\nGeneral notes\n\n\n\nSAS\nR\n\n\n\n\nOnline community available through SAS Customer Support\nOnline community available through RStudio, StackOverFlow, and R-bloggers\n\n\nHelp for commands available by help [command]\nHelp available by [function]? or search in the Help pane\n\n\nComment code using * TEXT ; or /* TEXT */\nComment code using #\n\n\nAlmost all commands are built-in. Users can write new functions using SAS macro, SAS/IML, SAS Component Language (SCL), and most recently, procedures Proc Fcmp and Proc Proto\nR installs with base functions, but typical use involves installing other packages from CRAN (see page on R basics)\n\n\nAnalysis is usually conducted by writing a SAS program in the Editor window.\nAnalysis written in an R script in the RStudio source pane. R markdown scripts are an alternative.\n\n\n\nWorking directory\n\n\n\nSAS\nR\n\n\n\n\nWorking directories can be either absolute, or relative to a project root folder by defining the root folder using %let rootdir=/root path; %include “&rootdir/subfoldername/filename”\nWorking directories can be either absolute, or relative to a project root folder by using the here package (see Import and export))\n\n\nSee current working directory with %put %sysfunc(getoption(work));\nUse getwd() or here() (if using the here package), with empty parentheses\n\n\nSet working directory with libname “folder location”\nUse setwd(“folder location”), or set_here(\"folder location) if using here package\n\n\n\nImporting and viewing data\n\n\n\nSAS\nR\n\n\n\n\nUse Proc Import procedure or using Data Step Infile statement.\nUse import() from rio package for almost all filetypes. Specific functions exist as alternatives (see Import and export)\n\n\nReading in csv files is done by using Proc Import datafile=”filename.csv” out=work.filename dbms=CSV; run; OR using Data Step Infile statement\nUse import(\"filename.csv\")\n\n\nReading in xslx files is done by using Proc Import datafile=”filename.xlsx” out=work.filename dbms=xlsx; run; OR using Data Step Infile statement\nUse import(“filename.xlsx”)\n\n\nBrowse your data in a new window by opening the Explorer window and select desired library and the dataset\nView a dataset in the RStudio source pane using View(dataset). You need to specify your dataset name to the function in R because multiple datasets can be held at the same time. Note capital “V” in this function\n\n\n\nBasic data manipulation\n\n\n\nSAS\nR\n\n\n\n\nDataset columns are often referred to as “variables”\nMore often referred to as “columns” or sometimes as “vectors” or “variables”\n\n\nNo special procedures are needed to create a variable. New variables are created simply by typing the new variable name, followed by an equal sign, and then an expression for the value\nGenerate new variables using the function mutate(). See page on Cleaning data and core functions for details on all the below dplyr functions.\n\n\nVariables are renamed using rename *old_name=new_name*\nColumns can be renamed using the function rename(new_name = old_name)\n\n\nVariables are kept using **keep**=varname\nColumns can be selected using the function select() with the column name in the parentheses\n\n\nVariables are dropped using **drop**=varname\nColumns can be removed using the function select() with the column name in the parentheses following a minus sign\n\n\nFactor variables can be labeled in the Data Step using Label statement\nLabeling values can done by converting the column to Factor class and specifying levels. See page on Factors. Column names are not typically labeled.\n\n\nRecords are selected using Where or If statement in the Data Step. Multiple selection conditions are separated using “and” command.\nRecords are selected using the function filter() with multiple selection conditions separated either by an AND operator (&) or a comma\n\n\nDatasets are combined using Merge statement in the Data Step. The datasets to be merged need to be sorted first using Proc Sort procedure.\ndplyr package offers a few functions for merging datasets. See page Joining Data for details.\n\n\n\nDescriptive analysis\n\n\n\nSAS\nR\n\n\n\n\nGet a high-level overview of your dataset using Proc Summary procedure, which provides the variable names and descriptive statistics\nGet a high-level overview of your dataset using summary(dataset) or skim(dataset) from the skimr package\n\n\nTabulate counts of a variable using proc freq data=Dataset; Tables varname; Run;\nSee the page on Descriptive tables. Options include table() from base R, and tabyl() from janitor package, among others. Note you will need to specify the dataset and column name as R holds multiple datasets.\n\n\nCross-tabulation of two variables in a 2x2 table is done with proc freq data=Dataset; Tables rowvar*colvar; Run;\nAgain, you can use table(), tabyl() or other options as described in the Descriptive tables page.\n\n\n\nSome useful resources:\nR for SAS and SPSS Users (2011)\nSAS and R, Second Edition (2014)",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Transition to R</span>"
    ]
  },
  {
    "objectID": "new_pages/transition_to_R.html#data-interoperability",
    "href": "new_pages/transition_to_R.html#data-interoperability",
    "title": "3  Transition to R",
    "section": "3.4 Data interoperability",
    "text": "3.4 Data interoperability\n\nsee the Import and export(importing.qmd) page for details on how the R package rio can import and export files such as STATA .dta files, SAS .xpt and.sas7bdat files, SPSS .por and.sav files, and many others.",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Transition to R</span>"
    ]
  },
  {
    "objectID": "new_pages/packages_suggested.html",
    "href": "new_pages/packages_suggested.html",
    "title": "4  Suggested packages",
    "section": "",
    "text": "4.1 Packages from CRAN\n##########################################\n# List of useful epidemiology R packages #\n##########################################\n\n# This script uses the p_load() function from pacman R package, \n# which installs if package is absent, and loads for use if already installed\n\n\n# Ensures the package \"pacman\" is installed\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\n\n# Packages available from CRAN\n##############################\npacman::p_load(\n     \n     # learning R\n     ############\n     learnr,   # interactive tutorials in RStudio Tutorial pane\n     swirl,    # interactive tutorials in R console\n        \n     # project and file management\n     #############################\n     here,     # file paths relative to R project root folder\n     rio,      # import/export of many types of data\n     openxlsx, # import/export of multi-sheet Excel workbooks \n     \n     # package install and management\n     ################################\n     pacman,   # package install/load\n     renv,     # managing versions of packages when working in collaborative groups\n     remotes,  # install from github\n     \n     # General data management\n     #########################\n     tidyverse,    # includes many packages for tidy data wrangling and presentation\n          #dplyr,      # data management\n          #tidyr,      # data management\n          #ggplot2,    # data visualization\n          #stringr,    # work with strings and characters\n          #forcats,    # work with factors \n          #lubridate,  # work with dates\n          #purrr       # iteration and working with lists\n     linelist,     # cleaning linelists\n     naniar,       # assessing missing data\n     \n     # statistics  \n     ############\n     janitor,      # tables and data cleaning\n     gtsummary,    # making descriptive and statistical tables\n     rstatix,      # quickly run statistical tests and summaries\n     broom,        # tidy up results from regressions\n     lmtest,       # likelihood-ratio tests\n     easystats,\n          # parameters, # alternative to tidy up results from regressions\n          # see,        # alternative to visualise forest plots \n     \n     # epidemic modeling\n     ###################\n     epicontacts,  # Analysing transmission networks\n     EpiNow2,      # Rt estimation\n     EpiEstim,     # Rt estimation\n     projections,  # Incidence projections\n     incidence2,   # Make epicurves and handle incidence data\n     i2extras,     # Extra functions for the incidence2 package\n     epitrix,      # Useful epi functions\n     distcrete,    # Discrete delay distributions\n     \n     \n     # plots - general\n     #################\n     #ggplot2,         # included in tidyverse\n     cowplot,          # combining plots  \n     # patchwork,      # combining plots (alternative)     \n     RColorBrewer,     # color scales\n     ggnewscale,       # to add additional layers of color schemes\n\n     \n     # plots - specific types\n     ########################\n     DiagrammeR,       # diagrams using DOT language\n     incidence2,       # epidemic curves\n     gghighlight,      # highlight a subset\n     ggrepel,          # smart labels\n     plotly,           # interactive graphics\n     gganimate,        # animated graphics \n\n     \n     # gis\n     ######\n     sf,               # to manage spatial data using a Simple Feature format\n     tmap,             # to produce simple maps, works for both interactive and static maps\n     OpenStreetMap,    # to add OSM basemap in ggplot map\n     spdep,            # spatial statistics \n     \n     # routine reports\n     #################\n     rmarkdown,        # produce PDFs, Word Documents, Powerpoints, and HTML files\n     reportfactory,    # auto-organization of R Markdown outputs\n     officer,          # powerpoints\n     \n     # dashboards\n     ############\n     flexdashboard,    # convert an R Markdown script into a dashboard\n     shiny,            # interactive web apps\n     \n     # tables for presentation\n     #########################\n     knitr,            # R Markdown report generation and html tables\n     flextable,        # HTML tables\n     #DT,              # HTML tables (alternative)\n     #gt,              # HTML tables (alternative)\n     #huxtable,        # HTML tables (alternative) \n     \n     # phylogenetics\n     ###############\n     ggtree,           # visualization and annotation of trees\n     ape,              # analysis of phylogenetics and evolution\n     treeio            # to visualize phylogenetic files\n \n)",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Suggested packages</span>"
    ]
  },
  {
    "objectID": "new_pages/packages_suggested.html#packages-from-github",
    "href": "new_pages/packages_suggested.html#packages-from-github",
    "title": "4  Suggested packages",
    "section": "4.2 Packages from Github",
    "text": "4.2 Packages from Github\nBelow are commmands to install two packages directly from Github repositories.\n\nThe development version of epicontacts contains the ability to make transmission trees with an temporal x-axis\n\nThe epirhandbook package contains all the example data for this handbook and can be used to download the offline version of the handbook.\n\n\n# Packages to download from Github (not available on CRAN)\n##########################################################\n\n# Development version of epicontacts (for transmission chains with a time x-axis)\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n# The package for this handbook, which includes all the example data  \npacman::p_install_gh(\"appliedepi/epirhandbook\")",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Suggested packages</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.html",
    "href": "new_pages/r_projects.html",
    "title": "5  R projects",
    "section": "",
    "text": "5.1 Suggested use\nA common, efficient, and trouble-free way to use R is to combine these 3 elements. One discrete work project is hosted within one R project. Each element is described in the sections below.",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>R projects</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.html#suggested-use",
    "href": "new_pages/r_projects.html#suggested-use",
    "title": "5  R projects",
    "section": "",
    "text": "An R project\n\nA self-contained working environment with folders for data, scripts, outputs, etc.\n\n\nThe here package for relative filepaths\n\nFilepaths are written relative to the root folder of the R project - see Import and export for more information\n\n\nThe rio package for importing/exporting\n\nimport() and export() handle any file type by by its extension (e.g. .csv, .xlsx, .png)",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>R projects</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.html#creating-an-r-project",
    "href": "new_pages/r_projects.html#creating-an-r-project",
    "title": "5  R projects",
    "section": "5.2 Creating an R project",
    "text": "5.2 Creating an R project\nTo create an R project, select “New Project” from the File menu.\n\nIf you want to create a new folder for the project, select “New directory” and indicate where you want it to be created.\n\nIf you want to create the project within an existing folder, click “Existing directory” and indicate the folder.\n\nIf you want to clone a Github repository, select the third option “Version Control” and then “Git”. See the page on Version control and collaboration with Git and Github for further details.\n\n\n\n\n\n\n\n\n\n\nThe R project you create will come in the form of a folder containing a .Rproj file. This file is a shortcut and likely the primary way you will open your project. You can also open a project by selecting “Open Project” from the File menu. Alternatively on the far upper right side of RStudio you will see an R project icon and a drop-down menu of available R projects.\nTo exit from an R project, either open a new project, or close the project (File - Close Project).\n\nSwitch projects\nTo switch between projects, click the R project icon and drop-down menu at the very top-right of RStudio. You will see options to Close Project, Open Project, and a list of recent projects.\n\n\n\n\n\n\n\n\n\n\n\nSettings\nIt is generally advised that you start RStudio each time with a “clean slate” - that is, with your workspace not preserved from your previous session. This will mean that your objects and results will not persist session-to-session (you must re-create them by running your scripts). This is good, because it will force you to write better scripts and avoid errors in the long run.\nTo set RStudio to have a “clean slate” each time at start-up:\n\nSelect “Project Options” from the Tools menu.\n\nIn the “General” tab, set RStudio to not restore .RData into workspace at startup, and to not save workspace to .RData on exit.\n\n\n\nOrganization\nIt is common to have subfolders in your project. Consider having folders such as “data”, “scripts”, “figures”, “presentations”. You can add folders in the typical way you would add a new folder for your computer. Alternatively, see the page on Directory interactions to learn how to create new folders with R commands.\n\n\nVersion control\nConsider a version control system. It could be something as simple as having dates on the names of scripts (e.g. “transmission_analysis_2020-10-03.R”) and an “archive” folder. Consider also having commented header text at the top of each script with a description, tags, authors, and change log.\nA more complicated method would involve using Github or a similar platform for version control. See the page on Version control and collaboration with Git and Github.\nOne tip is that you can search across an entire project or folder using the “Find in Files” tool (Edit menu). It can search and even replace strings across multiple files.",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>R projects</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.html#examples",
    "href": "new_pages/r_projects.html#examples",
    "title": "5  R projects",
    "section": "5.3 Examples",
    "text": "5.3 Examples\nBelow are some examples of import/export/saving using here() from within an R projct. Read more about using the here package in the Import and export page.\nImporting linelist_raw.xlsx from the “data” folder in your R project\n\nlinelist &lt;- import(here(\"data\", \"linelist_raw.xlsx\"))\n\nExporting the R object linelist as “my_linelist.rds” to the “clean” folder within the “data” folder in your R project.\n\nexport(linelist, here(\"data\",\"clean\", \"my_linelist.rds\"))\n\nSaving the most recently printed plot as “epicurve_2021-02-15.png” within the “epicurves” folder in “outputs” folder in your R project.\n\nggsave(here(\"outputs\", \"epicurves\", \"epicurve_2021-02-15.png\"))",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>R projects</span>"
    ]
  },
  {
    "objectID": "new_pages/r_projects.html#resources",
    "href": "new_pages/r_projects.html#resources",
    "title": "5  R projects",
    "section": "5.4 Resources",
    "text": "5.4 Resources\nRStudio webpage on using R projects",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>R projects</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html",
    "href": "new_pages/importing.html",
    "title": "6  Import and export",
    "section": "",
    "text": "6.1 Overview\nWhen you import a “dataset” into R, you are generally creating a new data frame object in your R environment and defining it as an imported file (e.g. Excel, CSV, TSV, RDS) that is located in your folder directories at a certain file path/address.\nYou can import/export many types of files, including those created by other statistical programs (SAS, STATA, SPSS). You can also connect to relational databases.\nR even has its own data formats:",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#overview",
    "href": "new_pages/importing.html#overview",
    "title": "6  Import and export",
    "section": "",
    "text": "An RDS file (.rds) stores a single R object such as a data frame. These are useful to store cleaned data, as they maintain R column classes. Read more in this section.\n\nAn RData file (.Rdata) can be used to store multiple objects, or even a complete R workspace. Read more in this section.",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#the-rio-package",
    "href": "new_pages/importing.html#the-rio-package",
    "title": "6  Import and export",
    "section": "6.2 The rio package",
    "text": "6.2 The rio package\nThe R package we recommend is: rio. The name “rio” is an abbreviation of “R I/O” (input/output).\nIts functions import() and export() can handle many different file types (e.g. .xlsx, .csv, .rds, .tsv). When you provide a file path to either of these functions (including the file extension like “.csv”), rio will read the extension and use the correct tool to import or export the file.\nThe alternative to using rio is to use functions from many other packages, each of which is specific to a type of file. For example, read.csv() (base R), read.xlsx() (openxlsx package), and write_csv() (readr pacakge), etc. These alternatives can be difficult to remember, whereas using import() and export() from rio is easy.\nrio’s functions import() and export() use the appropriate package and function for a given file, based on its file extension. See the end of this page for a complete table of which packages/functions rio uses in the background. It can also be used to import STATA, SAS, and SPSS files, among dozens of other file types.\nImport/export of shapefiles requires other packages, as detailed in the page on GIS basics.",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#here",
    "href": "new_pages/importing.html#here",
    "title": "6  Import and export",
    "section": "6.3 The here package",
    "text": "6.3 The here package\nThe package here and its function here() make it easy to tell R where to find and to save your files - in essence, it builds file paths.\nUsed in conjunction with an R project, here allows you to describe the location of files in your R project in relation to the R project’s root directory (the top-level folder). This is useful when the R project may be shared or accessed by multiple people/computers. It prevents complications due to the unique file paths on different computers (e.g. \"C:/Users/Laura/Documents...\" by “starting” the file path in a place common to all users (the R project root).\nThis is how here() works within an R project:\n\nWhen the here package is first loaded within the R project, it places a small file called “.here” in the root folder of your R project as a “benchmark” or “anchor”\n\nIn your scripts, to reference a file in the R project’s sub-folders, you use the function here() to build the file path in relation to that anchor\nTo build the file path, write the names of folders beyond the root, within quotes, separated by commas, finally ending with the file name and file extension as shown below\n\nhere() file paths can be used for both importing and exporting\n\nFor example, below, the function import() is being provided a file path constructed with here().\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\n\nThe command here(\"data\", \"linelists\", \"ebola_linelist.xlsx\") is actually providing the full file path that is unique to the user’s computer:\n\"C:/Users/Laura/Documents/my_R_project/data/linelists/ebola_linelist.xlsx\"\nThe beauty is that the R command using here() can be successfully run on any computer accessing the R project.\nTIP: If you are unsure where the “.here” root is set to, run the function here() with empty parentheses.\nRead more about the here package at this link.",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#file-paths",
    "href": "new_pages/importing.html#file-paths",
    "title": "6  Import and export",
    "section": "6.4 File paths",
    "text": "6.4 File paths\nWhen importing or exporting data, you must provide a file path. You can do this one of three ways:\n\nRecommended: provide a “relative” file path with the here package\n\nProvide the “full” / “absolute” file path\n\nManual file selection\n\n\n“Relative” file paths\nIn R, “relative” file paths consist of the file path relative to the root of an R project. They allow for more simple file paths that can work on different computers (e.g. if the R project is on a shared drive or is sent by email). As described above, relative file paths are facilitated by use of the here package.\nAn example of a relative file path constructed with here() is below. We assume the work is in an R project that contains a sub-folder “data” and within that a subfolder “linelists”, in which there is the .xlsx file of interest.\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\n\n\n\n“Absolute” file paths\nAbsolute or “full” file paths can be provided to functions like import() but they are “fragile” as they are unique to the user’s specific computer and therefore not recommended.\nBelow is an example of an absolute file path, where in Laura’s computer there is a folder “analysis”, a sub-folder “data” and within that a sub-folder “linelists”, in which there is the .xlsx file of interest.\n\nlinelist &lt;- import(\"C:/Users/Laura/Documents/analysis/data/linelists/ebola_linelist.xlsx\")\n\nA few things to note about absolute file paths:\n\nAvoid using absolute file paths as they will break if the script is run on a different computer\nUse forward slashes (/), as in the example above (note: this is NOT the default for Windows file paths)\n\nFile paths that begin with double slashes (e.g. “//…”) will likely not be recognized by R and will produce an error. Consider moving your work to a “named” or “lettered” drive that begins with a letter (e.g. “J:” or “C:”). See the page on Directory interactions for more details on this issue.\n\nOne scenario where absolute file paths may be appropriate is when you want to import a file from a shared drive that has the same full file path for all users.\nTIP: To quickly convert all \\ to /, highlight the code of interest, use Ctrl+f (in Windows), check the option box for “In selection”, and then use the replace functionality to convert them.\n\n\n\nSelect file manually\nYou can import data manually via one of these methods:\n\nEnvironment RStudio Pane, click “Import Dataset”, and select the type of data\nClick File / Import Dataset / (select the type of data)\n\nTo hard-code manual selection, use the base R command file.choose() (leaving the parentheses empty) to trigger appearance of a pop-up window that allows the user to manually select the file from their computer. For example:\n\n\n# Manual selection of a file. When this command is run, a POP-UP window will appear. \n# The file path selected will be supplied to the import() command.\n\nmy_data &lt;- import(file.choose())\n\nTIP: The pop-up window may appear BEHIND your RStudio window.",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#import-data",
    "href": "new_pages/importing.html#import-data",
    "title": "6  Import and export",
    "section": "6.5 Import data",
    "text": "6.5 Import data\nTo use import() to import a dataset is quite simple. Simply provide the path to the file (including the file name and file extension) in quotes. If using here() to build the file path, follow the instructions above. Below are a few examples:\nImporting a csv file that is located in your “working directory” or in the R project root folder:\n\nlinelist &lt;- import(\"linelist_cleaned.csv\")\n\nImporting the first sheet of an Excel workbook that is located in “data” and “linelists” sub-folders of the R project (the file path built using here()):\n\nlinelist &lt;- import(here(\"data\", \"linelists\", \"linelist_cleaned.xlsx\"))\n\nImporting a data frame (a .rds file) using an absolute file path:\n\nlinelist &lt;- import(\"C:/Users/Laura/Documents/tuberculosis/data/linelists/linelist_cleaned.rds\")\n\n\nSpecific Excel sheets\nBy default, if you provide an Excel workbook (.xlsx) to import(), the workbook’s first sheet will be imported. If you want to import a specific sheet, include the sheet name to the which = argument. For example:\n\nmy_data &lt;- import(\"my_excel_file.xlsx\", which = \"Sheetname\")\n\nIf using the here() method to provide a relative pathway to import(), you can still indicate a specific sheet by adding the which = argument after the closing parentheses of the here() function.\n\n# Demonstration: importing a specific Excel sheet when using relative pathways with the 'here' package\nlinelist_raw &lt;- import(here(\"data\", \"linelist.xlsx\"), which = \"Sheet1\")`  \n\nTo export a data frame from R to a specific Excel sheet and have the rest of the Excel workbook remain unchanged, you will have to import, edit, and export with an alternative package catered to this purpose such as openxlsx. See more information in the page on Directory interactions or at this github page.\nIf your Excel workbook is .xlsb (binary format Excel workbook) you may not be able to import it using rio. Consider re-saving it as .xlsx, or using a package like readxlsb which is built for this purpose.\n\n\n\nMissing values\nYou may want to designate which value(s) in your dataset should be considered as missing. As explained in the page on Missing data, the value in R for missing data is NA, but perhaps the dataset you want to import uses 99, “Missing”, or just empty character space “” instead.\nUse the na = argument for import() and provide the value(s) within quotes (even if they are numbers). You can specify multiple values by including them within a vector, using c() as shown below.\nHere, the value “99” in the imported dataset is considered missing and converted to NA in R.\n\nlinelist &lt;- import(here(\"data\", \"my_linelist.xlsx\"), na = \"99\")\n\nHere, any of the values “Missing”, “” (empty cell), or ” ” (single space) in the imported dataset are converted to NA in R.\n\nlinelist &lt;- import(here(\"data\", \"my_linelist.csv\"), na = c(\"Missing\", \"\", \" \"))\n\n\n\n\nSkip rows\nSometimes, you may want to avoid importing a row of data. You can do this with the argument skip = if using import() from rio on a .xlsx or .csv file. Provide the number of rows you want to skip.\n\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\", skip = 1)  # does not import header row\n\nUnfortunately skip = only accepts one integer value, not a range (e.g. “2:10” does not work). To skip import of specific rows that are not consecutive from the top, consider importing multiple times and using bind_rows() from dplyr. See the example below of skipping only row 2.\n\n\nManage a second header row\nSometimes, your data may have a second row, for example if it is a “data dictionary” row as shown below. This situation can be problematic because it can result in all columns being imported as class “character”.\nBelow is an example of this kind of dataset (with the first row being the data dictionary).\n\n\n\n\n\n\n\nRemove the second header row\nTo drop the second header row, you will likely need to import the data twice.\n\nImport the data in order to store the correct column names\n\nImport the data again, skipping the first two rows (header and second rows)\n\nBind the correct names onto the reduced dataframe\n\nThe exact argument used to bind the correct column names depends on the type of data file (.csv, .tsv, .xlsx, etc.). This is because rio is using a different function for the different file types (see table above).\nFor Excel files: (col_names =)\n\n# import first time; store the column names\nlinelist_raw_names &lt;- import(\"linelist_raw.xlsx\") %&gt;% names()  # save true column names\n\n# import second time; skip row 2, and assign column names to argument col_names =\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\",\n                       skip = 2,\n                       col_names = linelist_raw_names\n                       ) \n\nFor CSV files: (col.names =)\n\n# import first time; sotre column names\nlinelist_raw_names &lt;- import(\"linelist_raw.csv\") %&gt;% names() # save true column names\n\n# note argument for csv files is 'col.names = '\nlinelist_raw &lt;- import(\"linelist_raw.csv\",\n                       skip = 2,\n                       col.names = linelist_raw_names\n                       ) \n\nBackup option - changing column names as a separate command\n\n# assign/overwrite headers using the base 'colnames()' function\ncolnames(linelist_raw) &lt;- linelist_raw_names\n\n\n\nMake a data dictionary\nBonus! If you do have a second row that is a data dictionary, you can easily create a proper data dictionary from it. This tip is adapted from this post.\n\ndict &lt;- linelist_2headers %&gt;%             # begin: linelist with dictionary as first row\n  head(1) %&gt;%                             # keep only column names and first dictionary row                \n  pivot_longer(cols = everything(),       # pivot all columns to long format\n               names_to = \"Column\",       # assign new column names\n               values_to = \"Description\")\n\n\n\n\n\n\n\n\n\nCombine the two header rows\nIn some cases when your raw dataset has two header rows (or more specifically, the 2nd row of data is a secondary header), you may want to “combine” them or add the values in the second header row into the first header row.\nThe command below will define the data frame’s column names as the combination (pasting together) of the first (true) headers with the value immediately underneath (in the first row).\n\nnames(my_data) &lt;- paste(names(my_data), my_data[1, ], sep = \"_\")\n\n\n\n\n\nGoogle sheets\nYou can import data from an online Google spreadsheet with the googlesheet4 package and by authenticating your access to the spreadsheet.\n\npacman::p_load(\"googlesheets4\")\n\nBelow, a demo Google sheet is imported and saved. This command may prompt confirmation of authentification of your Google account. Follow prompts and pop-ups in your internet browser to grant Tidyverse API packages permissions to edit, create, and delete your spreadsheets in Google Drive.\nThe sheet below is “viewable for anyone with the link” and you can try to import it.\n\nGsheets_demo &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY/edit#gid=0\")\n\nThe sheet can also be imported using only the sheet ID, a shorter part of the URL:\n\nGsheets_demo &lt;- read_sheet(\"1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY\")\n\nAnother package, googledrive offers useful functions for writing, editing, and deleting Google sheets. For example, using the gs4_create() and sheet_write() functions found in this package.\nHere are some other helpful online tutorials:\nbasic Google sheets importing tutorial\nmore detailed tutorial\ninteraction between the googlesheets4 and tidyverse",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#multiple-files---import-export-split-combine",
    "href": "new_pages/importing.html#multiple-files---import-export-split-combine",
    "title": "6  Import and export",
    "section": "6.6 Multiple files - import, export, split, combine",
    "text": "6.6 Multiple files - import, export, split, combine\nSee the page on Iteration, loops, and lists for examples of how to import and combine multiple files, or multiple Excel workbook files. That page also has examples on how to split a data frame into parts and export each one separately, or as named sheets in an Excel workbook.",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#import_github",
    "href": "new_pages/importing.html#import_github",
    "title": "6  Import and export",
    "section": "6.7 Import from Github",
    "text": "6.7 Import from Github\nImporting data directly from Github into R can be very easy or can require a few steps - depending on the file type. Below are some approaches:\n\nCSV files\nIt can be easy to import a .csv file directly from Github into R with an R command.\n\nGo to the Github repo, locate the file of interest, and click on it\n\nClick on the “Raw” button (you will then see the “raw” csv data, as shown below)\n\nCopy the URL (web address)\n\nPlace the URL in quotes within the import() R command\n\n\n\n\n\n\n\n\n\n\n\n\nXLSX files\nYou may not be able to view the “Raw” data for some files (e.g. .xlsx, .rds, .nwk, .shp)\n\nGo to the Github repo, locate the file of interest, and click on it\n\nClick the “Download” button, as shown below\n\nSave the file on your computer, and import it into R\n\n\n\n\n\n\n\n\n\n\n\n\nShapefiles\nShapefiles have many sub-component files, each with a different file extention. One file will have the “.shp” extension, but others may have “.dbf”, “.prj”, etc. To download a shapefile from Github, you will need to download each of the sub-component files individually, and save them in the same folder on your computer. In Github, click on each file individually and download them by clicking on the “Download” button.\nOnce saved to your computer you can import the shapefile as shown in the GIS basics page using st_read() from the sf package. You only need to provide the filepath and name of the “.shp” file - as long as the other related files are within the same folder on your computer.\nBelow, you can see how the shapefile “sle_adm3” consists of many files - each of which must be downloaded from Github.",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#manual-data-entry",
    "href": "new_pages/importing.html#manual-data-entry",
    "title": "6  Import and export",
    "section": "6.8 Manual data entry",
    "text": "6.8 Manual data entry\n\nEntry by rows\nUse the tribble function from the tibble package from the tidyverse (online tibble reference).\nNote how column headers start with a tilde (~). Also note that each column must contain only one class of data (character, numeric, etc.). You can use tabs, spacing, and new rows to make the data entry more intuitive and readable. Spaces do not matter between values, but each row is represented by a new line of code. For example:\n\n# create the dataset manually by row\nmanual_entry_rows &lt;- tibble::tribble(\n  ~colA, ~colB,\n  \"a\",   1,\n  \"b\",   2,\n  \"c\",   3\n  )\n\nAnd now we display the new dataset:\n\n\n\n\n\n\n\n\nEntry by columns\nSince a data frame consists of vectors (vertical columns), the base approach to manual dataframe creation in R expects you to define each column and then bind them together. This can be counter-intuitive in epidemiology, as we usually think about our data in rows (as above).\n\n# define each vector (vertical column) separately, each with its own name\nPatientID &lt;- c(235, 452, 778, 111)\nTreatment &lt;- c(\"Yes\", \"No\", \"Yes\", \"Yes\")\nDeath     &lt;- c(1, 0, 1, 0)\n\nCAUTION: All vectors must be the same length (same number of values).\nThe vectors can then be bound together using the function data.frame():\n\n# combine the columns into a data frame, by referencing the vector names\nmanual_entry_cols &lt;- data.frame(PatientID, Treatment, Death)\n\nAnd now we display the new dataset:\n\n\n\n\n\n\n\n\nPasting from clipboard\nIf you copy data from elsewhere and have it on your clipboard, you can try one of the two ways below:\nFrom the clipr package, you can use read_clip_tbl() to import as a data frame, or just just read_clip() to import as a character vector. In both cases, leave the parentheses empty.\n\nlinelist &lt;- clipr::read_clip_tbl()  # imports current clipboard as data frame\nlinelist &lt;- clipr::read_clip()      # imports as character vector\n\nYou can also easily export to your system’s clipboard with clipr. See the section below on Export.\nAlternatively, you can use the the read.table() function from base R with file = \"clipboard\") to import as a data frame:\n\ndf_from_clipboard &lt;- read.table(\n  file = \"clipboard\",  # specify this as \"clipboard\"\n  sep = \"t\",           # separator could be tab, or commas, etc.\n  header=TRUE)         # if there is a header row",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#import-most-recent-file",
    "href": "new_pages/importing.html#import-most-recent-file",
    "title": "6  Import and export",
    "section": "6.9 Import most recent file",
    "text": "6.9 Import most recent file\nOften you may receive daily updates to your datasets. In this case you will want to write code that imports the most recent file. Below we present two ways to approach this:\n\nSelecting the file based on the date in the file name\n\nSelecting the file based on file metadata (last modification)\n\n\nDates in file name\nThis approach depends on three premises:\n\nYou trust the dates in the file names\n\nThe dates are numeric and appear in generally the same format (e.g. year then month then day)\n\nThere are no other numbers in the file name\n\nWe will explain each step, and then show you them combined at the end.\nFirst, use dir() from base R to extract just the file names for each file in the folder of interest. See the page on Directory interactions for more details about dir(). In this example, the folder of interest is the folder “linelists” within the folder “example” within “data” within the R project.\n\nlinelist_filenames &lt;- dir(here(\"data\", \"example\", \"linelists\")) # get file names from folder\nlinelist_filenames                                              # print\n\n[1] \"20201007linelist.csv\"          \"case_linelist_2020-10-02.csv\" \n[3] \"case_linelist_2020-10-03.csv\"  \"case_linelist_2020-10-04.csv\" \n[5] \"case_linelist_2020-10-05.csv\"  \"case_linelist_2020-10-08.xlsx\"\n[7] \"case_linelist20201006.csv\"    \n\n\nOnce you have this vector of names, you can extract the dates from them by applying str_extract() from stringr using this regular expression. It extracts any numbers in the file name (including any other characters in the middle such as dashes or slashes). You can read more about stringr in the Strings and characters page.\n\nlinelist_dates_raw &lt;- stringr::str_extract(linelist_filenames, \"[0-9].*[0-9]\") # extract numbers and any characters in between\nlinelist_dates_raw  # print\n\n[1] \"20201007\"   \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\"\n[6] \"2020-10-08\" \"20201006\"  \n\n\nAssuming the dates are written in generally the same date format (e.g. Year then Month then Day) and the years are 4-digits, you can use lubridate’s flexible conversion functions (ymd(), dmy(), or mdy()) to convert them to dates. For these functions, the dashes, spaces, or slashes do not matter, only the order of the numbers. Read more in the Working with dates page.\n\nlinelist_dates_clean &lt;- lubridate::ymd(linelist_dates_raw)\nlinelist_dates_clean\n\n[1] \"2020-10-07\" \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\"\n[6] \"2020-10-08\" \"2020-10-06\"\n\n\nThe base R function which.max() can then be used to return the index position (e.g. 1st, 2nd, 3rd, …) of the maximum date value. The latest file is correctly identified as the 6th file - “case_linelist_2020-10-08.xlsx”.\n\nindex_latest_file &lt;- which.max(linelist_dates_clean)\nindex_latest_file\n\n[1] 6\n\n\nIf we condense all these commands, the complete code could look like below. Note that the . in the last line is a placeholder for the piped object at that point in the pipe sequence. At that point the value is simply the number 6. This is placed in double brackets to extract the 6th element of the vector of file names produced by dir().\n\n# load packages\npacman::p_load(\n  tidyverse,         # data management\n  stringr,           # work with strings/characters\n  lubridate,         # work with dates\n  rio,               # import / export\n  here,              # relative file paths\n  fs)                # directory interactions\n\n# extract the file name of latest file\nlatest_file &lt;- dir(here(\"data\", \"example\", \"linelists\")) %&gt;%  # file names from \"linelists\" sub-folder          \n  str_extract(\"[0-9].*[0-9]\") %&gt;%                  # pull out dates (numbers)\n  ymd() %&gt;%                                        # convert numbers to dates (assuming year-month-day format)\n  which.max() %&gt;%                                  # get index of max date (latest file)\n  dir(here(\"data\", \"example\", \"linelists\"))[[.]]              # return the filename of latest linelist\n\nlatest_file  # print name of latest file\n\n[1] \"case_linelist_2020-10-08.xlsx\"\n\n\nYou can now use this name to finish the relative file path, with here():\n\nhere(\"data\", \"example\", \"linelists\", latest_file) \n\nAnd you can now import the latest file:\n\n# import\nimport(here(\"data\", \"example\", \"linelists\", latest_file)) # import \n\n\n\nUse the file info\nIf your files do not have dates in their names (or you do not trust those dates), you can try to extract the last modification date from the file metadata. Use functions from the package fs to examine the metadata information for each file, which includes the last modification time and the file path.\nBelow, we provide the folder of interest to fs’s dir_info(). In this case, the folder of interest is in the R project in the folder “data”, the sub-folder “example”, and its sub-folder “linelists”. The result is a data frame with one line per file and columns for modification_time, path, etc. You can see a visual example of this in the page on Directory interactions.\nWe can sort this data frame of files by the column modification_time, and then keep only the top/latest row (file) with base R’s head(). Then we can extract the file path of this latest file only with the dplyr function pull() on the column path. Finally we can pass this file path to import(). The imported file is saved as latest_file.\n\nlatest_file &lt;- dir_info(here(\"data\", \"example\", \"linelists\")) %&gt;%  # collect file info on all files in directory\n  arrange(desc(modification_time)) %&gt;%      # sort by modification time\n  head(1) %&gt;%                               # keep only the top (latest) file\n  pull(path) %&gt;%                            # extract only the file path\n  import()                                  # import the file",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#import_api",
    "href": "new_pages/importing.html#import_api",
    "title": "6  Import and export",
    "section": "6.10 APIs",
    "text": "6.10 APIs\nAn “Automated Programming Interface” (API) can be used to directly request data from a website. APIs are a set of rules that allow one software application to interact with another. The client (you) sends a “request” and receives a “response” containing content. The R packages httr and jsonlite can facilitate this process.\nEach API-enabled website will have its own documentation and specifics to become familiar with. Some sites are publicly available and can be accessed by anyone. Others, such as platforms with user IDs and credentials, require authentication to access their data.\nNeedless to say, it is necessary to have an internet connection to import data via API. We will briefly give examples of use of APIs to import data, and link you to further resources.\nNote: recall that data may be posted* on a website without an API, which may be easier to retrieve. For example a posted CSV file may be accessible simply by providing the site URL to import() as described in the section on importing from Github.*\n\nHTTP request\nThe API exchange is most commonly done through an HTTP request. HTTP is Hypertext Transfer Protocol, and is the underlying format of a request/response between a client and a server. The exact input and output may vary depending on the type of API but the process is the same - a “Request” (often HTTP Request) from the user, often containing a query, followed by a “Response”, containing status information about the request and possibly the requested content.\nHere are a few components of an HTTP request:\n\nThe URL of the API endpoint\n\nThe “Method” (or “Verb”)\n\nHeaders\n\nBody\n\nThe HTTP request “method” is the action your want to perform. The two most common HTTP methods are GET and POST but others could include PUT, DELETE, PATCH, etc. When importing data into R it is most likely that you will use GET.\nAfter your request, your computer will receive a “response” in a format similar to what you sent, including URL, HTTP status (Status 200 is what you want!), file type, size, and the desired content. You will then need to parse this response and turn it into a workable data frame within your R environment.\n\n\nPackages\nThe httr package works well for handling HTTP requests in R. It requires little prior knowledge of Web APIs and can be used by people less familiar with software development terminology. In addition, if the HTTP response is .json, you can use jsonlite to parse the response.\n\n# load packages\npacman::p_load(httr, jsonlite, tidyverse)\n\n\n\nPublicly-available data\nBelow is an example of an HTTP request, borrowed from a tutorial from the Trafford Data Lab. This site has several other resources to learn and API exercises.\nScenario: We want to import a list of fast food outlets in the city of Trafford, UK. The data can be accessed from the API of the Food Standards Agency, which provides food hygiene rating data for the United Kingdom.\nHere are the parameters for our request:\n\nHTTP verb: GET\n\nAPI endpoint URL: http://api.ratings.food.gov.uk/Establishments\n\nSelected parameters: name, address, longitude, latitude, businessTypeId, ratingKey, localAuthorityId\n\nHeaders: “x-api-version”, 2\n\nData format(s): JSON, XML\n\nDocumentation: http://api.ratings.food.gov.uk/help\n\nThe R code would be as follows:\n\n# prepare the request\npath &lt;- \"http://api.ratings.food.gov.uk/Establishments\"\nrequest &lt;- GET(url = path,\n             query = list(\n               localAuthorityId = 188,\n               BusinessTypeId = 7844,\n               pageNumber = 1,\n               pageSize = 5000),\n             add_headers(\"x-api-version\" = \"2\"))\n\n# check for any server error (\"200\" is good!)\nrequest$status_code\n\n# submit the request, parse the response, and convert to a data frame\nresponse &lt;- content(request, as = \"text\", encoding = \"UTF-8\") %&gt;%\n  fromJSON(flatten = TRUE) %&gt;%\n  pluck(\"establishments\") %&gt;%\n  as_tibble()\n\nYou can now clean and use the response data frame, which contains one row per fast food facility.\n\n\nAuthentication required\nSome APIs require authentication - for you to prove who you are, so you can access restricted data. To import these data, you may need to first use a POST method to provide a username, password, or code. This will return an access token, that can be used for subsequent GET method requests to retrieve the desired data.\nBelow is an example of querying data from Go.Data, which is an outbreak investigation tool. Go.Data uses an API for all interactions between the web front-end and smartphone applications used for data collection. Go.Data is used throughout the world. Because outbreak data are sensitive and you should only be able to access data for your outbreak, authentication is required.\nBelow is some sample R code using httr and jsonlite for connecting to the Go.Data API to import data on contact follow-up from your outbreak.\n\n# set credentials for authorization\nurl &lt;- \"https://godatasampleURL.int/\"           # valid Go.Data instance url\nusername &lt;- \"username\"                          # valid Go.Data username \npassword &lt;- \"password\"                          # valid Go,Data password \noutbreak_id &lt;- \"xxxxxx-xxxx-xxxx-xxxx-xxxxxxx\"  # valid Go.Data outbreak ID\n\n# get access token\nurl_request &lt;- paste0(url,\"api/oauth/token?access_token=123\") # define base URL request\n\n# prepare request\nresponse &lt;- POST(\n  url = url_request,  \n  body = list(\n    username = username,    # use saved username/password from above to authorize                               \n    password = password),                                       \n    encode = \"json\")\n\n# execute request and parse response\ncontent &lt;-\n  content(response, as = \"text\") %&gt;%\n  fromJSON(flatten = TRUE) %&gt;%          # flatten nested JSON\n  glimpse()\n\n# Save access token from response\naccess_token &lt;- content$access_token    # save access token to allow subsequent API calls below\n\n# import outbreak contacts\n# Use the access token \nresponse_contacts &lt;- GET(\n  paste0(url,\"api/outbreaks/\",outbreak_id,\"/contacts\"),          # GET request\n  add_headers(\n    Authorization = paste(\"Bearer\", access_token, sep = \" \")))\n\njson_contacts &lt;- content(response_contacts, as = \"text\")         # convert to text JSON\n\ncontacts &lt;- as_tibble(fromJSON(json_contacts, flatten = TRUE))   # flatten JSON to tibble\n\nCAUTION: If you are importing large amounts of data from an API requiring authentication, it may time-out. To avoid this, retrieve access_token again before each API GET request and try using filters or limits in the query. \nTIP: The fromJSON() function in the jsonlite package does not fully un-nest the first time it’s executed, so you will likely still have list items in your resulting tibble. You will need to further un-nest for certain variables; depending on how nested your .json is. To view more info on this, view the documentation for the jsonlite package, such as the flatten() function. \nFor more details, View documentation on LoopBack Explorer, the Contact Tracing page or API tips on Go.Data Github repository\nYou can read more about the httr package here\nThis section was also informed by this tutorial and this tutorial.",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#export",
    "href": "new_pages/importing.html#export",
    "title": "6  Import and export",
    "section": "6.11 Export",
    "text": "6.11 Export\n\nWith rio package\nWith rio, you can use the export() function in a very similar way to import(). First give the name of the R object you want to save (e.g. linelist) and then in quotes put the file path where you want to save the file, including the desired file name and file extension. For example:\nThis saves the data frame linelist as an Excel workbook to the working directory/R project root folder:\n\nexport(linelist, \"my_linelist.xlsx\") # will save to working directory\n\nYou could save the same data frame as a csv file by changing the extension. For example, we also save it to a file path constructed with here():\n\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.csv\"))\n\n\n\nTo clipboard\nTo export a data frame to your computer’s “clipboard” (to then paste into another software like Excel, Google Spreadsheets, etc.) you can use write_clip() from the clipr package.\n\n# export the linelist data frame to your system's clipboard\nclipr::write_clip(linelist)",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#import_rds",
    "href": "new_pages/importing.html#import_rds",
    "title": "6  Import and export",
    "section": "6.12 RDS files",
    "text": "6.12 RDS files\nAlong with .csv, .xlsx, etc, you can also export/save R data frames as .rds files. This is a file format specific to R, and is very useful if you know you will work with the exported data again in R.\nThe classes of columns are stored, so you don’t have do to cleaning again when it is imported (with an Excel or even a CSV file this can be a headache!). It is also a smaller file, which is useful for export and import if your dataset is large.\nFor example, if you work in an Epidemiology team and need to send files to a GIS team for mapping, and they use R as well, just send them the .rds file! Then all the column classes are retained and they have less work to do.\n\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.rds\"))",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#import_rdata",
    "href": "new_pages/importing.html#import_rdata",
    "title": "6  Import and export",
    "section": "6.13 Rdata files and lists",
    "text": "6.13 Rdata files and lists\n.Rdata files can store multiple R objects - for example multiple data frames, model results, lists, etc. This can be very useful to consolidate or share a lot of your data for a given project.\nIn the below example, multiple R objects are stored within the exported file “my_objects.Rdata”:\n\nrio::export(my_list, my_dataframe, my_vector, \"my_objects.Rdata\")\n\nNote: if you are trying to import a list, use import_list() from rio to import it with the complete original structure and contents.\n\nrio::import_list(\"my_list.Rdata\")",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#saving-plots",
    "href": "new_pages/importing.html#saving-plots",
    "title": "6  Import and export",
    "section": "6.14 Saving plots",
    "text": "6.14 Saving plots\nInstructions on how to save plots, such as those created by ggplot(), are discussed in depth in the ggplot basics page.\nIn brief, run ggsave(\"my_plot_filepath_and_name.png\") after printing your plot. You can either provide a saved plot object to the plot = argument, or only specify the destination file path (with file extension) to save the most recently-displayed plot. You can also control the width =, height =, units =, and dpi =.\nHow to save a network graph, such as a transmission tree, is addressed in the page on Transmission chains.",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/importing.html#resources",
    "href": "new_pages/importing.html#resources",
    "title": "6  Import and export",
    "section": "6.15 Resources",
    "text": "6.15 Resources\nThe R Data Import/Export Manual\nR 4 Data Science chapter on data import\nggsave() documentation\nBelow is a table, taken from the rio online vignette. For each type of data it shows: the expected file extension, the package rio uses to import or export the data, and whether this functionality is included in the default installed version of rio.\n\n\n\n\n\n\n\n\n\n\nFormat\nTypical Extension\nImport Package\nExport Package\nInstalled by Default\n\n\n\n\nComma-separated data\n.csv\ndata.table fread()\ndata.table\nYes\n\n\nPipe-separated data\n.psv\ndata.table fread()\ndata.table\nYes\n\n\nTab-separated data\n.tsv\ndata.table fread()\ndata.table\nYes\n\n\nSAS\n.sas7bdat\nhaven\nhaven\nYes\n\n\nSPSS\n.sav\nhaven\nhaven\nYes\n\n\nStata\n.dta\nhaven\nhaven\nYes\n\n\nSAS\nXPORT\n.xpt\nhaven\nhaven\n\n\nSPSS Portable\n.por\nhaven\n\nYes\n\n\nExcel\n.xls\nreadxl\n\nYes\n\n\nExcel\n.xlsx\nreadxl\nopenxlsx\nYes\n\n\nR syntax\n.R\nbase\nbase\nYes\n\n\nSaved R objects\n.RData, .rda\nbase\nbase\nYes\n\n\nSerialized R objects\n.rds\nbase\nbase\nYes\n\n\nEpiinfo\n.rec\nforeign\n\nYes\n\n\nMinitab\n.mtp\nforeign\n\nYes\n\n\nSystat\n.syd\nforeign\n\nYes\n\n\n“XBASE”\ndatabase files\n.dbf\nforeign\nforeign\n\n\nWeka Attribute-Relation File Format\n.arff\nforeign\nforeign\nYes\n\n\nData Interchange Format\n.dif\nutils\n\nYes\n\n\nFortran data\nno recognized extension\nutils\n\nYes\n\n\nFixed-width format data\n.fwf\nutils\nutils\nYes\n\n\ngzip comma-separated data\n.csv.gz\nutils\nutils\nYes\n\n\nCSVY (CSV + YAML metadata header)\n.csvy\ncsvy\ncsvy\nNo\n\n\nEViews\n.wf1\nhexView\n\nNo\n\n\nFeather R/Python interchange format\n.feather\nfeather\nfeather\nNo\n\n\nFast Storage\n.fst\nfst\nfst\nNo\n\n\nJSON\n.json\njsonlite\njsonlite\nNo\n\n\nMatlab\n.mat\nrmatio\nrmatio\nNo\n\n\nOpenDocument Spreadsheet\n.ods\nreadODS\nreadODS\nNo\n\n\nHTML Tables\n.html\nxml2\nxml2\nNo\n\n\nShallow XML documents\n.xml\nxml2\nxml2\nNo\n\n\nYAML\n.yml\nyaml\nyaml\nNo\n\n\nClipboard default is tsv\n\nclipr\nclipr\nNo",
    "crumbs": [
      "Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Import and export</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html",
    "href": "new_pages/cleaning.html",
    "title": "7  Cleaning data and core functions",
    "section": "",
    "text": "Core functions\nThis handbook emphasizes use of the functions from the tidyverse family of R packages. The essential R functions demonstrated in this page are listed below.\nMany of these functions belong to the dplyr R package, which provides “verb” functions to solve data manipulation challenges (the name is a reference to a “data frame-plier. dplyr is part of the tidyverse family of R packages (which also includes ggplot2, tidyr, stringr, tibble, purrr, magrittr, and forcats among others).\nIf you want to see how these functions compare to Stata or SAS commands, see the page on Transition to R.\nYou may encounter an alternative data management framework from the data.table R package with operators like := and frequent use of brackets [ ]. This approach and syntax is briefly explained in the Data Table page.",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html#cleaning-pipeline",
    "href": "new_pages/cleaning.html#cleaning-pipeline",
    "title": "7  Cleaning data and core functions",
    "section": "7.1 Cleaning pipeline",
    "text": "7.1 Cleaning pipeline\nThis page proceeds through typical cleaning steps, adding them sequentially to a cleaning pipe chain.\nIn epidemiological analysis and data processing, cleaning steps are often performed sequentially, linked together. In R, this often manifests as a cleaning “pipeline”, where the raw dataset is passed or “piped” from one cleaning step to another.\nSuch chains utilize dplyr “verb” functions and the magrittr pipe operator %&gt;%. This pipe begins with the “raw” data (“linelist_raw.xlsx”) and ends with a “clean” R data frame (linelist) that can be used, saved, exported, etc.\nIn a cleaning pipeline the order of the steps is important. Cleaning steps might include:\n\nImporting of data\n\nColumn names cleaned or changed\n\nDe-duplication\n\nColumn creation and transformation (e.g. re-coding or standardising values)\n\nRows filtered or added",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html#load-packages",
    "href": "new_pages/cleaning.html#load-packages",
    "title": "7  Cleaning data and core functions",
    "section": "7.2 Load packages",
    "text": "7.2 Load packages\nThis code chunk shows the loading of packages required for the analyses. In this handbook we emphasize p_load() from pacman, which installs the package if necessary and loads it for use. You can also load installed packages with library() from base R. See the page on R basics for more information on R packages.\n\npacman::p_load(\n  rio,        # importing data  \n  here,       # relative file pathways  \n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  matchmaker, # dictionary-based cleaning\n  epikit,     # age_categories() function\n  tidyverse   # data management and visualization\n)",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html#import-data",
    "href": "new_pages/cleaning.html#import-data",
    "title": "7  Cleaning data and core functions",
    "section": "7.3 Import data",
    "text": "7.3 Import data\n\nImport\nHere we import the “raw” case linelist Excel file using the import() function from the package rio. The rio package flexibly handles many types of files (e.g. .xlsx, .csv, .tsv, .rds. See the page on Import and export for more information and tips on unusual situations (e.g. skipping rows, setting missing values, importing Google sheets, etc).\nIf you want to follow along, click to download the “raw” linelist (as .xlsx file).\nIf your dataset is large and takes a long time to import, it can be useful to have the import command be separate from the pipe chain and the “raw” saved as a distinct file. This also allows easy comparison between the original and cleaned versions.\nBelow we import the raw Excel file and save it as the data frame linelist_raw. We assume the file is located in your working directory or R project root, and so no sub-folders are specified in the file path.\n\nlinelist_raw &lt;- import(\"linelist_raw.xlsx\")\n\nYou can view the first 50 rows of the the data frame below. Note: the base R function head(n) allow you to view just the first n rows in the R console.\n\n\n\n\n\n\n\n\nReview\nYou can use the function skim() from the package skimr to get an overview of the entire dataframe (see page on Descriptive tables for more info). Columns are summarised by class/type such as character, numeric. Note: “POSIXct” is a type of raw date class (see Working with dates.\n\nskimr::skim(linelist_raw)\n\n\n\n\nData summary\n\n\nName\nlinelist_raw\n\n\nNumber of rows\n6611\n\n\nNumber of columns\n28\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n17\n\n\nnumeric\n8\n\n\nPOSIXct\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncase_id\n137\n0.98\n6\n6\n0\n5888\n0\n\n\ndate onset\n293\n0.96\n10\n10\n0\n580\n0\n\n\noutcome\n1500\n0.77\n5\n7\n0\n2\n0\n\n\ngender\n324\n0.95\n1\n1\n0\n2\n0\n\n\nhospital\n1512\n0.77\n5\n36\n0\n13\n0\n\n\ninfector\n2323\n0.65\n6\n6\n0\n2697\n0\n\n\nsource\n2323\n0.65\n5\n7\n0\n2\n0\n\n\nage\n107\n0.98\n1\n2\n0\n75\n0\n\n\nage_unit\n7\n1.00\n5\n6\n0\n2\n0\n\n\nfever\n258\n0.96\n2\n3\n0\n2\n0\n\n\nchills\n258\n0.96\n2\n3\n0\n2\n0\n\n\ncough\n258\n0.96\n2\n3\n0\n2\n0\n\n\naches\n258\n0.96\n2\n3\n0\n2\n0\n\n\nvomit\n258\n0.96\n2\n3\n0\n2\n0\n\n\ntime_admission\n844\n0.87\n5\n5\n0\n1091\n0\n\n\nmerged_header\n0\n1.00\n1\n1\n0\n1\n0\n\n\n…28\n0\n1.00\n1\n1\n0\n1\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\n\n\n\n\ngeneration\n7\n1.00\n16.60\n5.71\n0.00\n13.00\n16.00\n20.00\n37.00\n\n\nlon\n7\n1.00\n-13.23\n0.02\n-13.27\n-13.25\n-13.23\n-13.22\n-13.21\n\n\nlat\n7\n1.00\n8.47\n0.01\n8.45\n8.46\n8.47\n8.48\n8.49\n\n\nrow_num\n0\n1.00\n3240.91\n1857.83\n1.00\n1647.50\n3241.00\n4836.50\n6481.00\n\n\nwt_kg\n7\n1.00\n52.69\n18.59\n-11.00\n41.00\n54.00\n66.00\n111.00\n\n\nht_cm\n7\n1.00\n125.25\n49.57\n4.00\n91.00\n130.00\n159.00\n295.00\n\n\nct_blood\n7\n1.00\n21.26\n1.67\n16.00\n20.00\n22.00\n22.00\n26.00\n\n\ntemp\n158\n0.98\n38.60\n0.95\n35.20\n38.30\n38.80\n39.20\n40.80\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ninfection date\n2322\n0.65\n2012-04-09\n2015-04-27\n2014-10-04\n538\n\n\nhosp date\n7\n1.00\n2012-04-20\n2015-04-30\n2014-10-15\n570\n\n\ndate_of_outcome\n1068\n0.84\n2012-05-14\n2015-06-04\n2014-10-26\n575",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html#column-names",
    "href": "new_pages/cleaning.html#column-names",
    "title": "7  Cleaning data and core functions",
    "section": "7.4 Column names",
    "text": "7.4 Column names\nIn R, column names are the “header” or “top” value of a column. They are used to refer to columns in the code, and serve as a default label in figures.\nOther statistical software such as SAS and STATA use “labels” that co-exist as longer printed versions of the shorter column names. While R does offer the possibility of adding column labels to the data, this is not emphasized in most practice. To make column names “printer-friendly” for figures, one typically adjusts their display within the plotting commands that create the outputs (e.g. axis or legend titles of a plot, or column headers in a printed table - see the scales section of the ggplot tips page and Tables for presentation pages). If you want to assign column labels in the data, read more online here and here.\nAs R column names are used very often, so they must have “clean” syntax. We suggest the following:\n\nShort names\nNo spaces (replace with underscores _ )\nNo unusual characters (&, #, &lt;, &gt;, …)\n\nSimilar style nomenclature (e.g. all date columns named like date_onset, date_report, date_death…)\n\nThe columns names of linelist_raw are printed below using names() from base R. We can see that initially:\n\nSome names contain spaces (e.g. infection date)\n\nDifferent naming patterns are used for dates (date onset vs. infection date)\n\nThere must have been a merged header across the two last columns in the .xlsx. We know this because the name of two merged columns (“merged_header”) was assigned by R to the first column, and the second column was assigned a placeholder name “…28” (as it was then empty and is the 28th column).\n\n\nnames(linelist_raw)\n\n [1] \"case_id\"         \"generation\"      \"infection date\"  \"date onset\"     \n [5] \"hosp date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n[13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n[17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n[21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n[25] \"temp\"            \"time_admission\"  \"merged_header\"   \"...28\"          \n\n\nNOTE: To reference a column name that includes spaces, surround the name with back-ticks, for example: linelist$` '\\x60infection date\\x60'`. note that on your keyboard, the back-tick (`) is different from the single quotation mark (’).\n\nAutomatic cleaning\nThe function clean_names() from the package janitor standardizes column names and makes them unique by doing the following:\n\nConverts all names to consist of only underscores, numbers, and letters\n\nAccented characters are transliterated to ASCII (e.g. german o with umlaut becomes “o”, spanish “enye” becomes “n”)\n\nCapitalization preference for the new column names can be specified using the case = argument (“snake” is default, alternatives include “sentence”, “title”, “small_camel”…)\n\nYou can specify specific name replacements by providing a vector to the replace = argument (e.g. replace = c(onset = \"date_of_onset\"))\n\nHere is an online vignette\n\nBelow, the cleaning pipeline begins by using clean_names() on the raw linelist.\n\n# pipe the raw dataset through the function clean_names(), assign result as \"linelist\"  \nlinelist &lt;- linelist_raw %&gt;% \n  janitor::clean_names()\n\n# see the new column names\nnames(linelist)\n\n [1] \"case_id\"         \"generation\"      \"infection_date\"  \"date_onset\"     \n [5] \"hosp_date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n[13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n[17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n[21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n[25] \"temp\"            \"time_admission\"  \"merged_header\"   \"x28\"            \n\n\nNOTE: The last column name “…28” was changed to “x28”.\n\n\nManual name cleaning\nRe-naming columns manually is often necessary, even after the standardization step above. Below, re-naming is performed using the rename() function from the dplyr package, as part of a pipe chain. rename() uses the style NEW = OLD - the new column name is given before the old column name.\nBelow, a re-naming command is added to the cleaning pipeline. Spaces have been added strategically to align code for easier reading.\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome)\n\nNow you can see that the columns names have been changed:\n\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\n\nRename by column position\nYou can also rename by column position, instead of column name, for example:\n\nrename(newNameForFirstColumn  = 1,\n       newNameForSecondColumn = 2)\n\n\n\nRename via select() and summarise()\nAs a shortcut, you can also rename columns within the dplyr select() and summarise() functions. select() is used to keep only certain columns (and is covered later in this page). summarise() is covered in the Grouping data and Descriptive tables pages. These functions also uses the format new_name = old_name. Here is an example:\n\nlinelist_raw %&gt;% \n  select(# NEW name             # OLD name\n         date_infection       = `infection date`,    # rename and KEEP ONLY these columns\n         date_hospitalisation = `hosp date`)\n\n\n\n\nOther challenges\n\nEmpty Excel column names\nR cannot have dataset columns that do not have column names (headers). So, if you import an Excel dataset with data but no column headers, R will fill-in the headers with names like “…1” or “…2”. The number represents the column number (e.g. if the 4th column in the dataset has no header, then R will name it “…4”).\nYou can clean these names manually by referencing their position number (see example above), or their assigned name (linelist_raw$...1).\n\n\nMerged Excel column names and cells\nMerged cells in an Excel file are a common occurrence when receiving data. As explained in Transition to R, merged cells can be nice for human reading of data, but are not “tidy data” and cause many problems for machine reading of data. R cannot accommodate merged cells.\nRemind people doing data entry that human-readable data is not the same as machine-readable data. Strive to train users about the principles of tidy data. If at all possible, try to change procedures so that data arrive in a tidy format without merged cells.\n\nEach variable must have its own column.\n\nEach observation must have its own row.\n\nEach value must have its own cell.\n\nWhen using rio’s import() function, the value in a merged cell will be assigned to the first cell and subsequent cells will be empty.\nOne solution to deal with merged cells is to import the data with the function readWorkbook() from the package openxlsx. Set the argument fillMergedCells = TRUE. This gives the value in a merged cell to all cells within the merge range.\n\nlinelist_raw &lt;- openxlsx::readWorkbook(\"linelist_raw.xlsx\", fillMergedCells = TRUE)\n\nDANGER: If column names are merged with readWorkbook(), you will end up with duplicate column names, which you will need to fix manually - R does not work well with duplicate column names! You can re-name them by referencing their position (e.g. column 5), as explained in the section on manual column name cleaning.",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html#select-or-re-order-columns",
    "href": "new_pages/cleaning.html#select-or-re-order-columns",
    "title": "7  Cleaning data and core functions",
    "section": "7.5 Select or re-order columns",
    "text": "7.5 Select or re-order columns\nUse select() from dplyr to select the columns you want to retain, and to specify their order in the data frame.\nCAUTION: In the examples below, the linelist data frame is modified with select() and displayed, but not saved. This is for demonstration purposes. The modified column names are printed by piping the data frame to names().\nHere are ALL the column names in the linelist at this point in the cleaning pipe chain:\n\nnames(linelist)\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\n\nKeep columns\nSelect only the columns you want to remain\nPut their names in the select() command, with no quotation marks. They will appear in the data frame in the order you provide. Note that if you include a column that does not exist, R will return an error (see use of any_of() below if you want no error in this situation).\n\n# linelist dataset is piped through select() command, and names() prints just the column names\nlinelist %&gt;% \n  select(case_id, date_onset, date_hospitalisation, fever) %&gt;% \n  names()  # display the column names\n\n[1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\"\n[4] \"fever\"               \n\n\n\n\n“tidyselect” helper functions\nThese helper functions exist to make it easy to specify columns to keep, discard, or transform. They are from the package tidyselect, which is included in tidyverse and underlies how columns are selected in dplyr functions.\nFor example, if you want to re-order the columns, everything() is a useful function to signify “all other columns not yet mentioned”. The command below moves columns date_onset and date_hospitalisation to the beginning (left) of the dataset, but keeps all the other columns afterward. Note that everything() is written with empty parentheses:\n\n# move date_onset and date_hospitalisation to beginning\nlinelist %&gt;% \n  select(date_onset, date_hospitalisation, everything()) %&gt;% \n  names()\n\n [1] \"date_onset\"           \"date_hospitalisation\" \"case_id\"             \n [4] \"generation\"           \"date_infection\"       \"date_outcome\"        \n [7] \"outcome\"              \"gender\"               \"hospital\"            \n[10] \"lon\"                  \"lat\"                  \"infector\"            \n[13] \"source\"               \"age\"                  \"age_unit\"            \n[16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n[19] \"ct_blood\"             \"fever\"                \"chills\"              \n[22] \"cough\"                \"aches\"                \"vomit\"               \n[25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[28] \"x28\"                 \n\n\nHere are other “tidyselect” helper functions that also work within dplyr functions like select(), across(), and summarise():\n\neverything() - all other columns not mentioned\n\nlast_col() - the last column\n\nwhere() - applies a function to all columns and selects those which are TRUE\n\ncontains() - columns containing a character string\n\nexample: select(contains(\"time\"))\n\n\nstarts_with() - matches to a specified prefix\n\nexample: select(starts_with(\"date_\"))\n\n\nends_with() - matches to a specified suffix\n\nexample: select(ends_with(\"_post\"))\n\n\nmatches() - to apply a regular expression (regex)\n\nexample: select(matches(\"[pt]al\"))\n\n\nnum_range() - a numerical range like x01, x02, x03\n\nany_of() - matches IF column exists but returns no error if it is not found\n\nexample: select(any_of(date_onset, date_death, cardiac_arrest))\n\n\nIn addition, use normal operators such as c() to list several columns, : for consecutive columns, ! for opposite, & for AND, and | for OR.\nUse where() to specify logical criteria for columns. If providing a function inside where(), do not include the function’s empty parentheses. The command below selects columns that are class Numeric.\n\n# select columns that are class Numeric\nlinelist %&gt;% \n  select(where(is.numeric)) %&gt;% \n  names()\n\n[1] \"generation\" \"lon\"        \"lat\"        \"row_num\"    \"wt_kg\"     \n[6] \"ht_cm\"      \"ct_blood\"   \"temp\"      \n\n\nUse contains() to select only columns in which the column name contains a specified character string. ends_with() and starts_with() provide more nuance.\n\n# select columns containing certain characters\nlinelist %&gt;% \n  select(contains(\"date\")) %&gt;% \n  names()\n\n[1] \"date_infection\"       \"date_onset\"           \"date_hospitalisation\"\n[4] \"date_outcome\"        \n\n\nThe function matches() works similarly to contains() but can be provided a regular expression (see page on Characters and strings), such as multiple strings separated by OR bars within the parentheses:\n\n# searched for multiple character matches\nlinelist %&gt;% \n  select(matches(\"onset|hosp|fev\")) %&gt;%   # note the OR symbol \"|\"\n  names()\n\n[1] \"date_onset\"           \"date_hospitalisation\" \"hospital\"            \n[4] \"fever\"               \n\n\nCAUTION: If a column name that you specifically provide does not exist in the data, it can return an error and stop your code. Consider using any_of() to cite columns that may or may not exist, especially useful in negative (remove) selections.\nOnly one of these columns exists, but no error is produced and the code continues without stopping your cleaning chain.\n\nlinelist %&gt;% \n  select(any_of(c(\"date_onset\", \"village_origin\", \"village_detection\", \"village_residence\", \"village_travel\"))) %&gt;% \n  names()\n\n[1] \"date_onset\"\n\n\n\n\nRemove columns\nIndicate which columns to remove by placing a minus symbol “-” in front of the column name (e.g. select(-outcome)), or a vector of column names (as below). All other columns will be retained.\n\nlinelist %&gt;% \n  select(-c(date_onset, fever:vomit)) %&gt;% # remove date_onset and all columns from fever to vomit\n  names()\n\n [1] \"case_id\"              \"generation\"           \"date_infection\"      \n [4] \"date_hospitalisation\" \"date_outcome\"         \"outcome\"             \n [7] \"gender\"               \"hospital\"             \"lon\"                 \n[10] \"lat\"                  \"infector\"             \"source\"              \n[13] \"age\"                  \"age_unit\"             \"row_num\"             \n[16] \"wt_kg\"                \"ht_cm\"                \"ct_blood\"            \n[19] \"temp\"                 \"time_admission\"       \"merged_header\"       \n[22] \"x28\"                 \n\n\nYou can also remove a column using base R syntax, by defining it as NULL. For example:\n\nlinelist$date_onset &lt;- NULL   # deletes column with base R syntax \n\n\n\nStandalone\nselect() can also be used as an independent command (not in a pipe chain). In this case, the first argument is the original dataframe to be operated upon.\n\n# Create a new linelist with id and age-related columns\nlinelist_age &lt;- select(linelist, case_id, contains(\"age\"))\n\n# display the column names\nnames(linelist_age)\n\n[1] \"case_id\"  \"age\"      \"age_unit\"\n\n\n\nAdd to the pipe chain\nIn the linelist_raw, there are a few columns we do not need: row_num, merged_header, and x28. We remove them with a select() command in the cleaning pipe chain:\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n\n    # remove column\n    select(-c(row_num, merged_header, x28))",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html#deduplication",
    "href": "new_pages/cleaning.html#deduplication",
    "title": "7  Cleaning data and core functions",
    "section": "7.6 Deduplication",
    "text": "7.6 Deduplication\nSee the handbook page on De-duplication for extensive options on how to de-duplicate data. Only a very simple row de-duplication example is presented here.\nThe package dplyr offers the distinct() function. This function examines every row and reduce the data frame to only the unique rows. That is, it removes rows that are 100% duplicates.\nWhen evaluating duplicate rows, it takes into account a range of columns - by default it considers all columns. As shown in the de-duplication page, you can adjust this column range so that the uniqueness of rows is only evaluated in regards to certain columns.\nIn this simple example, we just add the empty command distinct() to the pipe chain. This ensures there are no rows that are 100% duplicates of other rows (evaluated across all columns).\nWe begin with nrow(linelist) rows in linelist.\n\nlinelist &lt;- linelist %&gt;% \n  distinct()\n\nAfter de-duplication there are nrow(linelist) rows. Any removed rows would have been 100% duplicates of other rows.\nBelow, the distinct() command is added to the cleaning pipe chain:\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n    \n    # de-duplicate\n    distinct()",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html#column-creation-and-transformation",
    "href": "new_pages/cleaning.html#column-creation-and-transformation",
    "title": "7  Cleaning data and core functions",
    "section": "7.7 Column creation and transformation",
    "text": "7.7 Column creation and transformation\nWe recommend using the dplyr function mutate() to add a new column, or to modify an existing one.\nBelow is an example of creating a new column with mutate(). The syntax is: mutate(new_column_name = value or transformation)\nIn Stata, this is similar to the command generate, but R’s mutate() can also be used to modify an existing column.\n\nNew columns\nThe most basic mutate() command to create a new column might look like this. It creates a new column new_col where the value in every row is 10.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(new_col = 10)\n\nYou can also reference values in other columns, to perform calculations. Below, a new column bmi is created to hold the Body Mass Index (BMI) for each case - as calculated using the formula BMI = kg/m^2, using column ht_cm and column wt_kg.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\n\nIf creating multiple new columns, separate each with a comma and new line. Below are examples of new columns, including ones that consist of values from other columns combined using str_glue() from the stringr package (see page on Characters and strings.\n\nnew_col_demo &lt;- linelist %&gt;%                       \n  mutate(\n    new_var_dup    = case_id,             # new column = duplicate/copy another existing column\n    new_var_static = 7,                   # new column = all values the same\n    new_var_static = new_var_static + 5,  # you can overwrite a column, and it can be a calculation using other variables\n    new_var_paste  = stringr::str_glue(\"{hospital} on ({date_hospitalisation})\") # new column = pasting together values from other columns\n    ) %&gt;% \n  select(case_id, hospital, date_hospitalisation, contains(\"new\"))        # show only new columns, for demonstration purposes\n\nReview the new columns. For demonstration purposes, only the new columns and the columns used to create them are shown:\n\n\n\n\n\n\nTIP: A variation on mutate() is the function transmute(). This function adds a new column just like mutate(), but also drops/removes all other columns that you do not mention within its parentheses.\n\n# HIDDEN FROM READER\n# removes new demo columns created above\n# linelist &lt;- linelist %&gt;% \n#   select(-contains(\"new_var\"))\n\n\n\nConvert column class\nColumns containing values that are dates, numbers, or logical values (TRUE/FALSE) will only behave as expected if they are correctly classified. There is a difference between “2” of class character and 2 of class numeric!\nThere are ways to set column class during the import commands, but this is often cumbersome. See the R Basics section on object classes to learn more about converting the class of objects and columns.\nFirst, let’s run some checks on important columns to see if they are the correct class. We also saw this in the beginning when we ran skim().\nCurrently, the class of the age column is character. To perform quantitative analyses, we need these numbers to be recognized as numeric!\n\nclass(linelist$age)\n\n[1] \"character\"\n\n\nThe class of the date_onset column is also character! To perform analyses, these dates must be recognized as dates!\n\nclass(linelist$date_onset)\n\n[1] \"character\"\n\n\nTo resolve this, use the ability of mutate() to re-define a column with a transformation. We define the column as itself, but converted to a different class. Here is a basic example, converting or ensuring that the column age is class Numeric:\n\nlinelist &lt;- linelist %&gt;% \n  mutate(age = as.numeric(age))\n\nIn a similar way, you can use as.character() and as.logical(). To convert to class Factor, you can use factor() from base R or as_factor() from forcats. Read more about this in the Factors page.\nYou must be careful when converting to class Date. Several methods are explained on the page Working with dates. Typically, the raw date values must all be in the same format for conversion to work correctly (e.g “MM/DD/YYYY”, or “DD MM YYYY”). After converting to class Date, check your data to confirm that each value was converted correctly.\n\n\nGrouped data\nIf your data frame is already grouped (see page on Grouping data), mutate() may behave differently than if the data frame is not grouped. Any summarizing functions, like mean(), median(), max(), etc. will calculate by group, not by all the rows.\n\n# age normalized to mean of ALL rows\nlinelist %&gt;% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\n# age normalized to mean of hospital group\nlinelist %&gt;% \n  group_by(hospital) %&gt;% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\nRead more about using mutate () on grouped dataframes in this tidyverse mutate documentation.\n\n\nTransform multiple columns\nOften to write concise code you want to apply the same transformation to multiple columns at once. A transformation can be applied to multiple columns at once using the across() function from the package dplyr (also contained within tidyverse package). across() can be used with any dplyr function, but is commonly used within select(), mutate(), filter(), or summarise(). See how it is applied to summarise() in the page on Descriptive tables.\nSpecify the columns to the argument .cols = and the function(s) to apply to .fns =. Any additional arguments to provide to the .fns function can be included after a comma, still within across().\n\nacross() column selection\nSpecify the columns to the argument .cols =. You can name them individually, or use “tidyselect” helper functions. Specify the function to .fns =. Note that using the function mode demonstrated below, the function is written without its parentheses ( ).\nHere the transformation as.character() is applied to specific columns named within across().\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = c(temp, ht_cm, wt_kg), .fns = as.character))\n\nThe “tidyselect” helper functions are available to assist you in specifying columns. They are detailed above in the section on Selecting and re-ordering columns, and they include: everything(), last_col(), where(), starts_with(), ends_with(), contains(), matches(), num_range() and any_of().\nHere is an example of how one would change all columns to character class:\n\n#to change all columns to character class\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = everything(), .fns = as.character))\n\nConvert to character all columns where the name contains the string “date” (note the placement of commas and parentheses):\n\n#to change all columns to character class\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"date\"), .fns = as.character))\n\nBelow, an example of mutating the columns that are currently class POSIXct (a raw datetime class that shows timestamps) - in other words, where the function is.POSIXct() evaluates to TRUE. Then we want to apply the function as.Date() to these columns to convert them to a normal class Date.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = where(is.POSIXct), .fns = as.Date))\n\n\nNote that within across() we also use the function where() as is.POSIXct is evaluating to either TRUE or FALSE.\n\nNote that is.POSIXct() is from the package lubridate. Other similar “is” functions like is.character(), is.numeric(), and is.logical() are from base R\n\n\n\nacross() functions\nYou can read the documentation with ?across for details on how to provide functions to across(). A few summary points: there are several ways to specify the function(s) to perform on a column and you can even define your own functions:\n\nYou can provide the function name alone (e.g. mean or as.character)\n\nYou can provide the function in purrr-style (e.g. ~ mean(.x, na.rm = TRUE)) (see this page)\n\nYou can specify multiple functions by providing a list (e.g. list(mean = mean, n_miss = ~ sum(is.na(.x))).\n\nIf you provide multiple functions, multiple transformed columns will be returned per input column, with unique names in the format col_fn. You can adjust how the new columns are named with the .names = argument using glue syntax (see page on Characters and strings) where {.col} and {.fn} are shorthand for the input column and function.\n\n\nHere are a few online resources on using across(): creator Hadley Wickham’s thoughts/rationale\n\n\n\ncoalesce()\nThis dplyr function finds the first non-missing value at each position. It “fills-in” missing values with the first available value in an order you specify.\nHere is an example outside the context of a data frame: Let us say you have two vectors, one containing the patient’s village of detection and another containing the patient’s village of residence. You can use coalesce to pick the first non-missing value for each index:\n\nvillage_detection &lt;- c(\"a\", \"b\", NA,  NA)\nvillage_residence &lt;- c(\"a\", \"c\", \"a\", \"d\")\n\nvillage &lt;- coalesce(village_detection, village_residence)\nvillage    # print\n\n[1] \"a\" \"b\" \"a\" \"d\"\n\n\nThis works the same if you provide data frame columns: for each row, the function will assign the new column value with the first non-missing value in the columns you provided (in order provided).\n\nlinelist &lt;- linelist %&gt;% \n  mutate(village = coalesce(village_detection, village_residence))\n\nThis is an example of a “row-wise” operation. For more complicated row-wise calculations, see the section below on Row-wise calculations.\n\n\nCumulative math\nIf you want a column to reflect the cumulative sum/mean/min/max etc as assessed down the rows of a dataframe to that point, use the following functions:\ncumsum() returns the cumulative sum, as shown below:\n\nsum(c(2,4,15,10))     # returns only one number\n\n[1] 31\n\ncumsum(c(2,4,15,10))  # returns the cumulative sum at each step\n\n[1]  2  6 21 31\n\n\nThis can be used in a dataframe when making a new column. For example, to calculate the cumulative number of cases per day in an outbreak, consider code like this:\n\ncumulative_case_counts &lt;- linelist %&gt;%  # begin with case linelist\n  count(date_onset) %&gt;%                 # count of rows per day, as column 'n'   \n  mutate(cumulative_cases = cumsum(n))  # new column, of the cumulative sum at each row\n\nBelow are the first 10 rows:\n\nhead(cumulative_case_counts, 10)\n\n   date_onset n cumulative_cases\n1  2012-04-15 1                1\n2  2012-05-05 1                2\n3  2012-05-08 1                3\n4  2012-05-31 1                4\n5  2012-06-02 1                5\n6  2012-06-07 1                6\n7  2012-06-14 1                7\n8  2012-06-21 1                8\n9  2012-06-24 1                9\n10 2012-06-25 1               10\n\n\nSee the page on Epidemic curves for how to plot cumulative incidence with the epicurve.\nSee also:\ncumsum(), cummean(), cummin(), cummax(), cumany(), cumall()\n\n\nUsing base R\nTo define a new column (or re-define a column) using base R, write the name of data frame, connected with $, to the new column (or the column to be modified). Use the assignment operator &lt;- to define the new value(s). Remember that when using base R you must specify the data frame name before the column name every time (e.g. dataframe$column). Here is an example of creating the bmi column using base R:\n\nlinelist$bmi = linelist$wt_kg / (linelist$ht_cm / 100) ^ 2)\n\n\n\nAdd to pipe chain\nBelow, a new column is added to the pipe chain and some classes are converted.\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # de-duplicate\n    distinct() %&gt;% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    # add new column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;% \n  \n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age))",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html#re-code-values",
    "href": "new_pages/cleaning.html#re-code-values",
    "title": "7  Cleaning data and core functions",
    "section": "7.8 Re-code values",
    "text": "7.8 Re-code values\nHere are a few scenarios where you need to re-code (change) values:\n\nto edit one specific value (e.g. one date with an incorrect year or format)\n\nto reconcile values not spelled the same\nto create a new column of categorical values\n\nto create a new column of numeric categories (e.g. age categories)\n\n\nSpecific values\nTo change values manually you can use the recode() function within the mutate() function.\nImagine there is a nonsensical date in the data (e.g. “2014-14-15”): you could fix the date manually in the raw source data, or, you could write the change into the cleaning pipeline via mutate() and recode(). The latter is more transparent and reproducible to anyone else seeking to understand or repeat your analysis.\n\n# fix incorrect values                   # old value       # new value\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = recode(date_onset, \"2014-14-15\" = \"2014-04-15\"))\n\nThe mutate() line above can be read as: “mutate the column date_onset to equal the column date_onset re-coded so that OLD VALUE is changed to NEW VALUE”. Note that this pattern (OLD = NEW) for recode() is the opposite of most R patterns (new = old). The R development community is working on revising this.\nHere is another example re-coding multiple values within one column.\nIn linelist the values in the column “hospital” must be cleaned. There are several different spellings and many missing values.\n\ntable(linelist$hospital, useNA = \"always\")  # print table of all unique values, including missing  \n\n\n                     Central Hopital                     Central Hospital \n                                  11                                  457 \n                          Hospital A                           Hospital B \n                                 290                                  289 \n                    Military Hopital                    Military Hospital \n                                  32                                  798 \n                    Mitylira Hopital                    Mitylira Hospital \n                                   1                                   79 \n                               Other                         Port Hopital \n                                 907                                   48 \n                       Port Hospital St. Mark's Maternity Hospital (SMMH) \n                                1756                                  417 \n  St. Marks Maternity Hopital (SMMH)                                 &lt;NA&gt; \n                                  11                                 1512 \n\n\nThe recode() command below re-defines the column “hospital” as the current column “hospital”, but with the specified recode changes. Don’t forget commas after each!\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = recode(hospital,\n                     # for reference: OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      ))\n\nNow we see the spellings in the hospital column have been corrected and consolidated:\n\ntable(linelist$hospital, useNA = \"always\")\n\n\n                    Central Hospital                           Hospital A \n                                 468                                  290 \n                          Hospital B                    Military Hospital \n                                 289                                  910 \n                               Other                        Port Hospital \n                                 907                                 1804 \nSt. Mark's Maternity Hospital (SMMH)                                 &lt;NA&gt; \n                                 428                                 1512 \n\n\nTIP: The number of spaces before and after an equals sign does not matter. Make your code easier to read by aligning the = for all or most rows. Also, consider adding a hashed comment row to clarify for future readers which side is OLD and which side is NEW. \nTIP: Sometimes a blank character value exists in a dataset (not recognized as R’s value for missing - NA). You can reference this value with two quotation marks with no space inbetween (““).\n\n\nBy logic\nBelow we demonstrate how to re-code values in a column using logic and conditions:\n\nUsing replace(), ifelse() and if_else() for simple logic\nUsing case_when() for more complex logic\n\n\n\nSimple logic\n\nreplace()\nTo re-code with simple logical criteria, you can use replace() within mutate(). replace() is a function from base R. Use a logic condition to specify the rows to change . The general syntax is:\nmutate(col_to_change = replace(col_to_change, criteria for rows, new value)).\nOne common situation to use replace() is changing just one value in one row, using an unique row identifier. Below, the gender is changed to “Female” in the row where the column case_id is “2195”.\n\n# Example: change gender of one specific observation to \"Female\" \nlinelist &lt;- linelist %&gt;% \n  mutate(gender = replace(gender, case_id == \"2195\", \"Female\"))\n\nThe equivalent command using base R syntax and indexing brackets [ ] is below. It reads as “Change the value of the dataframe linelist‘s column gender (for the rows where linelist’s column case_id has the value ’2195’) to ‘Female’”.\n\nlinelist$gender[linelist$case_id == \"2195\"] &lt;- \"Female\"\n\n\n\nifelse() and if_else()\nAnother tool for simple logic is ifelse() and its partner if_else(). However, in most cases for re-coding it is more clear to use case_when() (detailed below). These “if else” commands are simplified versions of an if and else programming statement. The general syntax is:\nifelse(condition, value to return if condition evaluates to TRUE, value to return if condition evaluates to FALSE)\nBelow, the column source_known is defined. Its value in a given row is set to “known” if the row’s value in column source is not missing. If the value in source is missing, then the value in source_known is set to “unknown”.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(source_known = ifelse(!is.na(source), \"known\", \"unknown\"))\n\nif_else() is a special version from dplyr that handles dates. Note that if the ‘true’ value is a date, the ‘false’ value must also qualify a date, hence using the special value NA_real_ instead of just NA.\n\n# Create a date of death column, which is NA if patient has not died.\nlinelist &lt;- linelist %&gt;% \n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, NA_real_))\n\nAvoid stringing together many ifelse commands… use case_when() instead! case_when() is much easier to read and you’ll make fewer errors.\n\n\n\n\n\n\n\n\n\nOutside of the context of a data frame, if you want to have an object used in your code switch its value, consider using switch() from base R.\n\n\n\nComplex logic\nUse dplyr’s case_when() if you are re-coding into many new groups, or if you need to use complex logic statements to re-code values. This function evaluates every row in the data frame, assess whether the rows meets specified criteria, and assigns the correct new value.\ncase_when() commands consist of statements that have a Right-Hand Side (RHS) and a Left-Hand Side (LHS) separated by a “tilde” ~. The logic criteria are in the left side and the pursuant values are in the right side of each statement. Statements are separated by commas.\nFor example, here we utilize the columns age and age_unit to create a column age_years:\n\nlinelist &lt;- linelist %&gt;% \n  mutate(age_years = case_when(\n       age_unit == \"years\"  ~ age,       # if age unit is years\n       age_unit == \"months\" ~ age/12,    # if age unit is months, divide age by 12\n       is.na(age_unit)      ~ age))      # if age unit is missing, assume years\n                                         # any other circumstance, assign NA (missing)\n\nAs each row in the data is evaluated, the criteria are applied/evaluated in the order the case_when() statements are written - from top-to-bottom. If the top criteria evaluates to TRUE for a given row, the RHS value is assigned, and the remaining criteria are not even tested for that row in the data. Thus, it is best to write the most specific criteria first, and the most general last. A data row that does not meet any of the RHS criteria will be assigned NA.\nSometimes, you may with to write a final statement that assigns a value for all other scenarios not described by one of the previous lines. To do this, place TRUE on the left-side, which will capture any row that did not meet any of the previous criteria. The right-side of this statement could be assigned a value like “check me!” or missing.\nBelow is another example of case_when() used to create a new column with the patient classification, according to a case definition for confirmed and suspect cases:\n\nlinelist &lt;- linelist %&gt;% \n     mutate(case_status = case_when(\n          \n          # if patient had lab test and it is positive,\n          # then they are marked as a confirmed case \n          ct_blood &lt; 20                   ~ \"Confirmed\",\n          \n          # given that a patient does not have a positive lab result,\n          # if patient has a \"source\" (epidemiological link) AND has fever, \n          # then they are marked as a suspect case\n          !is.na(source) & fever == \"yes\" ~ \"Suspect\",\n          \n          # any other patient not addressed above \n          # is marked for follow up\n          TRUE                            ~ \"To investigate\"))\n\nDANGER: Values on the right-side must all be the same class - either numeric, character, date, logical, etc. To assign missing (NA), you may need to use special variations of NA such as NA_character_, NA_real_ (for numeric or POSIX), and as.Date(NA). Read more in Working with dates.\n\n\nMissing values\nBelow are special functions for handling missing values in the context of data cleaning.\nSee the page on Missing data for more detailed tips on identifying and handling missing values. For example, the is.na() function which logically tests for missingness.\nreplace_na()\nTo change missing values (NA) to a specific value, such as “Missing”, use the dplyr function replace_na() within mutate(). Note that this is used in the same manner as recode above - the name of the variable must be repeated within replace_na().\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = replace_na(hospital, \"Missing\"))\n\nfct_explicit_na()\nThis is a function from the forcats package. The forcats package handles columns of class Factor. Factors are R’s way to handle ordered values such as c(\"First\", \"Second\", \"Third\") or to set the order that values (e.g. hospitals) appear in tables and plots. See the page on Factors.\nIf your data are class Factor and you try to convert NA to “Missing” by using replace_na(), you will get this error: invalid factor level, NA generated. You have tried to add “Missing” as a value, when it was not defined as a possible level of the factor, and it was rejected.\nThe easiest way to solve this is to use the forcats function fct_explicit_na() which converts a column to class factor, and converts NA values to the character “(Missing)”.\n\nlinelist %&gt;% \n  mutate(hospital = fct_explicit_na(hospital))\n\nA slower alternative would be to add the factor level using fct_expand() and then convert the missing values.\nna_if()\nTo convert a specific value to NA, use dplyr’s na_if(). The command below performs the opposite operation of replace_na(). In the example below, any values of “Missing” in the column hospital are converted to NA.\n\nlinelist &lt;- linelist %&gt;% \n  mutate(hospital = na_if(hospital, \"Missing\"))\n\nNote: na_if() cannot be used for logic criteria (e.g. “all values &gt; 99”) - use replace() or case_when() for this:\n\n# Convert temperatures above 40 to NA \nlinelist &lt;- linelist %&gt;% \n  mutate(temp = replace(temp, temp &gt; 40, NA))\n\n# Convert onset dates earlier than 1 Jan 2000 to missing\nlinelist &lt;- linelist %&gt;% \n  mutate(date_onset = replace(date_onset, date_onset &gt; as.Date(\"2000-01-01\"), NA))\n\n\n\nCleaning dictionary\nUse the R package matchmaker and its function match_df() to clean a data frame with a cleaning dictionary.\n\nCreate a cleaning dictionary with 3 columns:\n\nA “from” column (the incorrect value)\n\nA “to” column (the correct value)\n\nA column specifying the column for the changes to be applied (or “.global” to apply to all columns)\n\n\nNote: .global dictionary entries will be overridden by column-specific dictionary entries.\n\n\n\n\n\n\n\n\n\n\nImport the dictionary file into R. This example can be downloaded via instructions on the Download handbook and data page.\n\n\ncleaning_dict &lt;- import(\"cleaning_dict.csv\")\n\n\nPipe the raw linelist to match_df(), specifying to dictionary = the cleaning dictionary data frame. The from = argument should be the name of the dictionary column which contains the “old” values, the by = argument should be dictionary column which contains the corresponding “new” values, and the third column lists the column in which to make the change. Use .global in the by = column to apply a change across all columns. A fourth dictionary column order can be used to specify factor order of new values.\n\nRead more details in the package documentation by running ?match_df. Note this function can take a long time to run for a large dataset.\n\nlinelist &lt;- linelist %&gt;%     # provide or pipe your dataset\n     matchmaker::match_df(\n          dictionary = cleaning_dict,  # name of your dictionary\n          from = \"from\",               # column with values to be replaced (default is col 1)\n          to = \"to\",                   # column with final values (default is col 2)\n          by = \"col\"                   # column with column names (default is col 3)\n  )\n\nNow scroll to the right to see how values have changed - particularly gender (lowercase to uppercase), and all the symptoms columns have been transformed from yes/no to 1/0.\n\n\n\n\n\n\nNote that your column names in the cleaning dictionary must correspond to the names at this point in your cleaning script. See this online reference for the linelist package for more details.\n\nAdd to pipe chain\nBelow, some new columns and column transformations are added to the pipe chain.\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # de-duplicate\n    distinct() %&gt;% \n  \n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n   # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n   ###################################################\n\n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_))",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html#num_cats",
    "href": "new_pages/cleaning.html#num_cats",
    "title": "7  Cleaning data and core functions",
    "section": "7.9 Numeric categories",
    "text": "7.9 Numeric categories\nHere we describe some special approaches for creating categories from numerical columns. Common examples include age categories, groups of lab values, etc. Here we will discuss:\n\nage_categories(), from the epikit package\n\ncut(), from base R\n\ncase_when()\n\nquantile breaks with quantile() and ntile()\n\n\nReview distribution\nFor this example we will create an age_cat column using the age_years column.\n\n#check the class of the linelist variable age\nclass(linelist$age_years)\n\n[1] \"numeric\"\n\n\nFirst, examine the distribution of your data, to make appropriate cut-points. See the page on ggplot basics.\n\n# examine the distribution\nhist(linelist$age_years)\n\n\n\n\n\n\n\n\n\nsummary(linelist$age_years, na.rm=T)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    6.00   13.00   16.04   23.00   84.00     107 \n\n\nCAUTION: Sometimes, numeric variables will import as class “character”. This occurs if there are non-numeric characters in some of the values, for example an entry of “2 months” for age, or (depending on your R locale settings) if a comma is used in the decimals place (e.g. “4,5” to mean four and one half years)..\n\n\n\nage_categories()\nWith the epikit package, you can use the age_categories() function to easily categorize and label numeric columns (note: this function can be applied to non-age numeric variables too). As a bonum, the output column is automatically an ordered factor.\nHere are the required inputs:\n\nA numeric vector (column)\n\nThe breakers = argument - provide a numeric vector of break points for the new groups\n\nFirst, the simplest example:\n\n# Simple example\n################\npacman::p_load(epikit)                    # load package\n\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(             # create new column\n      age_years,                            # numeric column to make groups from\n      breakers = c(0, 5, 10, 15, 20,        # break points\n                   30, 40, 50, 60, 70)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-69   70+  &lt;NA&gt; \n 1227  1223  1048   827  1216   597   251    78    27     7   107 \n\n\nThe break values you specify are by default the lower bounds - that is, they are included in the “higher” group / the groups are “open” on the lower/left side. As shown below, you can add 1 to each break value to achieve groups that are open at the top/right.\n\n# Include upper ends for the same categories\n############################################\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-5  6-10 11-15 16-20 21-30 31-40 41-50 51-60 61-70   71+  &lt;NA&gt; \n 1469  1195  1040   770  1149   547   231    70    24     6   107 \n\n\nYou can adjust how the labels are displayed with separator =. The default is “-”\nYou can adjust how the top numbers are handled, with the ceiling = arguemnt. To set an upper cut-off set ceiling = TRUE. In this use, the highest break value provided is a “ceiling” and a category “XX+” is not created. Any values above highest break value (or to upper =, if defined) are categorized as NA. Below is an example with ceiling = TRUE, so that there is no category of XX+ and values above 70 (the highest break value) are assigned as NA.\n\n# With ceiling set to TRUE\n##########################\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),\n      ceiling = TRUE)) # 70 is ceiling, all above become NA\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-70  &lt;NA&gt; \n 1227  1223  1048   827  1216   597   251    78    28   113 \n\n\nAlternatively, instead of breakers =, you can provide all of lower =, upper =, and by =:\n\nlower = The lowest number you want considered - default is 0\n\nupper = The highest number you want considered\n\nby = The number of years between groups\n\n\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      lower = 0,\n      upper = 100,\n      by = 10))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")\n\n\n  0-9 10-19 20-29 30-39 40-49 50-59 60-69 70-79 80-89 90-99  100+  &lt;NA&gt; \n 2450  1875  1216   597   251    78    27     6     1     0     0   107 \n\n\nSee the function’s Help page for more details (enter ?age_categories in the R console).\n\n\n\ncut()\ncut() is a base R alternative to age_categories(), but I think you will see why age_categories() was developed to simplify this process. Some notable differences from age_categories() are:\n\nYou do not need to install/load another package\n\nYou can specify whether groups are open/closed on the right/left\n\nYou must provide accurate labels yourself\n\nIf you want 0 included in the lowest group you must specify this\n\nThe basic syntax within cut() is to first provide the numeric column to be cut (age_years), and then the breaks argument, which is a numeric vector c() of break points. Using cut(), the resulting column is an ordered factor.\nBy default, the categorization occurs so that the right/upper side is “open” and inclusive (and the left/lower side is “closed” or exclusive). This is the opposite behavior from the age_categories() function. The default labels use the notation “(A, B]”, which means A is not included but B is. Reverse this behavior by providing the right = TRUE argument.\nThus, by default, “0” values are excluded from the lowest group, and categorized as NA! “0” values could be infants coded as age 0 so be careful! To change this, add the argument include.lowest = TRUE so that any “0” values will be included in the lowest group. The automatically-generated label for the lowest category will then be “[A],B]”. Note that if you include the include.lowest = TRUE argument and right = TRUE, the extreme inclusion will now apply to the highest break point value and category, not the lowest.\nYou can provide a vector of customized labels using the labels = argument. As these are manually written, be very careful to ensure they are accurate! Check your work using cross-tabulation, as described below.\nAn example of cut() applied to age_years to make the new variable age_cat is below:\n\n# Create new variable, by cutting the numeric age variable\n# lower break is excluded but upper break is included in each category\nlinelist &lt;- linelist %&gt;% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),\n      include.lowest = TRUE         # include 0 in lowest group\n      ))\n\n# tabulate the number of observations per group\ntable(linelist$age_cat, useNA = \"always\")\n\n\n   [0,5]   (5,10]  (10,15]  (15,20]  (20,30]  (30,50]  (50,70] (70,100] \n    1469     1195     1040      770     1149      778       94        6 \n    &lt;NA&gt; \n     107 \n\n\nCheck your work!!! Verify that each age value was assigned to the correct category by cross-tabulating the numeric and category columns. Examine assignment of boundary values (e.g. 15, if neighboring categories are 10-15 and 16-20).\n\n# Cross tabulation of the numeric and category columns. \ntable(\"Numeric Values\" = linelist$age_years,   # names specified in table for clarity.\n      \"Categories\"     = linelist$age_cat,\n      useNA = \"always\")                        # don't forget to examine NA values\n\n                    Categories\nNumeric Values       [0,5] (5,10] (10,15] (15,20] (20,30] (30,50] (50,70]\n  0                    136      0       0       0       0       0       0\n  0.0833333333333333     1      0       0       0       0       0       0\n  0.25                   2      0       0       0       0       0       0\n  0.333333333333333      6      0       0       0       0       0       0\n  0.416666666666667      1      0       0       0       0       0       0\n  0.5                    6      0       0       0       0       0       0\n  0.583333333333333      3      0       0       0       0       0       0\n  0.666666666666667      3      0       0       0       0       0       0\n  0.75                   3      0       0       0       0       0       0\n  0.833333333333333      1      0       0       0       0       0       0\n  0.916666666666667      1      0       0       0       0       0       0\n  1                    275      0       0       0       0       0       0\n  1.5                    2      0       0       0       0       0       0\n  2                    308      0       0       0       0       0       0\n  3                    246      0       0       0       0       0       0\n  4                    233      0       0       0       0       0       0\n  5                    242      0       0       0       0       0       0\n  6                      0    241       0       0       0       0       0\n  7                      0    256       0       0       0       0       0\n  8                      0    239       0       0       0       0       0\n  9                      0    245       0       0       0       0       0\n  10                     0    214       0       0       0       0       0\n  11                     0      0     220       0       0       0       0\n  12                     0      0     224       0       0       0       0\n  13                     0      0     191       0       0       0       0\n  14                     0      0     199       0       0       0       0\n  15                     0      0     206       0       0       0       0\n  16                     0      0       0     186       0       0       0\n  17                     0      0       0     164       0       0       0\n  18                     0      0       0     141       0       0       0\n  19                     0      0       0     130       0       0       0\n  20                     0      0       0     149       0       0       0\n  21                     0      0       0       0     158       0       0\n  22                     0      0       0       0     149       0       0\n  23                     0      0       0       0     125       0       0\n  24                     0      0       0       0     144       0       0\n  25                     0      0       0       0     107       0       0\n  26                     0      0       0       0     100       0       0\n  27                     0      0       0       0     117       0       0\n  28                     0      0       0       0      85       0       0\n  29                     0      0       0       0      82       0       0\n  30                     0      0       0       0      82       0       0\n  31                     0      0       0       0       0      68       0\n  32                     0      0       0       0       0      84       0\n  33                     0      0       0       0       0      78       0\n  34                     0      0       0       0       0      58       0\n  35                     0      0       0       0       0      58       0\n  36                     0      0       0       0       0      33       0\n  37                     0      0       0       0       0      46       0\n  38                     0      0       0       0       0      45       0\n  39                     0      0       0       0       0      45       0\n  40                     0      0       0       0       0      32       0\n  41                     0      0       0       0       0      34       0\n  42                     0      0       0       0       0      26       0\n  43                     0      0       0       0       0      31       0\n  44                     0      0       0       0       0      24       0\n  45                     0      0       0       0       0      27       0\n  46                     0      0       0       0       0      25       0\n  47                     0      0       0       0       0      16       0\n  48                     0      0       0       0       0      21       0\n  49                     0      0       0       0       0      15       0\n  50                     0      0       0       0       0      12       0\n  51                     0      0       0       0       0       0      13\n  52                     0      0       0       0       0       0       7\n  53                     0      0       0       0       0       0       4\n  54                     0      0       0       0       0       0       6\n  55                     0      0       0       0       0       0       9\n  56                     0      0       0       0       0       0       7\n  57                     0      0       0       0       0       0       9\n  58                     0      0       0       0       0       0       6\n  59                     0      0       0       0       0       0       5\n  60                     0      0       0       0       0       0       4\n  61                     0      0       0       0       0       0       2\n  62                     0      0       0       0       0       0       1\n  63                     0      0       0       0       0       0       5\n  64                     0      0       0       0       0       0       1\n  65                     0      0       0       0       0       0       5\n  66                     0      0       0       0       0       0       3\n  67                     0      0       0       0       0       0       2\n  68                     0      0       0       0       0       0       1\n  69                     0      0       0       0       0       0       3\n  70                     0      0       0       0       0       0       1\n  72                     0      0       0       0       0       0       0\n  73                     0      0       0       0       0       0       0\n  76                     0      0       0       0       0       0       0\n  84                     0      0       0       0       0       0       0\n  &lt;NA&gt;                   0      0       0       0       0       0       0\n                    Categories\nNumeric Values       (70,100] &lt;NA&gt;\n  0                         0    0\n  0.0833333333333333        0    0\n  0.25                      0    0\n  0.333333333333333         0    0\n  0.416666666666667         0    0\n  0.5                       0    0\n  0.583333333333333         0    0\n  0.666666666666667         0    0\n  0.75                      0    0\n  0.833333333333333         0    0\n  0.916666666666667         0    0\n  1                         0    0\n  1.5                       0    0\n  2                         0    0\n  3                         0    0\n  4                         0    0\n  5                         0    0\n  6                         0    0\n  7                         0    0\n  8                         0    0\n  9                         0    0\n  10                        0    0\n  11                        0    0\n  12                        0    0\n  13                        0    0\n  14                        0    0\n  15                        0    0\n  16                        0    0\n  17                        0    0\n  18                        0    0\n  19                        0    0\n  20                        0    0\n  21                        0    0\n  22                        0    0\n  23                        0    0\n  24                        0    0\n  25                        0    0\n  26                        0    0\n  27                        0    0\n  28                        0    0\n  29                        0    0\n  30                        0    0\n  31                        0    0\n  32                        0    0\n  33                        0    0\n  34                        0    0\n  35                        0    0\n  36                        0    0\n  37                        0    0\n  38                        0    0\n  39                        0    0\n  40                        0    0\n  41                        0    0\n  42                        0    0\n  43                        0    0\n  44                        0    0\n  45                        0    0\n  46                        0    0\n  47                        0    0\n  48                        0    0\n  49                        0    0\n  50                        0    0\n  51                        0    0\n  52                        0    0\n  53                        0    0\n  54                        0    0\n  55                        0    0\n  56                        0    0\n  57                        0    0\n  58                        0    0\n  59                        0    0\n  60                        0    0\n  61                        0    0\n  62                        0    0\n  63                        0    0\n  64                        0    0\n  65                        0    0\n  66                        0    0\n  67                        0    0\n  68                        0    0\n  69                        0    0\n  70                        0    0\n  72                        1    0\n  73                        3    0\n  76                        1    0\n  84                        1    0\n  &lt;NA&gt;                      0  107\n\n\nRe-labeling NA values\nYou may want to assign NA values a label such as “Missing”. Because the new column is class Factor (restricted values), you cannot simply mutate it with replace_na(), as this value will be rejected. Instead, use fct_explicit_na() from forcats as explained in the Factors page.\n\nlinelist &lt;- linelist %&gt;% \n  \n  # cut() creates age_cat, automatically of class Factor      \n  mutate(age_cat = cut(\n    age_years,\n    breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n    right = FALSE,\n    include.lowest = TRUE,        \n    labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n    # make missing values explicit\n    age_cat = fct_explicit_na(\n      age_cat,\n      na_level = \"Missing age\")  # you can specify the label\n  )    \n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `age_cat = fct_explicit_na(age_cat, na_level = \"Missing age\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\n# table to view counts\ntable(linelist$age_cat, useNA = \"always\")\n\n\n        0-4         5-9       10-14       15-19       20-29       30-49 \n       1227        1223        1048         827        1216         848 \n      50-69      70-100 Missing age        &lt;NA&gt; \n        105           7         107           0 \n\n\nQuickly make breaks and labels\nFor a fast way to make breaks and label vectors, use something like below. See the R basics page for references on seq() and rep().\n\n# Make break points from 0 to 90 by 5\nage_seq = seq(from = 0, to = 90, by = 5)\nage_seq\n\n# Make labels for the above categories, assuming default cut() settings\nage_labels = paste0(age_seq + 1, \"-\", age_seq + 5)\nage_labels\n\n# check that both vectors are the same length\nlength(age_seq) == length(age_labels)\n\nRead more about cut() in its Help page by entering ?cut in the R console.\n\n\nQuantile breaks\nIn common understanding, “quantiles” or “percentiles” typically refer to a value below which a proportion of values fall. For example, the 95th percentile of ages in linelist would be the age below which 95% of the age fall.\nHowever in common speech, “quartiles” and “deciles” can also refer to the groups of data as equally divided into 4, or 10 groups (note there will be one more break point than group).\nTo get quantile break points, you can use quantile() from the stats package from base R. You provide a numeric vector (e.g. a column in a dataset) and vector of numeric probability values ranging from 0 to 1.0. The break points are returned as a numeric vector. Explore the details of the statistical methodologies by entering ?quantile.\n\nIf your input numeric vector has any missing values it is best to set na.rm = TRUE\n\nSet names = FALSE to get an un-named numeric vector\n\n\nquantile(linelist$age_years,               # specify numeric vector to work on\n  probs = c(0, .25, .50, .75, .90, .95),   # specify the percentiles you want\n  na.rm = TRUE)                            # ignore missing values \n\n 0% 25% 50% 75% 90% 95% \n  0   6  13  23  33  41 \n\n\nYou can use the results of quantile() as break points in age_categories() or cut(). Below we create a new column deciles using cut() where the breaks are defined using quantiles() on age_years. Below, we display the results using tabyl() from janitor so you can see the percentages (see the Descriptive tables page). Note how they are not exactly 10% in each group.\n\nlinelist %&gt;%                                # begin with linelist\n  mutate(deciles = cut(age_years,           # create new column decile as cut() on column age_years\n    breaks = quantile(                      # define cut breaks using quantile()\n      age_years,                               # operate on age_years\n      probs = seq(0, 1, by = 0.1),             # 0.0 to 1.0 by 0.1\n      na.rm = TRUE),                           # ignore missing values\n    include.lowest = TRUE)) %&gt;%             # for cut() include age 0\n  janitor::tabyl(deciles)                   # pipe to table to display\n\n deciles   n    percent valid_percent\n   [0,2] 748 0.11319613    0.11505922\n   (2,5] 721 0.10911017    0.11090601\n   (5,7] 497 0.07521186    0.07644978\n  (7,10] 698 0.10562954    0.10736810\n (10,13] 635 0.09609564    0.09767728\n (13,17] 755 0.11425545    0.11613598\n (17,21] 578 0.08746973    0.08890940\n (21,26] 625 0.09458232    0.09613906\n (26,33] 596 0.09019370    0.09167820\n (33,84] 648 0.09806295    0.09967697\n    &lt;NA&gt; 107 0.01619249            NA\n\n\n\n\nEvenly-sized groups\nAnother tool to make numeric groups is the the dplyr function ntile(), which attempts to break your data into n evenly-sized groups - but be aware that unlike with quantile() the same value could appear in more than one group. Provide the numeric vector and then the number of groups. The values in the new column created is just group “numbers” (e.g. 1 to 10), not the range of values themselves as when using cut().\n\n# make groups with ntile()\nntile_data &lt;- linelist %&gt;% \n  mutate(even_groups = ntile(age_years, 10))\n\n# make table of counts and proportions by group\nntile_table &lt;- ntile_data %&gt;% \n  janitor::tabyl(even_groups)\n  \n# attach min/max values to demonstrate ranges\nntile_ranges &lt;- ntile_data %&gt;% \n  group_by(even_groups) %&gt;% \n  summarise(\n    min = min(age_years, na.rm=T),\n    max = max(age_years, na.rm=T)\n  )\n\nWarning: There were 2 warnings in `summarise()`.\nThe first warning was:\nℹ In argument: `min = min(age_years, na.rm = T)`.\nℹ In group 11: `even_groups = NA`.\nCaused by warning in `min()`:\n! no non-missing arguments to min; returning Inf\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\n# combine and print - note that values are present in multiple groups\nleft_join(ntile_table, ntile_ranges, by = \"even_groups\")\n\n even_groups   n    percent valid_percent min  max\n           1 651 0.09851695    0.10013844   0    2\n           2 650 0.09836562    0.09998462   2    5\n           3 650 0.09836562    0.09998462   5    7\n           4 650 0.09836562    0.09998462   7   10\n           5 650 0.09836562    0.09998462  10   13\n           6 650 0.09836562    0.09998462  13   17\n           7 650 0.09836562    0.09998462  17   21\n           8 650 0.09836562    0.09998462  21   26\n           9 650 0.09836562    0.09998462  26   33\n          10 650 0.09836562    0.09998462  33   84\n          NA 107 0.01619249            NA Inf -Inf\n\n\n\n\n\ncase_when()\nIt is possible to use the dplyr function case_when() to create categories from a numeric column, but it is easier to use age_categories() from epikit or cut() because these will create an ordered factor automatically.\nIf using case_when(), please review the proper use as described earlier in the Re-code values section of this page. Also be aware that all right-hand side values must be of the same class. Thus, if you want NA on the right-side you should either write “Missing” or use the special NA value NA_character_.\n\n\nAdd to pipe chain\nBelow, code to create two categorical age columns is added to the cleaning pipe chain:\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # de-duplicate\n    distinct() %&gt;% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %&gt;% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################   \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html#add-rows",
    "href": "new_pages/cleaning.html#add-rows",
    "title": "7  Cleaning data and core functions",
    "section": "7.10 Add rows",
    "text": "7.10 Add rows\n\nOne-by-one\nAdding rows one-by-one manually is tedious but can be done with add_row() from dplyr. Remember that each column must contain values of only one class (either character, numeric, logical, etc.). So adding a row requires nuance to maintain this.\n\nlinelist &lt;- linelist %&gt;% \n  add_row(row_num = 666,\n          case_id = \"abc\",\n          generation = 4,\n          `infection date` = as.Date(\"2020-10-10\"),\n          .before = 2)\n\nUse .before and .after. to specify the placement of the row you want to add. .before = 3 will put the new row before the current 3rd row. The default behavior is to add the row to the end. Columns not specified will be left empty (NA).\nThe new row number may look strange (“…23”) but the row numbers in the pre-existing rows have changed. So if using the command twice, examine/test the insertion carefully.\nIf a class you provide is off you will see an error like this:\nError: Can't combine ..1$infection date &lt;date&gt; and ..2$infection date &lt;character&gt;.\n(when inserting a row with a date value, remember to wrap the date in the function as.Date() like as.Date(\"2020-10-10\")).\n\n\nBind rows\nTo combine datasets together by binding the rows of one dataframe to the bottom of another data frame, you can use bind_rows() from dplyr. This is explained in more detail in the page Joining data.",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html#filter-rows",
    "href": "new_pages/cleaning.html#filter-rows",
    "title": "7  Cleaning data and core functions",
    "section": "7.11 Filter rows",
    "text": "7.11 Filter rows\nA typical cleaning step after you have cleaned the columns and re-coded values is to filter the data frame for specific rows using the dplyr verb filter().\nWithin filter(), specify the logic that must be TRUE for a row in the dataset to be kept. Below we show how to filter rows based on simple and complex logical conditions.\n\n\nSimple filter\nThis simple example re-defines the dataframe linelist as itself, having filtered the rows to meet a logical condition. Only the rows where the logical statement within the parentheses evaluates to TRUE are kept.\nIn this example, the logical statement is gender == \"f\", which is asking whether the value in the column gender is equal to “f” (case sensitive).\nBefore the filter is applied, the number of rows in linelist is nrow(linelist).\n\nlinelist &lt;- linelist %&gt;% \n  filter(gender == \"f\")   # keep only rows where gender is equal to \"f\"\n\nAfter the filter is applied, the number of rows in linelist is linelist %&gt;% filter(gender == \"f\") %&gt;% nrow().\n\n\nFilter out missing values\nIt is fairly common to want to filter out rows that have missing values. Resist the urge to write filter(!is.na(column) & !is.na(column)) and instead use the tidyr function that is custom-built for this purpose: drop_na(). If run with empty parentheses, it removes rows with any missing values. Alternatively, you can provide names of specific columns to be evaluated for missingness, or use the “tidyselect” helper functions described above.\n\nlinelist %&gt;% \n  drop_na(case_id, age_years)  # drop rows with missing values for case_id or age_years\n\nSee the page on Missing data for many techniques to analyse and manage missingness in your data.\n\n\nFilter by row number\nIn a data frame or tibble, each row will usually have a “row number” that (when seen in R Viewer) appears to the left of the first column. It is not itself a true column in the data, but it can be used in a filter() statement.\nTo filter based on “row number”, you can use the dplyr function row_number() with open parentheses as part of a logical filtering statement. Often you will use the %in% operator and a range of numbers as part of that logical statement, as shown below. To see the first N rows, you can also use the special dplyr function head().\n\n# View first 100 rows\nlinelist %&gt;% head(100)     # or use tail() to see the n last rows\n\n# Show row 5 only\nlinelist %&gt;% filter(row_number() == 5)\n\n# View rows 2 through 20, and three specific columns\nlinelist %&gt;% filter(row_number() %in% 2:20) %&gt;% select(date_onset, outcome, age)\n\nYou can also convert the row numbers to a true column by piping your data frame to the tibble function rownames_to_column() (do not put anything in the parentheses).\n\n\n\nComplex filter\nMore complex logical statements can be constructed using parentheses ( ), OR |, negate !, %in%, and AND & operators. An example is below:\nNote: You can use the ! operator in front of a logical criteria to negate it. For example, !is.na(column) evaluates to true if the column value is not missing. Likewise !column %in% c(\"a\", \"b\", \"c\") evaluates to true if the column value is not in the vector.\n\nExamine the data\nBelow is a simple one-line command to create a histogram of onset dates. See that a second smaller outbreak from 2012-2013 is also included in this raw dataset. For our analyses, we want to remove entries from this earlier outbreak.\n\nhist(linelist$date_onset, breaks = 50)\n\n\n\n\n\n\n\n\n\n\nHow filters handle missing numeric and date values\nCan we just filter by date_onset to rows after June 2013? Caution! Applying the code filter(date_onset &gt; as.Date(\"2013-06-01\"))) would remove any rows in the later epidemic with a missing date of onset!\nDANGER: Filtering to greater than (&gt;) or less than (&lt;) a date or number can remove any rows with missing values (NA)! This is because NA is treated as infinitely large and small.\n(See the page on Working with dates for more information on working with dates and the package lubridate)\n\n\nDesign the filter\nExamine a cross-tabulation to make sure we exclude only the correct rows:\n\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values\n\n                                      YearOnset\nHospital                               2012 2013 2014 2015 &lt;NA&gt;\n  Central Hospital                        0    0  351   99   18\n  Hospital A                            229   46    0    0   15\n  Hospital B                            227   47    0    0   15\n  Military Hospital                       0    0  676  200   34\n  Missing                                 0    0 1117  318   77\n  Other                                   0    0  684  177   46\n  Port Hospital                           9    1 1372  347   75\n  St. Mark's Maternity Hospital (SMMH)    0    0  322   93   13\n  &lt;NA&gt;                                    0    0    0    0    0\n\n\nWhat other criteria can we filter on to remove the first outbreak (in 2012 & 2013) from the dataset? We see that:\n\nThe first epidemic in 2012 & 2013 occurred at Hospital A, Hospital B, and that there were also 10 cases at Port Hospital.\n\nHospitals A & B did not have cases in the second epidemic, but Port Hospital did.\n\nWe want to exclude:\n\nThe nrow(linelist %&gt;% filter(hospital %in% c(\"Hospital A\", \"Hospital B\") | date_onset &lt; as.Date(\"2013-06-01\"))) rows with onset in 2012 and 2013 at either hospital A, B, or Port:\n\nExclude nrow(linelist %&gt;% filter(date_onset &lt; as.Date(\"2013-06-01\"))) rows with onset in 2012 and 2013\nExclude nrow(linelist %&gt;% filter(hospital %in% c('Hospital A', 'Hospital B') & is.na(date_onset))) rows from Hospitals A & B with missing onset dates\n\nDo not exclude nrow(linelist %&gt;% filter(!hospital %in% c('Hospital A', 'Hospital B') & is.na(date_onset))) other rows with missing onset dates.\n\n\nWe start with a linelist of nrow(linelist)`. Here is our filter statement:\n\nlinelist &lt;- linelist %&gt;% \n  # keep rows where onset is after 1 June 2013 OR where onset is missing and it was a hospital OTHER than Hospital A or B\n  filter(date_onset &gt; as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))\n\nnrow(linelist)\n\n[1] 6019\n\n\nWhen we re-make the cross-tabulation, we see that Hospitals A & B are removed completely, and the 10 Port Hospital cases from 2012 & 2013 are removed, and all other values are the same - just as we wanted.\n\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values\n\n                                      YearOnset\nHospital                               2014 2015 &lt;NA&gt;\n  Central Hospital                      351   99   18\n  Military Hospital                     676  200   34\n  Missing                              1117  318   77\n  Other                                 684  177   46\n  Port Hospital                        1372  347   75\n  St. Mark's Maternity Hospital (SMMH)  322   93   13\n  &lt;NA&gt;                                    0    0    0\n\n\nMultiple statements can be included within one filter command (separated by commas), or you can always pipe to a separate filter() command for clarity.\nNote: some readers may notice that it would be easier to just filter by date_hospitalisation because it is 100% complete with no missing values. This is true. But date_onset is used for purposes of demonstrating a complex filter.\n\n\n\nStandalone\nFiltering can also be done as a stand-alone command (not part of a pipe chain). Like other dplyr verbs, in this case the first argument must be the dataset itself.\n\n# dataframe &lt;- filter(dataframe, condition(s) for rows to keep)\n\nlinelist &lt;- filter(linelist, !is.na(case_id))\n\nYou can also use base R to subset using square brackets which reflect the [rows, columns] that you want to retain.\n\n# dataframe &lt;- dataframe[row conditions, column conditions] (blank means keep all)\n\nlinelist &lt;- linelist[!is.na(case_id), ]\n\n\n\nQuickly review records\nOften you want to quickly review a few records, for only a few columns. The base R function View() will print a data frame for viewing in your RStudio.\nView the linelist in RStudio:\n\nView(linelist)\n\nHere are two examples of viewing specific cells (specific rows, and specific columns):\nWith dplyr functions filter() and select():\nWithin View(), pipe the dataset to filter() to keep certain rows, and then to select() to keep certain columns. For example, to review onset and hospitalization dates of 3 specific cases:\n\nView(linelist %&gt;%\n       filter(case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\")) %&gt;%\n       select(date_onset, date_hospitalisation))\n\nYou can achieve the same with base R syntax, using brackets [ ] to subset you want to see.\n\nView(linelist[linelist$case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\"), c(\"date_onset\", \"date_hospitalisation\")])\n\n\nAdd to pipe chain\n\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist &lt;- linelist_raw %&gt;%\n    \n    # standardize column name syntax\n    janitor::clean_names() %&gt;% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %&gt;% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %&gt;% \n  \n    # de-duplicate\n    distinct() %&gt;% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %&gt;%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %&gt;% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %&gt;% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %&gt;% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %&gt;% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %&gt;% \n  \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %&gt;% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    filter(\n          # keep only rows where case_id is not missing\n          !is.na(case_id),  \n          \n          # also filter to keep only the second outbreak\n          date_onset &gt; as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html#row-wise-calculations",
    "href": "new_pages/cleaning.html#row-wise-calculations",
    "title": "7  Cleaning data and core functions",
    "section": "7.12 Row-wise calculations",
    "text": "7.12 Row-wise calculations\nIf you want to perform a calculation within a row, you can use rowwise() from dplyr. See this online vignette on row-wise calculations. For example, this code applies rowwise() and then creates a new column that sums the number of the specified symptom columns that have value “yes”, for each row in the linelist. The columns are specified within sum() by name within a vector c(). rowwise() is essentially a special kind of group_by(), so it is best to use ungroup() when you are done (page on Grouping data).\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == \"yes\")) %&gt;% \n  ungroup() %&gt;% \n  select(fever, chills, cough, aches, vomit, num_symptoms) # for display\n\n# A tibble: 5,888 × 6\n   fever chills cough aches vomit num_symptoms\n   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;int&gt;\n 1 no    no     yes   no    yes              2\n 2 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 3 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 4 no    no     no    no    no               0\n 5 no    no     yes   no    yes              2\n 6 no    no     yes   no    yes              2\n 7 &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;            NA\n 8 no    no     yes   no    yes              2\n 9 no    no     yes   no    yes              2\n10 no    no     yes   no    no               1\n# ℹ 5,878 more rows\n\n\nAs you specify the column to evaluate, you may want to use the “tidyselect” helper functions described in the select() section of this page. You just have to make one adjustment (because you are not using them within a dplyr function like select() or summarise()).\nPut the column-specification criteria within the dplyr function c_across(). This is because c_across (documentation) is designed to work with rowwise() specifically. For example, the following code:\n\nApplies rowwise() so the following operation (sum()) is applied within each row (not summing entire columns)\n\nCreates new column num_NA_dates, defined for each row as the number of columns (with name containing “date”) for which is.na() evaluated to TRUE (they are missing data).\n\nungroup() to remove the effects of rowwise() for subsequent steps\n\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(num_NA_dates = sum(is.na(c_across(contains(\"date\"))))) %&gt;% \n  ungroup() %&gt;% \n  select(num_NA_dates, contains(\"date\")) # for display\n\n# A tibble: 5,888 × 5\n   num_NA_dates date_infection date_onset date_hospitalisation date_outcome\n          &lt;int&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1            1 2014-05-08     2014-05-13 2014-05-15           NA          \n 2            1 NA             2014-05-13 2014-05-14           2014-05-18  \n 3            1 NA             2014-05-16 2014-05-18           2014-05-30  \n 4            1 2014-05-04     2014-05-18 2014-05-20           NA          \n 5            0 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6            0 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7            0 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8            0 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9            1 NA             2014-06-05 2014-06-06           2014-06-18  \n10            1 NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows\n\n\nYou could also provide other functions, such as max() to get the latest or most recent date for each row:\n\nlinelist %&gt;%\n  rowwise() %&gt;%\n  mutate(latest_date = max(c_across(contains(\"date\")), na.rm=T)) %&gt;% \n  ungroup() %&gt;% \n  select(latest_date, contains(\"date\"))  # for display\n\n# A tibble: 5,888 × 5\n   latest_date date_infection date_onset date_hospitalisation date_outcome\n   &lt;date&gt;      &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 2014-05-15  2014-05-08     2014-05-13 2014-05-15           NA          \n 2 2014-05-18  NA             2014-05-13 2014-05-14           2014-05-18  \n 3 2014-05-30  NA             2014-05-16 2014-05-18           2014-05-30  \n 4 2014-05-20  2014-05-04     2014-05-18 2014-05-20           NA          \n 5 2014-05-29  2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6 2014-05-24  2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7 2014-06-01  2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8 2014-06-07  2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9 2014-06-18  NA             2014-06-05 2014-06-06           2014-06-18  \n10 2014-06-09  NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/cleaning.html#arrange-and-sort",
    "href": "new_pages/cleaning.html#arrange-and-sort",
    "title": "7  Cleaning data and core functions",
    "section": "7.13 Arrange and sort",
    "text": "7.13 Arrange and sort\nUse the dplyr function arrange() to sort or order the rows by column values.\nSimple list the columns in the order they should be sorted on. Specify .by_group = TRUE if you want the sorting to to first occur by any groupings applied to the data (see page on Grouping data).\nBy default, column will be sorted in “ascending” order (which applies to numeric and also to character columns). You can sort a variable in “descending” order by wrapping it with desc().\nSorting data with arrange() is particularly useful when making Tables for presentation, using slice() to take the “top” rows per group, or setting factor level order by order of appearance.\nFor example, to sort the our linelist rows by hospital, then by date_onset in descending order, we would use:\n\nlinelist %&gt;% \n   arrange(hospital, desc(date_onset))",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cleaning data and core functions</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.html",
    "href": "new_pages/iteration.html",
    "title": "8  Iteration, loops, and lists",
    "section": "",
    "text": "8.1 Preparation",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Iteration, loops, and lists</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.html#preparation",
    "href": "new_pages/iteration.html#preparation",
    "title": "8  Iteration, loops, and lists",
    "section": "",
    "text": "Load packages\nThis code chunk shows the loading of packages required for the analyses. In this handbook we emphasize p_load() from pacman, which installs the package if necessary and loads it for use. You can also load installed packages with library() from base R. See the page on R basics for more information on R packages.\n\npacman::p_load(\n     rio,         # import/export\n     here,        # file locator\n     purrr,       # iteration\n     grates,      # scales in ggplot\n     tidyverse    # data management and visualization\n)\n\n\n\nImport data\nWe import the dataset of cases from a simulated Ebola epidemic. If you want to follow along, click to download the “clean” linelist (as .rds file). Import data with the import() function from the rio package (it handles many file types like .xlsx, .csv, .rds - see the Import and export page for details).\n\n# import the linelist\nlinelist &lt;- import(\"linelist_cleaned.rds\")\n\nThe first 50 rows of the linelist are displayed below.",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Iteration, loops, and lists</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.html#for-loops",
    "href": "new_pages/iteration.html#for-loops",
    "title": "8  Iteration, loops, and lists",
    "section": "8.2 for loops",
    "text": "8.2 for loops\n\nfor loops in R\nfor loops are not emphasized in R, but are common in other programming languages. As a beginner, they can be helpful to learn and practice with because they are easier to “explore”, “de-bug”, and otherwise grasp exactly what is happening for each iteration, especially when you are not yet comfortable writing your own functions.\nYou may move quickly through for loops to iterating with mapped functions with purrr (see section below).\n\n\nCore components\nA for loop has three core parts:\n\nThe sequence of items to iterate through\n\nThe operations to conduct per item in the sequence\n\nThe container for the results (optional)\n\nThe basic syntax is: for (item in sequence) {do operations using item}. Note the parentheses and the curly brackets. The results could be printed to console, or stored in a container R object.\nA simple for loop example is below.\n\nfor (num in c(1,2,3,4,5)) {  # the SEQUENCE is defined (numbers 1 to 5) and loop is opened with \"{\"\n  print(num + 2)             # The OPERATIONS (add two to each sequence number and print)\n}                            # The loop is closed with \"}\"                            \n\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n\n                             # There is no \"container\" in this example\n\n\n\nSequence\nThis is the “for” part of a for loop - the operations will run “for” each item in the sequence. The sequence can be a series of values (e.g. names of jurisdictions, diseases, column names, list elements, etc), or it can be a series of consecutive numbers (e.g. 1,2,3,4,5). Each approach has their own utilities, described below.\nThe basic structure of a sequence statement is item in vector.\n\nYou can write any character or word in place of “item” (e.g. “i”, “num”, “hosp”, “district”, etc.). The value of this “item” changes with each iteration of the loop, proceeding through each value in the vector.\n\nThe vector could be of character values, column names, or perhaps a sequence of numbers - these are the values that will change with each iteration. You can use them within the for loop operations using the “item” term.\n\nExample: sequence of character values\nIn this example, a loop is performed for each value in a pre-defined character vector of hospital names.\n\n# make vector of the hospital names\nhospital_names &lt;- unique(linelist$hospital)\nhospital_names # print\n\n[1] \"Other\"                               \n[2] \"Missing\"                             \n[3] \"St. Mark's Maternity Hospital (SMMH)\"\n[4] \"Port Hospital\"                       \n[5] \"Military Hospital\"                   \n[6] \"Central Hospital\"                    \n\n\nWe have chosen the term hosp to represent values from the vector hospital_names. For the first iteration of the loop, the value of hosp will be hospital_names[[1]]. For the second loop it will be hospital_names[[2]]. And so on…\n\n# a 'for loop' with character sequence\n\nfor (hosp in hospital_names){       # sequence\n  \n       # OPERATIONS HERE\n  }\n\nExample: sequence of column names\nThis is a variation on the character sequence above, in which the names of an existing R object are extracted and become the vector. For example, the column names of a data frame. Conveniently, in the operations code of the for loop, the column names can be used to index (subset) their original data frame\nBelow, the sequence is the names() (column names) of the linelist data frame. Our “item” name is col, which will represent each column name as the loops proceeds.\nFor purposes of example, we include operations code inside the for loop, which is run for every value in the sequence. In this code, the sequence values (column names) are used to index (subset) linelist, one-at-a-time. As taught in the R basics page, double branckets [[ ]] are used to subset. The resulting column is passed to is.na(), then to sum() to produce the number of values in the column that are missing. The result is printed to the console - one number for each column.\nA note on indexing with column names - whenever referencing the column itself do not just write “col”! col represents just the character column name! To refer to the entire column you must use the column name as an index on linelist via linelist[[col]].\n\nfor (col in names(linelist)){        # loop runs for each column in linelist; column name represented by \"col\" \n  \n  # Example operations code - print number of missing values in column\n  print(sum(is.na(linelist[[col]])))  # linelist is indexed by current value of \"col\"\n     \n}\n\n[1] 0\n[1] 0\n[1] 2087\n[1] 256\n[1] 0\n[1] 936\n[1] 1323\n[1] 278\n[1] 86\n[1] 0\n[1] 86\n[1] 86\n[1] 86\n[1] 0\n[1] 0\n[1] 0\n[1] 2088\n[1] 2088\n[1] 0\n[1] 0\n[1] 0\n[1] 249\n[1] 249\n[1] 249\n[1] 249\n[1] 249\n[1] 149\n[1] 765\n[1] 0\n[1] 256\n\n\nSequence of numbers\nIn this approach, the sequence is a series of consecutive numbers. Thus, the value of the “item” is not a character value (e.g. “Central Hospital” or “date_onset”) but is a number. This is useful for looping through data frames, as you can use the “item” number inside the for loop to index the data frame by row number.\nFor example, let’s say that you want to loop through every row in your data frame and extract certain information. Your “items” would be numeric row numbers. Often, “items” in this case are written as i.\nThe for loop process could be explained in words as “for every item in a sequence of numbers from 1 to the total number of rows in my data frame, do X”. For the first iteration of the loop, the value of “item” i would be 1. For the second iteration, i would be 2, etc.\nHere is what the sequence looks like in code: for (i in 1:nrow(linelist)) {OPERATIONS CODE} where i represents the “item” and 1:nrow(linelist) produces a sequence of consecutive numbers from 1 through the number of rows in linelist.\n\nfor (i in 1:nrow(linelist)) {  # use on a data frame\n  # OPERATIONS HERE\n}  \n\nIf you want the sequence to be numbers, but you are starting from a vector (not a data frame), use the shortcut seq_along() to return a sequence of numbers for each element in the vector. For example, for (i in seq_along(hospital_names) {OPERATIONS CODE}.\nThe below code actually returns numbers, which would become the value of i in their respective loop.\n\nseq_along(hospital_names)  # use on a named vector\n\n[1] 1 2 3 4 5 6\n\n\nOne advantage of using numbers in the sequence is that is easy to also use the i number to index a container that stores the loop outputs. There is an example of this in the Operations section below.\n\n\nOperations\nThis is code within the curly brackets { } of the for loop. You want this code to run for each “item” in the sequence. Therefore, be careful that every part of your code that changes by the “item” is correctly coded such that it actually changes! E.g. remember to use [[ ]] for indexing.\nIn the example below, we iterate through each row in the linelist. The gender and age values of each row are pasted together and stored in the container character vector cases_demographics. Note how we also use indexing [[i]] to save the loop output to the correct position in the “container” vector.\n\n# create container to store results - a character vector\ncases_demographics &lt;- vector(mode = \"character\", length = nrow(linelist))\n\n# the for loop\nfor (i in 1:nrow(linelist)){\n  \n  # OPERATIONS\n  # extract values from linelist for row i, using brackets for indexing\n  row_gender  &lt;- linelist$gender[[i]]\n  row_age     &lt;- linelist$age_years[[i]]    # don't forget to index!\n     \n  # combine gender-age and store in container vector at indexed location\n  cases_demographics[[i]] &lt;- str_c(row_gender, row_age, sep = \",\") \n\n}  # end for loop\n\n\n# display first 10 rows of container\nhead(cases_demographics, 10)\n\n [1] \"m,2\"  \"f,3\"  \"m,56\" \"f,18\" \"m,3\"  \"f,16\" \"f,16\" \"f,0\"  \"m,61\" \"f,27\"\n\n\n\n\nContainer\nSometimes the results of your for loop will be printed to the console or RStudio Plots pane. Other times, you will want to store the outputs in a “container” for later use. Such a container could be a vector, a data frame, or even a list.\nIt is most efficient to create the container for the results before even beginning the for loop. In practice, this means creating an empty vector, data frame, or list. These can be created with the functions vector() for vectors or lists, or with matrix() and data.frame() for a data frame.\nEmpty vector\nUse vector() and specify the mode = based on the expected class of the objects you will insert - either “double” (to hold numbers), “character”, or “logical”. You should also set the length = in advance. This should be the length of your for loop sequence.\nSay you want to store the median delay-to-admission for each hospital. You would use “double” and set the length to be the number of expected outputs (the number of unique hospitals in the data set).\n\ndelays &lt;- vector(\n  mode = \"double\",                            # we expect to store numbers\n  length = length(unique(linelist$hospital))) # the number of unique hospitals in the dataset\n\nEmpty data frame\nYou can make an empty data frame by specifying the number of rows and columns like this:\n\ndelays &lt;- data.frame(matrix(ncol = 2, nrow = 3))\n\nEmpty list\nYou may want store some plots created by a for loop in a list. A list is like vector, but holds other R objects within it that can be of different classes. Items in a list could be a single number, a dataframe, a vector, and even another list.\nYou actually initialize an empty list using the same vector() command as above, but with mode = \"list\". Specify the length however you wish.\n\nplots &lt;- vector(mode = \"list\", length = 16)\n\n\n\nPrinting\nNote that to print from within a for loop you will likely need to explicitly wrap with the function print().\nIn this example below, the sequence is an explicit character vector, which is used to subset the linelist by hospital. The results are not stored in a container, but rather are printed to console with the print() function.\n\nfor (hosp in hospital_names){ \n     hospital_cases &lt;- linelist %&gt;% filter(hospital == hosp)\n     print(nrow(hospital_cases))\n}\n\n[1] 885\n[1] 1469\n[1] 422\n[1] 1762\n[1] 896\n[1] 454\n\n\n\n\nTesting your for loop\nTo test your loop, you can run a command to make a temporary assignment of the “item”, such as i &lt;- 10 or hosp &lt;- \"Central Hospital\". Do this outside the loop and then run your operations code only (the code within the curly brackets) to see if the expected results are produced.\n\n\nLooping plots\nTo put all three components together (container, sequence, and operations) let’s try to plot an epicurve for each hospital (see page on Epidemic curves).\nWe can make a nice epicurve of all the cases by gender using the incidence2 package as below:\n\n# create 'incidence' object\noutbreak &lt;- incidence2::incidence(   \n     x = linelist,                   # dataframe - complete linelist\n     date_index = \"date_onset\",        # date column\n     interval = \"week\",              # aggregate counts weekly\n     groups = \"gender\")               # group values by gender\n     #na_as_group = TRUE)             # missing gender is own group\n\n# tracer la courbe d'épidémie\nggplot(outbreak, # nom de l'objet d'incidence\n        aes(x = date_index, #aesthetiques et axes\n            y = count, \n            fill = gender), # Fill colour of bars by gender\n       color = \"black\"      # Contour colour of bars\n       ) +  \n     geom_col() + \n     facet_wrap(~gender) +\n     theme_bw() + \n     labs(title = \"Outbreak of all cases\", #titre\n          x = \"Counts\", \n          y = \"Date\", \n          fill = \"Gender\", \n          color = \"Gender\")\n\n\n\n\n\n\n\n\nTo produce a separate plot for each hospital’s cases, we can put this epicurve code within a for loop.\nFirst, we save a named vector of the unique hospital names, hospital_names. The for loop will run once for each of these names: for (hosp in hospital_names). Each iteration of the for loop, the current hospital name from the vector will be represented as hosp for use within the loop.\nWithin the loop operations, you can write R code as normal, but use the “item” (hosp in this case) knowing that its value will be changing. Within this loop:\n\nA filter() is applied to linelist, such that column hospital must equal the current value of hosp\n\nThe incidence object is created on the filtered linelist\n\nThe plot for the current hospital is created, with an auto-adjusting title that uses hosp\n\nThe plot for the current hospital is temporarily saved and then printed\n\nThe loop then moves onward to repeat with the next hospital in hospital_names\n\n\n# make vector of the hospital names\nhospital_names &lt;- unique(linelist$hospital)\n\n# for each name (\"hosp\") in hospital_names, create and print the epi curve\nfor (hosp in hospital_names) {\n     \n     # create incidence object specific to the current hospital\n     outbreak_hosp &lt;- incidence2::incidence(\n          x = linelist %&gt;% filter(hospital == hosp),   # linelist is filtered to the current hospital\n          date_index = \"date_onset\",\n          interval = \"week\", \n          groups = \"gender\"#,\n          #na_as_group = TRUE\n     )\n     \n      plot_hosp &lt;- ggplot(outbreak_hosp, # incidence object name\n                         aes(x = date_index, #axes\n                             y = count, \n                             fill = gender), # fill colour by gender\n                         color = \"black\"      # colour of bar contour\n                         ) +  \n          geom_col() + \n          facet_wrap(~gender) +\n          theme_bw() + \n          labs(title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\"), #title\n               x = \"Counts\", \n               y = \"Date\", \n               fill = \"Gender\", \n               color = \"Gender\")\n     \n     # With older versions of R, remove the # before na_as_group and use this plot command instead.\n    # plot_hosp &lt;- plot(\n#       outbreak_hosp,\n#       fill = \"gender\",\n#       color = \"black\",\n#       title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\")\n#     )\n     \n     #print the plot for hospitals\n     print(plot_hosp)\n     \n} # end the for loop when it has been run for every hospital in hospital_names \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTracking progress of a loop\nA loop with many iterations can run for many minutes or even hours. Thus, it can be helpful to print the progress to the R console. The if statement below can be placed within the loop operations to print every 100th number. Just adjust it so that i is the “item” in your loop.\n\n# loop with code to print progress every 100 iterations\nfor (i in seq_len(nrow(linelist))){\n\n  # print progress\n  if(i %% 100==0){    # The %% operator is the remainder\n    print(i)\n\n}",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Iteration, loops, and lists</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.html#iter_purrr",
    "href": "new_pages/iteration.html#iter_purrr",
    "title": "8  Iteration, loops, and lists",
    "section": "8.3 purrr and lists",
    "text": "8.3 purrr and lists\nAnother approach to iterative operations is the purrr package - it is the tidyverse approach to iteration.\nIf you are faced with performing the same task several times, it is probably worth creating a generalised solution that you can use across many inputs. For example, producing plots for multiple jurisdictions, or importing and combining many files.\nThere are also a few other advantages to purrr - you can use it with pipes %&gt;%, it handles errors better than normal for loops, and the syntax is quite clean and simple! If you are using a for loop, you can probably do it more clearly and succinctly with purrr!\nKeep in mind that purrr is a functional programming tool. That is, the operations that are to be iteratively applied are wrapped up into functions. See the Writing functions page to learn how to write your own functions.\npurrr is also almost entirely based around lists and vectors - so think about it as applying a function to each element of that list/vector!\n\nLoad packages\npurrr is part of the tidyverse, so there is no need to install/load a separate package.\n\npacman::p_load(\n     rio,            # import/export\n     here,           # relative filepaths\n     tidyverse,      # data mgmt and viz\n     writexl,        # write Excel file with multiple sheets\n     readxl          # import Excel with multiple sheets\n)\n\n\n\nmap()\nOne core purrr function is map(), which “maps” (applies) a function to each input element of a list/vector you provide.\nThe basic syntax is map(.x = SEQUENCE, .f = FUNCTION, OTHER ARGUMENTS). In a bit more detail:\n\n.x = are the inputs upon which the .f function will be iteratively applied - e.g. a vector of jurisdiction names, columns in a data frame, or a list of data frames\n\n.f = is the function to apply to each element of the .x input - it could be a function like print() that already exists, or a custom function that you define. The function is often written after a tilde ~ (details below).\n\nA few more notes on syntax:\n\nIf the function needs no further arguments specified, it can be written with no parentheses and no tilde (e.g. .f = mean). To provide arguments that will be the same value for each iteration, provide them within map() but outside the .f = argument, such as the na.rm = T in map(.x = my_list, .f = mean, na.rm=T).\n\nYou can use .x (or simply .) within the .f = function as a placeholder for the .x value of that iteration\n\nUse tilde syntax (~) to have greater control over the function - write the function as normal with parentheses, such as: map(.x = my_list, .f = ~mean(., na.rm = T)). Use this syntax particularly if the value of an argument will change each iteration, or if it is the value .x itself (see examples below)\n\nThe output of using map() is a list - a list is an object class like a vector but whose elements can be of different classes. So, a list produced by map() could contain many data frames, or many vectors, many single values, or even many lists! There are alternative versions of map() explained below that produce other types of outputs (e.g. map_dfr() to produce a data frame, map_chr() to produce character vectors, and map_dbl() to produce numeric vectors).\n\nExample - import and combine Excel sheets\nLet’s demonstrate with a common epidemiologist task: - You want to import an Excel workbook with case data, but the data are split across different named sheets in the workbook. How do you efficiently import and combine the sheets into one data frame?\nLet’s say we are sent the below Excel workbook. Each sheet contains cases from a given hospital.\n\n\n\n\n\n\n\n\n\nHere is one approach that uses map():\n\nmap() the function import() so that it runs for each Excel sheet\n\nCombine the imported data frames into one using bind_rows()\n\nAlong the way, preserve the original sheet name for each row, storing this information in a new column in the final data frame\n\nFirst, we need to extract the sheet names and save them. We provide the Excel workbook’s file path to the function excel_sheets() from the package readxl, which extracts the sheet names. We store them in a character vector called sheet_names.\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\")\n\nHere are the names:\n\nsheet_names\n\n[1] \"Central Hospital\"              \"Military Hospital\"            \n[3] \"Missing\"                       \"Other\"                        \n[5] \"Port Hospital\"                 \"St. Mark's Maternity Hospital\"\n\n\nNow that we have this vector of names, map() can provide them one-by-one to the function import(). In this example, the sheet_names are .x and import() is the function .f.\nRecall from the Import and export page that when used on Excel workbooks, import() can accept the argument which = specifying the sheet to import. Within the .f function import(), we provide which = .x, whose value will change with each iteration through the vector sheet_names - first “Central Hospital”, then “Military Hospital”, etc.\nOf note - because we have used map(), the data in each Excel sheet will be saved as a separate data frame within a list. We want each of these list elements (data frames) to have a name, so before we pass sheet_names to map() we pass it through set_names() from purrr, which ensures that each list element gets the appropriate name.\nWe save the output list as combined.\n\ncombined &lt;- sheet_names %&gt;% \n  purrr::set_names() %&gt;% \n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x))\n\nWhen we inspect output, we see that the data from each Excel sheet is saved in the list with a name. This is good, but we are not quite finished.\n\n\n\n\n\n\n\n\n\nLastly, we use the function bind_rows() (from dplyr) which accepts the list of similarly-structured data frames and combines them into one data frame. To create a new column from the list element names, we use the argument .id = and provide it with the desired name for the new column.\nBelow is the whole sequence of commands:\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\")  # extract sheet names\n \ncombined &lt;- sheet_names %&gt;%                                     # begin with sheet names\n  purrr::set_names() %&gt;%                                        # set their names\n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x)) %&gt;%  # iterate, import, save in list\n  bind_rows(.id = \"origin_sheet\") # combine list of data frames, preserving origin in new column  \n\nAnd now we have one data frame with a column containing the sheet of origin!\n\n\n\n\n\n\n\n\n\nThere are variations of map() that you should be aware of. For example, map_dfr() returns a data frame, not a list. Thus, we could have used it for the task above and not have had to bind rows. But then we would not have been able to capture which sheet (hospital) each case came from.\nOther variations include map_chr(), map_dbl(). These are very useful functions for two reasons. Firstly. they automatically convert the output of an iterative function into a vector (not a list). Secondly, they can explicitly control the class that the data comes back in - you ensure that your data comes back as a character vector with map_chr(), or numeric vector with map_dbl(). Lets return to these later in the section!\nThe functions map_at() and map_if() are also very useful for iteration - they allow you to specify which elements of a list you should iterate at! These work by simply applying a vector of indexes/names (in the case of map_at()) or a logical test (in the case of map_if()).\nLets use an example where we didn’t want to read the first sheet of hospital data. We use map_at() instead of map(), and specify the .at = argument to c(-1) which means to not use the first element of .x. Alternatively, you can provide a vector of positive numbers, or names, to .at = to specify which elements to use.\n\nsheet_names &lt;- readxl::excel_sheets(\"hospital_linelists.xlsx\")\n\ncombined &lt;- sheet_names %&gt;% \n     purrr::set_names() %&gt;% \n     # exclude the first sheet\n     map_at(.f = ~import( \"hospital_linelists.xlsx\", which = .x),\n            .at = c(-1))\n\nNote that the first sheet name will still appear as an element of the output list - but it is only a single character name (not a data frame). You would need to remove this element before binding rows. We will cover how to remove and modify list elements in a later section.\n\n\n\nSplit dataset and export\nBelow, we give an example of how to split a dataset into parts and then use map() iteration to export each part as a separate Excel sheet, or as a separate CSV file.\n\nSplit dataset\nLet’s say we have the complete case linelist as a data frame, and we now want to create a separate linelist for each hospital and export each as a separate CSV file. Below, we do the following steps:\nUse group_split() (from dplyr) to split the linelist data frame by unique values in column hospital. The output is a list containing one data frame per hospital subset.\n\nlinelist_split &lt;- linelist %&gt;% \n     group_split(hospital)\n\nWe can run View(linelist_split) and see that this list contains 6 data frames (“tibbles”), each representing the cases from one hospital.\n\n\n\n\n\n\n\n\n\nHowever, note that the data frames in the list do not have names by default! We want each to have a name, and then to use that name when saving the CSV file.\nOne approach to extracting the names is to use pull() (from dplyr) to extract the hospital column from each data frame in the list. Then, to be safe, we convert the values to character and then use unique() to get the name for that particular data frame. All of these steps are applied to each data frame via map().\n\nnames(linelist_split) &lt;- linelist_split %&gt;%   # Assign to names of listed data frames \n     # Extract the names by doing the following to each data frame: \n     map(.f = ~pull(.x, hospital)) %&gt;%        # Pull out hospital column\n     map(.f = ~as.character(.x)) %&gt;%          # Convert to character, just in case\n     map(.f = ~unique(.x))                    # Take the unique hospital name\n\nWe can now see that each of the list elements has a name. These names can be accessed via names(linelist_split).\n\n\n\n\n\n\n\n\n\n\nnames(linelist_split)\n\n[1] \"Central Hospital\"                    \n[2] \"Military Hospital\"                   \n[3] \"Missing\"                             \n[4] \"Other\"                               \n[5] \"Port Hospital\"                       \n[6] \"St. Mark's Maternity Hospital (SMMH)\"\n\n\n\nMore than one group_split() column\nIf you wanted to split the linelist by more than one grouping column, such as to produce subset linelist by intersection of hospital AND gender, you will need a different approach to naming the list elements. This involves collecting the unique “group keys” using group_keys() from dplyr - they are returned as a data frame. Then you can combine the group keys into values with unite() as shown below, and assign these conglomerate names to linelist_split.\n\n# split linelist by unique hospital-gender combinations\nlinelist_split &lt;- linelist %&gt;% \n     group_split(hospital, gender)\n\n# extract group_keys() as a dataframe\ngroupings &lt;- linelist %&gt;% \n     group_by(hospital, gender) %&gt;%       \n     group_keys()\n\ngroupings      # show unique groupings \n\n# A tibble: 18 × 2\n   hospital                             gender\n   &lt;chr&gt;                                &lt;chr&gt; \n 1 Central Hospital                     f     \n 2 Central Hospital                     m     \n 3 Central Hospital                     &lt;NA&gt;  \n 4 Military Hospital                    f     \n 5 Military Hospital                    m     \n 6 Military Hospital                    &lt;NA&gt;  \n 7 Missing                              f     \n 8 Missing                              m     \n 9 Missing                              &lt;NA&gt;  \n10 Other                                f     \n11 Other                                m     \n12 Other                                &lt;NA&gt;  \n13 Port Hospital                        f     \n14 Port Hospital                        m     \n15 Port Hospital                        &lt;NA&gt;  \n16 St. Mark's Maternity Hospital (SMMH) f     \n17 St. Mark's Maternity Hospital (SMMH) m     \n18 St. Mark's Maternity Hospital (SMMH) &lt;NA&gt;  \n\n\nNow we combine the groupings together, separated by dashes, and assign them as the names of list elements in linelist_split. This takes some extra lines as we replace NA with “Missing”, use unite() from dplyr to combine the column values together (separated by dashes), and then convert into an un-named vector so it can be used as names of linelist_split.\n\n# Combine into one name value \nnames(linelist_split) &lt;- groupings %&gt;% \n     mutate(across(everything(), replace_na, \"Missing\")) %&gt;%  # replace NA with \"Missing\" in all columns\n     unite(\"combined\", sep = \"-\") %&gt;%                         # Unite all column values into one\n     setNames(NULL) %&gt;% \n     as_vector() %&gt;% \n     as.list()\n\n\n\n\nExport as Excel sheets\nTo export the hospital linelists as an Excel workbook with one linelist per sheet, we can just provide the named list linelist_split to the write_xlsx() function from the writexl package. This has the ability to save one Excel workbook with multiple sheets. The list element names are automatically applied as the sheet names.\n\nlinelist_split %&gt;% \n     writexl::write_xlsx(path = here(\"data\", \"hospital_linelists.xlsx\"))\n\nYou can now open the Excel file and see that each hospital has its own sheet.\n\n\n\n\n\n\n\n\n\n\n\nExport as CSV files\nIt is a bit more complex command, but you can also export each hospital-specific linelist as a separate CSV file, with a file name specific to the hospital.\nAgain we use map(): we take the vector of list element names (shown above) and use map() to iterate through them, applying export() (from the rio package, see Import and export page) on the data frame in the list linelist_split that has that name. We also use the name to create a unique file name. Here is how it works:\n\nWe begin with the vector of character names, passed to map() as .x\n\nThe .f function is export() , which requires a data frame and a file path to write to\n\nThe input .x (the hospital name) is used within .f to extract/index that specific element of linelist_split list. This results in only one data frame at a time being provided to export().\n\nFor example, when map() iterates for “Military Hospital”, then linelist_split[[.x]] is actually linelist_split[[\"Military Hospital\"]], thus returning the second element of linelist_split - which is all the cases from Military Hospital.\n\nThe file path provided to export() is dynamic via use of str_glue() (see Characters and strings page):\n\nhere() is used to get the base of the file path and specify the “data” folder (note single quotes to not interrupt the str_glue() double quotes)\n\n\nThen a slash /, and then again the .x which prints the current hospital name to make the file identifiable\n\nFinally the extension “.csv” which export() uses to create a CSV file\n\n\nnames(linelist_split) %&gt;%\n     map(.f = ~export(linelist_split[[.x]], file = str_glue(\"{here('data')}/{.x}.csv\")))\n\nNow you can see that each file is saved in the “data” folder of the R Project “Epi_R_handbook”!\n\n\n\n\n\n\n\n\n\n\n\n\nCustom functions\nYou may want to create your own function to provide to map().\nLet’s say we want to create epidemic curves for each hospital’s cases. To do this using purrr, our .f function can be ggplot() and extensions with + as usual. As the output of map() is always a list, the plots are stored in a list. Because they are plots, they can be extracted and plotted with the ggarrange() function from the ggpubr package (documentation).\n\n# load package for plotting elements from list\npacman::p_load(ggpubr)\n\n# map across the vector of 6 hospital \"names\" (created earlier)\n# use the ggplot function specified\n# output is a list with 6 ggplots\n\nhospital_names &lt;- unique(linelist$hospital)\n\nmy_plots &lt;- map(\n  .x = hospital_names,\n  .f = ~ggplot(data = linelist %&gt;% filter(hospital == .x)) +\n                geom_histogram(aes(x = date_onset)) +\n                labs(title = .x)\n)\n\n# print the ggplots (they are stored in a list)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n\n\n\n\n\n\n\n\nIf this map() code looks too messy, you can achieve the same result by saving your specific ggplot() command as a custom user-defined function, for example we can name it make_epicurve()). This function is then used within the map(). .x will be iteratively replaced by the hospital name, and used as hosp_name in the make_epicurve() function. See the page on Writing functions.\n\n# Create function\nmake_epicurve &lt;- function(hosp_name){\n  \n  ggplot(data = linelist %&gt;% filter(hospital == hosp_name)) +\n    geom_histogram(aes(x = date_onset)) +\n    theme_classic()+\n    labs(title = hosp_name)\n  \n}\n\n\n# mapping\nmy_plots &lt;- map(hospital_names, ~make_epicurve(hosp_name = .x))\n\n# print the ggplots (they are stored in a list)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n\n\n\nMapping a function across columns\nAnother common use-case is to map a function across many columns. Below, we map() the function t.test() across numeric columns in the data frame linelist, comparing the numeric values by gender.\nRecall from the page on Simple statistical tests that t.test() can take inputs in a formula format, such as t.test(numeric column ~ binary column). In this example, we do the following:\n\nThe numeric columns of interest are selected from linelist - these become the .x inputs to map()\n\nThe function t.test() is supplied as the .f function, which is applied to each numeric column\n\nWithin the parentheses of t.test():\n\nthe first ~ precedes the .f that map() will iterate over .x\n\nthe .x represents the current column being supplied to the function t.test()\n\nthe second ~ is part of the t-test equation described above\n\nthe t.test() function expects a binary column on the right-hand side of the equation. We supply the vector linelist$gender independently and statically (note that it is not included in select()).\n\n\nmap() returns a list, so the output is a list of t-test results - one list element for each numeric column analysed.\n\n# Results are saved as a list\nt.test_results &lt;- linelist %&gt;% \n  select(age, wt_kg, ht_cm, ct_blood, temp) %&gt;%  # keep only some numeric columns to map across\n  map(.f = ~t.test(.x ~ linelist$gender))        # t.test function, with equation NUMERIC ~ CATEGORICAL\n\nHere is what the list t.test_results looks like when opened (Viewed) in RStudio. We have highlighted parts that are important for the examples in this page.\n\nYou can see at the top that the whole list is named t.test_results and has five elements. Those five elements are named age, wt_km, ht_cm, ct_blood, temp after each variable that was used in a t-test with gender from the linelist.\n\nEach of those five elements are themselves lists, with elements within them such as p.value and conf.int. Some of these elements like p.value are single numbers, whereas some such as estimate consist of two or more elements (mean in group f and mean in group m).\n\n\n\n\n\n\n\n\n\n\nNote: Remember that if you want to apply a function to only certain columns in a data frame, you can also simply use mutate() and across(), as explained in the Cleaning data and core functions page. Below is an example of applying as.character() to only the “age” columns. Note the placement of the parentheses and commas.\n\n# convert columns with column name containing \"age\" to class Character\nlinelist &lt;- linelist %&gt;% \n  mutate(across(.cols = contains(\"age\"), .fns = as.character))  \n\n\n\nExtract from lists\nAs map() produces an output of class List, we will spend some time discussing how to extract data from lists using accompanying purrr functions. To demonstrate this, we will use the list t.test_results from the previous section. This is a list of 5 lists - each of the 5 lists contains the results of a t-test between a column from linelist data frame and its binary column gender. See the image in the section above for a visual of the list structure.\n\nNames of elements\nTo extract the names of the elements themselves, simply use names() from base R. In this case, we use names() on t.test_results to return the names of each sub-list, which are the names of the 5 variables that had t-tests performed.\n\nnames(t.test_results)\n\n[1] \"age\"      \"wt_kg\"    \"ht_cm\"    \"ct_blood\" \"temp\"    \n\n\n\n\nElements by name or position\nTo extract list elements by name or by position you can use brackets [[ ]] as described in the R basics page. Below we use double brackets to index the list t.tests_results and display the first element which is the results of the t-test on age.\n\nt.test_results[[1]] # first element by position\n\n\n    Welch Two Sample t-test\n\ndata:  .x by linelist$gender\nt = -21.3, df = 4902.9, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.544409 -6.272675\nsample estimates:\nmean in group f mean in group m \n       12.66085        19.56939 \n\nt.test_results[[1]][\"p.value\"] # return element named \"p.value\" from first element  \n\n$p.value\n[1] 2.350374e-96\n\n\nHowever, below we will demonstrate use of the simple and flexible purrr functions map() and pluck() to achieve the same outcomes.\n\n\npluck()\npluck() pulls out elements by name or by position. For example - to extract the t-test results for age, you can use pluck() like this:\n\nt.test_results %&gt;% \n  pluck(\"age\")        # alternatively, use pluck(1)\n\n\n    Welch Two Sample t-test\n\ndata:  .x by linelist$gender\nt = -21.3, df = 4902.9, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group f and group m is not equal to 0\n95 percent confidence interval:\n -7.544409 -6.272675\nsample estimates:\nmean in group f mean in group m \n       12.66085        19.56939 \n\n\nIndex deeper levels by specifying the further levels with commas. The below extracts the element named “p.value” from the list age within the list t.test_results. You can also use numbers instead of character names.\n\nt.test_results %&gt;% \n  pluck(\"age\", \"p.value\")\n\n[1] 2.350374e-96\n\n\nYou can extract such inner elements from all first-level elements by using map() to run the pluck() function across each first-level element. For example, the below code extracts the “p.value” elements from all lists within t.test_results. The list of t-test results is the .x iterated across, pluck() is the .f function being iterated, and the value “p-value” is provided to the function.\n\nt.test_results %&gt;%\n  map(pluck, \"p.value\")   # return every p-value\n\n$age\n[1] 2.350374e-96\n\n$wt_kg\n[1] 2.664367e-182\n\n$ht_cm\n[1] 3.515713e-144\n\n$ct_blood\n[1] 0.4473498\n\n$temp\n[1] 0.5735923\n\n\nAs another alternative, map() offers a shorthand where you can write the element name in quotes, and it will pluck it out. If you use map() the output will be a list, whereas if you use map_chr() it will be a named character vector and if you use map_dbl() it will be a named numeric vector.\n\nt.test_results %&gt;% \n  map_dbl(\"p.value\")   # return p-values as a named numeric vector\n\n          age         wt_kg         ht_cm      ct_blood          temp \n 2.350374e-96 2.664367e-182 3.515713e-144  4.473498e-01  5.735923e-01 \n\n\nYou can read more about pluck() in it’s purrr documentation. It has a sibling function chuck() that will return an error instead of NULL if an element does not exist.\n\n\n\nConvert list to data frame\nThis is a complex topic - see the Resources section for more complete tutorials. Nevertheless, we will demonstrate converting the list of t-test results into a data frame. We will create a data frame with columns for the variable, its p-value, and the means from the two groups (male and female).\nHere are some of the new approaches and functions that will be used:\n\nThe function tibble() will be used to create a tibble (like a data frame)\n\nWe surround the tibble() function with curly brackets { } to prevent the entire t.test_results from being stored as the first tibble column\n\n\nWithin tibble(), each column is created explicitly, similar to the syntax of mutate():\n\nThe . represents t.test_results\nTo create a column with the t-test variable names (the names of each list element) we use names() as described above\n\nTo create a column with the p-values we use map_dbl() as described above to pull the p.value elements and convert them to a numeric vector\n\n\n\nt.test_results %&gt;% {\n  tibble(\n    variables = names(.),\n    p         = map_dbl(., \"p.value\"))\n  }\n\n# A tibble: 5 × 2\n  variables         p\n  &lt;chr&gt;         &lt;dbl&gt;\n1 age       2.35e- 96\n2 wt_kg     2.66e-182\n3 ht_cm     3.52e-144\n4 ct_blood  4.47e-  1\n5 temp      5.74e-  1\n\n\nBut now let’s add columns containing the means for each group (males and females).\nWe would need to extract the element estimate, but this actually contains two elements within it (mean in group f and mean in group m). So, it cannot be simplified into a vector with map_chr() or map_dbl(). Instead, we use map(), which used within tibble() will create a column of class list within the tibble! Yes, this is possible!\n\nt.test_results %&gt;% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\"))}\n\n# A tibble: 5 × 3\n  variables         p means       \n  &lt;chr&gt;         &lt;dbl&gt; &lt;named list&gt;\n1 age       2.35e- 96 &lt;dbl [2]&gt;   \n2 wt_kg     2.66e-182 &lt;dbl [2]&gt;   \n3 ht_cm     3.52e-144 &lt;dbl [2]&gt;   \n4 ct_blood  4.47e-  1 &lt;dbl [2]&gt;   \n5 temp      5.74e-  1 &lt;dbl [2]&gt;   \n\n\nOnce you have this list column, there are several tidyr functions (part of tidyverse) that help you “rectangle” or “un-nest” these “nested list” columns. Read more about them here, or by running vignette(\"rectangle\"). In brief:\n\nunnest_wider() - gives each element of a list-column its own column\n\nunnest_longer() - gives each element of a list-column its own row\nhoist() - acts like unnest_wider() but you specify which elements to unnest\n\nBelow, we pass the tibble to unnest_wider() specifying the tibble’s means column (which is a nested list). The result is that means is replaced by two new columns, each reflecting the two elements that were previously in each means cell.\n\nt.test_results %&gt;% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\")\n    )} %&gt;% \n  unnest_wider(means)\n\n# A tibble: 5 × 4\n  variables         p `mean in group f` `mean in group m`\n  &lt;chr&gt;         &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n1 age       2.35e- 96              12.7              19.6\n2 wt_kg     2.66e-182              45.8              59.6\n3 ht_cm     3.52e-144             109.              142. \n4 ct_blood  4.47e-  1              21.2              21.2\n5 temp      5.74e-  1              38.6              38.6\n\n\n\n\nDiscard, keep, and compact lists\nBecause working with purrr so often involves lists, we will briefly explore some purrr functions to modify lists. See the Resources section for more complete tutorials on purrr functions.\n\nlist_modify() has many uses, one of which can be to remove a list element\n\nkeep() retains the elements specified to .p =, or where a function supplied to .p = evaluates to TRUE\n\ndiscard() removes the elements specified to .p, or where a function supplied to .p = evaluates to TRUE\n\ncompact() removes all empty elements\n\nHere are some examples using the combined list created in the section above on using map() to import and combine multiple files (it contains 6 case linelist data frames):\nElements can be removed by name with list_modify() and setting the name equal to NULL.\n\ncombined %&gt;% \n  list_modify(\"Central Hospital\" = NULL)   # remove list element by name\n\nYou can also remove elements by criteria, by providing a “predicate” equation to .p = (an equation that evaluates to either TRUE or FALSE). Place a tilde ~ before the function and use .x to represent the list element. Using keep() the list elements that evaluate to TRUE will be kept. Inversely, if using discard() the list elements that evaluate to TRUE will be removed.\n\n# keep only list elements with more than 500 rows\ncombined %&gt;% \n  keep(.p = ~nrow(.x) &gt; 500)  \n\nIn the below example, list elements are discarded if their class are not data frames.\n\n# Discard list elements that are not data frames\ncombined %&gt;% \n  discard(.p = ~class(.x) != \"data.frame\")\n\nYour predicate function can also reference elements/columns within each list item. For example, below, list elements where the mean of column ct_blood is over 25 are discarded.\n\n# keep only list elements where ct_blood column mean is over 25\ncombined %&gt;% \n  discard(.p = ~mean(.x$ct_blood) &gt; 25)  \n\nThis command would remove all empty list elements:\n\n# Remove all empty list elements\ncombined %&gt;% \n  compact()\n\n\n\npmap()\nTHIS SECTION IS UNDER CONSTRUCTION",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Iteration, loops, and lists</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.html#apply-functions",
    "href": "new_pages/iteration.html#apply-functions",
    "title": "8  Iteration, loops, and lists",
    "section": "8.4 Apply functions",
    "text": "8.4 Apply functions\nThe “apply” family of functions is a base R alternative to purrr for iterative operations. You can read more about them here.",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Iteration, loops, and lists</span>"
    ]
  },
  {
    "objectID": "new_pages/iteration.html#resources",
    "href": "new_pages/iteration.html#resources",
    "title": "8  Iteration, loops, and lists",
    "section": "8.5 Resources",
    "text": "8.5 Resources\nfor loops with Data Carpentry\nThe R for Data Science page on iteration\nVignette on write/read Excel files\nA purrr tutorial by jennybc\nAnother purrr tutorial by Rebecca Barter\nA purrr tutorial on map, pmap, and imap\npurrr cheatsheet\npurrr tips and tricks\nkeep and discard",
    "crumbs": [
      "Data Management",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Iteration, loops, and lists</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.html",
    "href": "new_pages/combination_analysis.html",
    "title": "9  Combinations analysis",
    "section": "",
    "text": "9.1 Preparation",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Combinations analysis</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.html#preparation",
    "href": "new_pages/combination_analysis.html#preparation",
    "title": "9  Combinations analysis",
    "section": "",
    "text": "Load packages\nThis code chunk shows the loading of packages required for the analyses. In this handbook we emphasize p_load() from pacman, which installs the package if necessary and loads it for use. You can also load installed packages with library() from base R. See the page on R basics for more information on R packages.\n\npacman::p_load(\n  tidyverse,     # data management and visualization\n  UpSetR,        # special package for combination plots\n  ggupset)       # special package for combination plots\n\n\n\n\nImport data\nTo begin, we import the cleaned linelist of cases from a simulated Ebola epidemic. If you want to follow along, click to download the “clean” linelist (as .rds file). Import data with the import() function from the rio package (it handles many file types like .xlsx, .csv, .rds - see the Import and export page for details).\n\n# import case linelist \nlinelist_sym &lt;- import(\"linelist_cleaned.rds\")\n\nThis linelist includes five “yes/no” variables on reported symptoms. We will need to transform these variables a bit to use the ggupset package to make our plot. View the data (scroll to the right to see the symptoms variables).\n\n\n\n\n\n\n\n\n\nRe-format values\nTo align with the format expected by ggupset we convert the “yes” and “no” the the actual symptom name, using case_when() from dplyr. If “no”, we set the value as blank, so the values are either NA or the symptom.\n\n# create column with the symptoms named, separated by semicolons\nlinelist_sym_1 &lt;- linelist_sym %&gt;% \n\n  # convert the \"yes\" and \"no\" values into the symptom name itself\n  # if old value is \"yes\", new value is \"fever\", otherwise set to missing (NA)\nmutate(fever = ifelse(fever == \"yes\", \"fever\", NA), \n       chills = ifelse(chills == \"yes\", \"chills\", NA),\n       cough = ifelse(cough == \"yes\", \"cough\", NA),\n       aches = ifelse(aches == \"yes\", \"aches\", NA),\n       vomit = ifelse(vomit == \"yes\", \"vomit\", NA))\n\nNow we make two final columns:\n\nConcatenating (gluing together) all the symptoms of the patient (a character column)\n\nConvert the above column to class list, so it can be accepted by ggupset to make the plot\n\nSee the page on Characters and strings to learn more about the unite() function from stringr\n\nlinelist_sym_1 &lt;- linelist_sym_1 %&gt;% \n  unite(col = \"all_symptoms\",\n        c(fever, chills, cough, aches, vomit), \n        sep = \"; \",\n        remove = TRUE,\n        na.rm = TRUE) %&gt;% \n  mutate(\n    # make a copy of all_symptoms column, but of class \"list\" (which is required to use ggupset() in next step)\n    all_symptoms_list = as.list(strsplit(all_symptoms, \"; \"))\n    )\n\nView the new data. Note the two columns towards the right end - the pasted combined values, and the list",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Combinations analysis</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.html#ggupset",
    "href": "new_pages/combination_analysis.html#ggupset",
    "title": "9  Combinations analysis",
    "section": "9.2 ggupset",
    "text": "9.2 ggupset\nLoad the package\n\npacman::p_load(ggupset)\n\nCreate the plot. We begin with a ggplot() and geom_bar(), but then we add the special function scale_x_upset() from the ggupset.\n\nggplot(\n  data = linelist_sym_1,\n  mapping = aes(x = all_symptoms_list)) +\ngeom_bar() +\nscale_x_upset(\n  reverse = FALSE,\n  n_intersections = 10,\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"))+\nlabs(\n  title = \"Signs & symptoms\",\n  subtitle = \"10 most frequent combinations of signs and symptoms\",\n  caption = \"Caption here.\",\n  x = \"Symptom combination\",\n  y = \"Frequency in dataset\")\n\n\n\n\n\n\n\n\nMore information on ggupset can be found online or offline in the package documentation in your RStudio Help tab ?ggupset.",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Combinations analysis</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.html#upsetr",
    "href": "new_pages/combination_analysis.html#upsetr",
    "title": "9  Combinations analysis",
    "section": "9.3 UpSetR",
    "text": "9.3 UpSetR\nThe UpSetR package allows more customization of the plot, but it can be more difficult to execute:\nLoad package\n\npacman::p_load(UpSetR)\n\nData cleaning\nWe must convert the linelist symptoms values to 1 / 0.\n\nlinelist_sym_2 &lt;- linelist_sym %&gt;% \n     # convert the \"yes\" and \"no\" values into 1s and 0s\n     mutate(fever = ifelse(fever == \"yes\", 1, 0), \n            chills = ifelse(chills == \"yes\", 1, 0),\n            cough = ifelse(cough == \"yes\", 1, 0),\n            aches = ifelse(aches == \"yes\", 1, 0),\n            vomit = ifelse(vomit == \"yes\", 1, 0))\n\nIf you are interested in a more efficient command, you can take advantage of the +() function, which converts to 1s and 0s based on a logical statement. This command utilizes the across() function to change multiple columns at once (read more in Cleaning data and core functions).\n\n# Efficiently convert \"yes\" to 1 and 0\nlinelist_sym_2 &lt;- linelist_sym %&gt;% \n  \n  # convert the \"yes\" and \"no\" values into 1s and 0s\n  mutate(across(c(fever, chills, cough, aches, vomit), .fns = ~+(.x == \"yes\")))\n\nNow make the plot using the custom function upset() - using only the symptoms columns. You must designate which “sets” to compare (the names of the symptom columns). Alternatively, use nsets = and order.by = \"freq\" to only show the top X combinations.\n\n# Make the plot\nlinelist_sym_2 %&gt;% \n  UpSetR::upset(\n       sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"),\n       order.by = \"freq\",\n       sets.bar.color = c(\"blue\", \"red\", \"yellow\", \"darkgreen\", \"orange\"), # optional colors\n       empty.intersections = \"on\",\n       # nsets = 3,\n       number.angles = 0,\n       point.size = 3.5,\n       line.size = 2, \n       mainbar.y.label = \"Symptoms Combinations\",\n       sets.x.label = \"Patients with Symptom\")",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Combinations analysis</span>"
    ]
  },
  {
    "objectID": "new_pages/combination_analysis.html#resources",
    "href": "new_pages/combination_analysis.html#resources",
    "title": "9  Combinations analysis",
    "section": "9.4 Resources",
    "text": "9.4 Resources\nThe github page on UpSetR\nA Shiny App version - you can upload your own data\n*documentation - difficult to interpret",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Combinations analysis</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.html",
    "href": "new_pages/transmission_chains.html",
    "title": "10  Transmission chains",
    "section": "",
    "text": "10.1 Overview\nThe primary tool to handle, analyse and visualise transmission chains and contact tracing data is the package epicontacts, developed by the folks at RECON. Try out the interactive plot below by hovering over the nodes for more information, dragging them to move them and clicking on them to highlight downstream cases.\nWarning in epicontacts::make_epicontacts(linelist = linelist, contacts =\ncontacts, : Cycle(s) detected in the contact network: this may be unwanted",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transmission chains</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.html#preparation",
    "href": "new_pages/transmission_chains.html#preparation",
    "title": "10  Transmission chains",
    "section": "10.2 Preparation",
    "text": "10.2 Preparation\n\nLoad packages\nFirst load the standard packages required for data import and manipulation. In this handbook we emphasize p_load() from pacman, which installs the package if necessary and loads it for use. You can also load packages with library() from base R. See the page on R basics for more information on R packages.\n\npacman::p_load(\n   rio,          # File import\n   here,         # File locator\n   tidyverse,    # Data management + ggplot2 graphics\n   remotes       # Package installation from github\n)\n\nYou will require the development version of epicontacts, which can be installed from github using the p_install_github() function from pacman. You only need to run this command below once, not every time you use the package (thereafter, you can use p_load() as usual).\n\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n\n\nImport data\nWe import the dataset of cases from a simulated Ebola epidemic. If you want to download the data to follow step-by-step, see instructions in the Download handbook and data page. The dataset is imported using the import() function from the rio package. See the page on Import and export for various ways to import data.\n\n# import the linelist\nlinelist &lt;- import(\"linelist_cleaned.xlsx\")\n\nThe first 50 rows of the linelist are displayed below. Of particular interest are the columns case_id, generation, infector, and source.\n\n\n\n\n\n\n\n\nCreating an epicontacts object\nWe then need to create an epicontacts object, which requires two types of data:\n\na linelist documenting cases where columns are variables and rows correspond to unique cases\na list of edges defining links between cases on the basis of their unique IDs (these can be contacts, transmission events, etc.)\n\nAs we already have a linelist, we just need to create a list of edges between cases, more specifically between their IDs. We can extract transmission links from the linelist by linking the infector column with the case_id column. At this point we can also add “edge properties”, by which we mean any variable describing the link between the two cases, not the cases themselves. For illustration, we will add a location variable describing the location of the transmission event, and a duration variable describing the duration of the contact in days.\nIn the code below, the dplyr function transmute is similar to mutate, except it only keeps the columns we have specified within the function. The drop_na function will filter out any rows where the specified columns have an NA value; in this case, we only want to keep the rows where the infector is known.\n\n## generate contacts\ncontacts &lt;- linelist %&gt;%\n  transmute(\n    infector = infector,\n    case_id = case_id,\n    location = sample(c(\"Community\", \"Nosocomial\"), n(), TRUE),\n    duration = sample.int(10, n(), TRUE)\n  ) %&gt;%\n  drop_na(infector)\n\nWe can now create the epicontacts object using the make_epicontacts function. We need to specify which column in the linelist points to the unique case identifier, as well as which columns in the contacts point to the unique identifiers of the cases involved in each link. These links are directional in that infection is going from the infector to the case, so we need to specify the from and to arguments accordingly. We therefore also set the directed argument to TRUE, which will affect future operations.\n\n## generate epicontacts object\nepic &lt;- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts,\n  id = \"case_id\",\n  from = \"infector\",\n  to = \"case_id\",\n  directed = TRUE\n)\n\nWarning in make_epicontacts(linelist = linelist, contacts = contacts, id =\n\"case_id\", : Cycle(s) detected in the contact network: this may be unwanted\n\n\nUpon examining the epicontacts objects, we can see that the case_id column in the linelist has been renamed to id and the case_id and infector columns in the contacts have been renamed to from and to. This ensures consistency in subsequent handling, visualisation and analysis operations.\n\n## view epicontacts object\nepic\n\n\n/// Epidemiological Contacts //\n\n  // class: epicontacts\n  // 5,888 cases in linelist; 3,800 contacts; directed \n\n  // linelist\n\n# A tibble: 5,888 × 30\n   id     generation date_infection date_onset date_hospitalisation date_outcome\n   &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 5fe599          4 2014-05-08     2014-05-13 2014-05-15           NA          \n 2 8689b7          4 NA             2014-05-13 2014-05-14           2014-05-18  \n 3 11f8ea          2 NA             2014-05-16 2014-05-18           2014-05-30  \n 4 b8812a          3 2014-05-04     2014-05-18 2014-05-20           NA          \n 5 893f25          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 6 be99c8          3 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n 7 07e3e8          4 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n 8 369449          4 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n 9 f393b4          4 NA             2014-06-05 2014-06-06           2014-06-18  \n10 1389ca          4 NA             2014-06-05 2014-06-07           2014-06-09  \n# ℹ 5,878 more rows\n# ℹ 24 more variables: outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;,\n#   age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, hospital &lt;chr&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;,\n#   ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;,\n#   vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;, bmi &lt;dbl&gt;,\n#   days_onset_hosp &lt;dbl&gt;\n\n  // contacts\n\n# A tibble: 3,800 × 4\n   from   to     location   duration\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;         &lt;int&gt;\n 1 f547d6 5fe599 Nosocomial       10\n 2 f90f5f b8812a Nosocomial        2\n 3 11f8ea 893f25 Nosocomial        8\n 4 aec8ec be99c8 Community         1\n 5 893f25 07e3e8 Nosocomial        8\n 6 133ee7 369449 Community         2\n 7 996f3a 2978ac Community         8\n 8 133ee7 57a565 Nosocomial        1\n 9 37a6f6 fc15ef Community         8\n10 9f6884 2eaa9a Nosocomial        7\n# ℹ 3,790 more rows",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transmission chains</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.html#handling",
    "href": "new_pages/transmission_chains.html#handling",
    "title": "10  Transmission chains",
    "section": "10.3 Handling",
    "text": "10.3 Handling\n\nSubsetting\nThe subset() method for epicontacts objects allows for, among other things, filtering of networks based on properties of the linelist (“node attributes”) and the contacts database (“edge attributes”). These values must be passed as named lists to the respective argument. For example, in the code below we are keeping only the male cases in the linelist that have an infection date between April and July 2014 (dates are specified as ranges), and transmission links that occured in the hospital.\n\nsub_attributes &lt;- subset(\n  epic,\n  node_attribute = list(\n    gender = \"m\",\n    date_infection = as.Date(c(\"2014-04-01\", \"2014-07-01\"))\n  ), \n  edge_attribute = list(location = \"Nosocomial\")\n)\nsub_attributes\n\n\n/// Epidemiological Contacts //\n\n  // class: epicontacts\n  // 69 cases in linelist; 1,905 contacts; directed \n\n  // linelist\n\n# A tibble: 69 × 30\n   id     generation date_infection date_onset date_hospitalisation date_outcome\n   &lt;chr&gt;       &lt;dbl&gt; &lt;date&gt;         &lt;date&gt;     &lt;date&gt;               &lt;date&gt;      \n 1 5fe599          4 2014-05-08     2014-05-13 2014-05-15           NA          \n 2 893f25          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n 3 2978ac          4 2014-05-30     2014-06-06 2014-06-08           2014-06-15  \n 4 57a565          4 2014-05-28     2014-06-13 2014-06-15           NA          \n 5 fc15ef          6 2014-06-14     2014-06-16 2014-06-17           2014-07-09  \n 6 99e8fa          7 2014-06-24     2014-06-28 2014-06-29           2014-07-09  \n 7 f327be          6 2014-06-14     2014-07-12 2014-07-13           2014-07-14  \n 8 90e5fe          5 2014-06-18     2014-07-13 2014-07-14           2014-07-16  \n 9 a47529          5 2014-06-13     2014-07-17 2014-07-18           2014-07-26  \n10 da8ecb          5 2014-06-20     2014-07-18 2014-07-20           2014-08-01  \n# ℹ 59 more rows\n# ℹ 24 more variables: outcome &lt;chr&gt;, gender &lt;chr&gt;, age &lt;dbl&gt;, age_unit &lt;chr&gt;,\n#   age_years &lt;dbl&gt;, age_cat &lt;fct&gt;, age_cat5 &lt;fct&gt;, hospital &lt;chr&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;, infector &lt;chr&gt;, source &lt;chr&gt;, wt_kg &lt;dbl&gt;, ht_cm &lt;dbl&gt;,\n#   ct_blood &lt;dbl&gt;, fever &lt;chr&gt;, chills &lt;chr&gt;, cough &lt;chr&gt;, aches &lt;chr&gt;,\n#   vomit &lt;chr&gt;, temp &lt;dbl&gt;, time_admission &lt;chr&gt;, bmi &lt;dbl&gt;,\n#   days_onset_hosp &lt;dbl&gt;\n\n  // contacts\n\n# A tibble: 1,905 × 4\n   from   to     location   duration\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;         &lt;int&gt;\n 1 f547d6 5fe599 Nosocomial       10\n 2 f90f5f b8812a Nosocomial        2\n 3 11f8ea 893f25 Nosocomial        8\n 4 893f25 07e3e8 Nosocomial        8\n 5 133ee7 57a565 Nosocomial        1\n 6 9f6884 2eaa9a Nosocomial        7\n 7 4802b1 bbfa93 Nosocomial       10\n 8 8e104d ddddee Nosocomial        4\n 9 b799eb bc2adf Nosocomial        2\n10 5d9e4d 8bd1e8 Nosocomial        5\n# ℹ 1,895 more rows\n\n\nWe can use the thin function to either filter the linelist to include cases that are found in the contacts by setting the argument what = \"linelist\", or filter the contacts to include cases that are found in the linelist by setting the argument what = \"contacts\". In the code below, we are further filtering the epicontacts object to keep only the transmission links involving the male cases infected between April and July which we had filtered for above. We can see that only two known transmission links fit that specification.\n\nsub_attributes &lt;- thin(sub_attributes, what = \"contacts\")\nnrow(sub_attributes$contacts)\n\n[1] 2\n\n\nIn addition to subsetting by node and edge attributes, networks can be pruned to only include components that are connected to certain nodes. The cluster_id argument takes a vector of case IDs and returns the linelist of individuals that are linked, directly or indirectly, to those IDs. In the code below, we can see that a total of 13 linelist cases are involved in the clusters containing 2ae019 and 71577a.\n\nsub_id &lt;- subset(epic, cluster_id = c(\"2ae019\",\"71577a\"))\nnrow(sub_id$linelist)\n\n[1] 13\n\n\nThe subset() method for epicontacts objects also allows filtering by cluster size using the cs, cs_min and cs_max arguments. In the code below, we are keeping only the cases linked to clusters of 10 cases or larger, and can see that 271 linelist cases are involved in such clusters.\n\nsub_cs &lt;- subset(epic, cs_min = 10)\nnrow(sub_cs$linelist)\n\n[1] 271\n\n\n\n\nAccessing IDs\nThe get_id() function retrieves information on case IDs in the dataset, and can be parameterized as follows:\n\nlinelist: IDs in the line list data\ncontacts: IDs in the contact dataset (“from” and “to” combined)\nfrom: IDs in the “from” column of contact datset\nto IDs in the “to” column of contact dataset\nall: IDs that appear anywhere in either dataset\ncommon: IDs that appear in both contacts dataset and line list\n\nFor example, what are the first ten IDs in the contacts dataset?\n\ncontacts_ids &lt;- get_id(epic, \"contacts\")\nhead(contacts_ids, n = 10)\n\n [1] \"f547d6\" \"f90f5f\" \"11f8ea\" \"aec8ec\" \"893f25\" \"133ee7\" \"996f3a\" \"37a6f6\"\n [9] \"9f6884\" \"4802b1\"\n\n\nHow many IDs are found in both the linelist and the contacts?\n\nlength(get_id(epic, \"common\"))\n\n[1] 4352",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transmission chains</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.html#visualization",
    "href": "new_pages/transmission_chains.html#visualization",
    "title": "10  Transmission chains",
    "section": "10.4 Visualization",
    "text": "10.4 Visualization\n\nBasic plotting\nAll visualisations of epicontacts objects are handled by the plot function. We will first filter the epicontacts object to include only the cases with onset dates in June 2014 using the subset function, and only include the contacts linked to those cases using the thin function.\n\n## subset epicontacts object\nsub &lt;- epic %&gt;%\n  subset(\n    node_attribute = list(date_onset = c(as.Date(c(\"2014-06-30\", \"2014-06-01\"))))\n  ) %&gt;%\n thin(\"contacts\")\n\nWe can then create the basic, interactive plot very simply as follows:\n\n## plot epicontacts object\nplot(\n  sub,\n  width = 700,\n  height = 700\n)\n\n\n\n\n\nYou can move the nodes around by dragging them, hover over them for more information and click on them to highlight connected cases.\nThere are a large number of arguments to further modify this plot. We will cover the main ones here, but check out the documentation via ?vis_epicontacts (the function called when using plot on an epicontacts object) to get a full description of the function arguments.\n\nVisualising node attributes\nNode color, node shape and node size can be mapped to a given column in the linelist using the node_color, node_shape and node_size arguments. This is similar to the aes syntax you may recognise from ggplot2.\nThe specific colors, shapes and sizes of nodes can be specified as follows:\n\nColors via the col_pal argument, either by providing a name list for manual specification of each color as done below, or by providing a color palette function such as colorRampPalette(c(\"black\", \"red\", \"orange\")), which would provide a gradient of colours between the ones specified.\nShapes by passing a named list to the shapes argument, specifying one shape for each unique element in the linelist column specified by the node_shape argument. See codeawesome for available shapes.\nSize by passing a size range of the nodes to the size_range argument.\n\nHere an example, where color represents the outcome, shape the gender and size the age:\n\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = \"age\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\nVisualising edge attributes\nEdge color, width and linetype can be mapped to a given column in the contacts dataframe using the edge_color, edge_width and edge_linetype arguments. The specific colors and widths of the edges can be specified as follows:\n\nColors via the edge_col_pal argument, in the same manner used for col_pal.\nWidths by passing a size range of the nodes to the width_range argument.\n\nHere an example:\n\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = 'age',\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  edge_color = 'location',\n  edge_linetype = 'location',\n  edge_width = 'duration',\n  edge_col_pal = c(Community = \"orange\", Nosocomial = \"purple\"),\n  width_range = c(1, 3),\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\n\nTemporal axis\nWe can also visualise the network along a temporal axis by mapping the x_axis argument to a column in the linelist. In the example below, the x-axis represents the date of symptom onset. We have also specified the arrow_size argument to ensure the arrows are not too large, and set label = FALSE to make the figure less cluttered.\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\nThere are a large number of additional arguments to futher specify how this network is visualised along a temporal axis, which you can check out via ?vis_temporal_interactive (the function called when using plot on an epicontacts object with x_axis specified). We’ll go through some below.\n\nSpecifying transmission tree shape\nThere are two main shapes that the transmission tree can assume, specified using the network_shape argument. The first is a branching shape as shown above, where a straight edge connects any two nodes. This is the most intuitive representation, however can result in overlapping edges in a densely connected network. The second shape is rectangle, which produces a tree resembling a phylogeny. For example:\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\nEach case node can be assigned a unique vertical position by toggling the position_dodge argument. The position of unconnected cases (i.e. with no reported contacts) is specified using the unlinked_pos argument.\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  position_dodge = TRUE,\n  unlinked_pos = \"bottom\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\nThe position of the parent node relative to the children nodes can be specified using the parent_pos argument. The default option is to place the parent node in the middle, however it can be placed at the bottom (parent_pos = 'bottom') or at the top (parent_pos = 'top').\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\n\n\n\n\n\n\n\nSaving plots and figures\nYou can save a plot as an interactive, self-contained html file with the visSave function from the VisNetwork package:\n\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n) %&gt;%\n  visNetwork::visSave(\"network.html\")\n\nSaving these network outputs as an image is unfortunately less easy and requires you to save the file as an html and then take a screenshot of this file using the webshot package. In the code below, we are converting the html file saved above into a PNG:\n\nwebshot(url = \"network.html\", file = \"network.png\")\n\n\n\n\nTimelines\nYou can also case timelines to the network, which are represented on the x-axis of each case. This can be used to visualise case locations, for example, or time to outcome. To generate a timeline, we need to create a data.frame of at least three columns indicating the case ID, the start date of the “event” and the end of date of the “event”. You can also add any number of other columns which can then be mapped to node and edge properties of the timeline. In the code below, we generate a timeline going from the date of symptom onset to the date of outcome, and keep the outcome and hospital variables which we use to define the node shape and colour. Note that you can have more than one timeline row/event per case, for example if a case is transferred between multiple hospitals.\n\n## generate timeline\ntimeline &lt;- linelist %&gt;%\n  transmute(\n    id = case_id,\n    start = date_onset,\n    end = date_outcome,\n    outcome = outcome,\n    hospital = hospital\n  )\n\nWe then pass the timeline element to the timeline argument. We can map timeline attributes to timeline node colours, shapes and sizes in the same way defined in previous sections, except that we have two nodes: the start and end node of each timeline, which have seperate arguments. For example, tl_start_node_color defines which timeline column is mapped to the colour of the start node, while tl_end_node_shape defines which timeline column is mapped to the shape of the end node. We can also map colour, width, linetype and labels to the timeline edge via the tl_edge_* arguments.\nSee ?vis_temporal_interactive (the function called when plotting an epicontacts object) for detailed documentation on the arguments. Each argument is annotated in the code below too:\n\n## define shapes\nshapes &lt;- c(\n  f = \"female\",\n  m = \"male\",\n  Death = \"user-times\",\n  Recover = \"heartbeat\",\n  \"NA\" = \"question-circle\"\n)\n\n## define colours\ncolours &lt;- c(\n  Death = \"firebrick\",\n  Recover = \"green\",\n  \"NA\" = \"grey\"\n)\n\n## make plot\nplot(\n  sub,\n  ## max x coordinate to date of onset\n  x_axis = \"date_onset\",\n  ## use rectangular network shape\n  network_shape = \"rectangle\",\n  ## mape case node shapes to gender column\n  node_shape = \"gender\",\n  ## we don't want to map node colour to any columns - this is important as the\n  ## default value is to map to node id, which will mess up the colour scheme\n  node_color = NULL,\n  ## set case node size to 30 (as this is not a character, node_size is not\n  ## mapped to a column but instead interpreted as the actual node size)\n  node_size = 30,\n  ## set transmission link width to 4 (as this is not a character, edge_width is\n  ## not mapped to a column but instead interpreted as the actual edge width)\n  edge_width = 4,\n  ## provide the timeline object\n  timeline = timeline,\n  ## map the shape of the end node to the outcome column in the timeline object\n  tl_end_node_shape = \"outcome\",\n  ## set the size of the end node to 15 (as this is not a character, this\n  ## argument is not mapped to a column but instead interpreted as the actual\n  ## node size)\n  tl_end_node_size = 15,\n  ## map the colour of the timeline edge to the hospital column\n  tl_edge_color = \"hospital\",\n  ## set the width of the timeline edge to 2 (as this is not a character, this\n  ## argument is not mapped to a column but instead interpreted as the actual\n  ## edge width)\n  tl_edge_width = 2,\n  ## map edge labels to the hospital variable\n  tl_edge_label = \"hospital\",\n  ## specify the shape for everyone node attribute (defined above)\n  shapes = shapes,\n  ## specify the colour palette (defined above)\n  col_pal = colours,\n  ## set the size of the arrow to 0.5\n  arrow_size = 0.5,\n  ## use two columns in the legend\n  legend_ncol = 2,\n  ## set font size\n  font_size = 15,\n  ## define formatting for dates\n  date_labels = c(\"%d %b %Y\"),\n  ## don't plot the ID labels below nodes\n  label = FALSE,\n  ## specify height\n  height = 1000,\n  ## specify width\n  width = 1200,\n  ## ensure each case node has a unique y-coordinate - this is very important\n  ## when using timelines, otherwise you will have overlapping timelines from\n  ## different cases\n  position_dodge = TRUE\n)\n\nWarning in assert_timeline(timeline, x, x_axis): 5865 timeline row(s) removed\nas ID not found in linelist or start/end date is NA",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transmission chains</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.html#analysis",
    "href": "new_pages/transmission_chains.html#analysis",
    "title": "10  Transmission chains",
    "section": "10.5 Analysis",
    "text": "10.5 Analysis\n\nSummarising\nWe can get an overview of some of the network properties using the summary function.\n\n## summarise epicontacts object\nsummary(epic)\n\n\n/// Overview //\n  // number of unique IDs in linelist: 5888\n  // number of unique IDs in contacts: 5511\n  // number of unique IDs in both: 4352\n  // number of contacts: 3800\n  // contacts with both cases in linelist: 56.868 %\n\n/// Degrees of the network //\n  // in-degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  1.0000  0.5392  1.0000  1.0000 \n\n  // out-degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.5392  1.0000  6.0000 \n\n  // in and out degree summary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   1.000   1.000   1.078   1.000   7.000 \n\n/// Attributes //\n  // attributes in linelist:\n generation date_infection date_onset date_hospitalisation date_outcome outcome gender age age_unit age_years age_cat age_cat5 hospital lon lat infector source wt_kg ht_cm ct_blood fever chills cough aches vomit temp time_admission bmi days_onset_hosp\n\n  // attributes in contacts:\n location duration\n\n\nFor example, we can see that only 57% of contacts have both cases in the linelist; this means that the we do not have linelist data on a significant number of cases involved in these transmission chains.\n\n\nPairwise characteristics\nThe get_pairwise() function allows processing of variable(s) in the line list according to each pair in the contact dataset. For the following example, date of onset of disease is extracted from the line list in order to compute the difference between disease date of onset for each pair. The value that is produced from this comparison represents the serial interval (si).\n\nsi &lt;- get_pairwise(epic, \"date_onset\")   \nsummary(si)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    5.00    9.00   11.01   15.00   99.00    1820 \n\ntibble(si = si) %&gt;%\n  ggplot(aes(si)) +\n  geom_histogram() +\n  labs(\n    x = \"Serial interval\",\n    y = \"Frequency\"\n  )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1820 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\nThe get_pairwise() will interpret the class of the column being used for comparison, and will adjust its method of comparing the values accordingly. For numbers and dates (like the si example above), the function will subtract the values. When applied to columns that are characters or categorical, get_pairwise() will paste values together. Because the function also allows for arbitrary processing (see “f” argument), these discrete combinations can be easily tabulated and analyzed.\n\nhead(get_pairwise(epic, \"gender\"), n = 10)\n\n [1] \"f -&gt; m\" NA       \"m -&gt; m\" NA       \"m -&gt; f\" \"f -&gt; f\" NA       \"f -&gt; m\"\n [9] NA       \"m -&gt; f\"\n\nget_pairwise(epic, \"gender\", f = table)\n\n           values.to\nvalues.from   f   m\n          f 464 516\n          m 510 468\n\nfisher.test(get_pairwise(epic, \"gender\", f = table))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  get_pairwise(epic, \"gender\", f = table)\np-value = 0.03758\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.6882761 0.9892811\nsample estimates:\nodds ratio \n 0.8252575 \n\n\nHere, we see a significant association between transmission links and gender.\n\n\nIdentifying clusters\nThe get_clusters() function can be used for to identify connected components in an epicontacts object. First, we use it to retrieve a data.frame containing the cluster information:\n\nclust &lt;- get_clusters(epic, output = \"data.frame\")\ntable(clust$cluster_size)\n\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14 \n1536 1680 1182  784  545  342  308  208  171  100   99   24   26   42 \n\nggplot(clust, aes(cluster_size)) +\n  geom_bar() +\n  labs(\n    x = \"Cluster size\",\n    y = \"Frequency\"\n  )\n\n\n\n\n\n\n\n\nLet us look at the largest clusters. For this, we add cluster information to the epicontacts object and then subset it to keep only the largest clusters:\n\nepic &lt;- get_clusters(epic)\nmax_size &lt;- max(epic$linelist$cluster_size)\nplot(subset(epic, cs = max_size))\n\n\n\n\n\n\n\nCalculating degrees\nThe degree of a node corresponds to its number of edges or connections to other nodes. get_degree() provides an easy method for calculating this value for epicontacts networks. A high degree in this context indicates an individual who was in contact with many others. The type argument indicates that we want to count both the in-degree and out-degree, the only_linelist argument indicates that we only want to calculate the degree for cases in the linelist.\n\ndeg_both &lt;- get_degree(epic, type = \"both\", only_linelist = TRUE)\n\nWhich individuals have the ten most contacts?\n\nhead(sort(deg_both, decreasing = TRUE), 10)\n\n916d0a 858426 6833d7 f093ea 11f8ea 3a4372 38fc71 c8c4d5 a127a7 02d8fd \n     7      6      6      6      5      5      5      5      5      5 \n\n\nWhat is the mean number of contacts?\n\nmean(deg_both)\n\n[1] 1.078473",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transmission chains</span>"
    ]
  },
  {
    "objectID": "new_pages/transmission_chains.html#resources",
    "href": "new_pages/transmission_chains.html#resources",
    "title": "10  Transmission chains",
    "section": "10.6 Resources",
    "text": "10.6 Resources\nThe epicontacts page provides an overview of the package functions and includes some more in-depth vignettes.\nThe github page can be used to raise issues and request features.",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transmission chains</span>"
    ]
  }
]